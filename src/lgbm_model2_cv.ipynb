{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lgbm CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('../data/feat/data.h5') as store:\n",
    "    print(store.keys())\n",
    "    X_train = store['X_train']\n",
    "    X_cv = store['X_cv']\n",
    "    y_train = store['y_train']\n",
    "    y_cv = store['y_cv']\n",
    "    X_test = store['X_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.clip(0,20)\n",
    "y_cv = y_cv.clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'bossting_type':'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'learning_rate' : 0.1,\n",
    "    'metric': 'rmse',    \n",
    "    'max_depth' : 12,\n",
    "    'num_leaves': 64,\n",
    "    'feature_fraction': 0.6203,\n",
    "    'bagging_fraction' : 0.9567,\n",
    "    'reg_lambda' : 0.3886,\n",
    "    'gamma' : 0.3962\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train,y_train)\n",
    "lgb_cv = lgb.Dataset(X_cv,y_cv,reference=lgb_train)\n",
    "gbm = lgb.train(params,lgb_train,valid_sets=lgb_cv,early_stopping_rounds = 5,num_boost_round=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your configurations as a dict\n",
    "# params = {\n",
    "#     'task': 'train',\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'objective': 'regression',\n",
    "#     'metric': {'l2', 'rmse'},\n",
    "#     'num_leaves': 31,\n",
    "#     'learning_rate': 0.05,\n",
    "#     'feature_fraction': 0.9,\n",
    "#     'bagging_fraction': 0.8,\n",
    "#     'bagging_freq': 5,\n",
    "#     'verbose': 0\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novice use of CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tcv_agg's rmse: 1.03234 + 0.00143198\n",
      "[2]\tcv_agg's rmse: 0.969869 + 0.00217628\n",
      "[3]\tcv_agg's rmse: 0.94568 + 0.00212529\n",
      "[4]\tcv_agg's rmse: 0.932161 + 0.00219261\n",
      "[5]\tcv_agg's rmse: 0.92496 + 0.00248139\n",
      "[6]\tcv_agg's rmse: 0.91999 + 0.00288447\n",
      "[7]\tcv_agg's rmse: 0.91606 + 0.00292988\n",
      "[8]\tcv_agg's rmse: 0.912338 + 0.00339231\n",
      "[9]\tcv_agg's rmse: 0.909737 + 0.00295088\n",
      "[10]\tcv_agg's rmse: 0.907743 + 0.00264986\n",
      "[11]\tcv_agg's rmse: 0.905281 + 0.00271093\n",
      "[12]\tcv_agg's rmse: 0.903528 + 0.00251146\n",
      "[13]\tcv_agg's rmse: 0.900599 + 0.00274028\n",
      "[14]\tcv_agg's rmse: 0.898606 + 0.00281831\n",
      "[15]\tcv_agg's rmse: 0.896049 + 0.00251786\n",
      "[16]\tcv_agg's rmse: 0.894117 + 0.00200885\n",
      "[17]\tcv_agg's rmse: 0.891856 + 0.00192826\n",
      "[18]\tcv_agg's rmse: 0.889589 + 0.00151304\n",
      "[19]\tcv_agg's rmse: 0.886479 + 0.00324279\n",
      "[20]\tcv_agg's rmse: 0.885476 + 0.00329226\n",
      "[21]\tcv_agg's rmse: 0.884688 + 0.00351945\n",
      "[22]\tcv_agg's rmse: 0.884 + 0.0033044\n",
      "[23]\tcv_agg's rmse: 0.882579 + 0.0033812\n",
      "[24]\tcv_agg's rmse: 0.882037 + 0.0031244\n",
      "[25]\tcv_agg's rmse: 0.880754 + 0.00349753\n",
      "[26]\tcv_agg's rmse: 0.879745 + 0.00349487\n",
      "[27]\tcv_agg's rmse: 0.878613 + 0.00393714\n",
      "[28]\tcv_agg's rmse: 0.87764 + 0.00417912\n",
      "[29]\tcv_agg's rmse: 0.876856 + 0.00418736\n",
      "[30]\tcv_agg's rmse: 0.875748 + 0.00401065\n",
      "[31]\tcv_agg's rmse: 0.87488 + 0.00373185\n",
      "[32]\tcv_agg's rmse: 0.874507 + 0.00372708\n",
      "[33]\tcv_agg's rmse: 0.873664 + 0.0042009\n",
      "[34]\tcv_agg's rmse: 0.873267 + 0.00430408\n",
      "[35]\tcv_agg's rmse: 0.872189 + 0.00383844\n",
      "[36]\tcv_agg's rmse: 0.870715 + 0.00351895\n",
      "[37]\tcv_agg's rmse: 0.869941 + 0.00352628\n",
      "[38]\tcv_agg's rmse: 0.869553 + 0.00356156\n",
      "[39]\tcv_agg's rmse: 0.869069 + 0.00360621\n",
      "[40]\tcv_agg's rmse: 0.868376 + 0.00406702\n",
      "[41]\tcv_agg's rmse: 0.867723 + 0.00421157\n",
      "[42]\tcv_agg's rmse: 0.867175 + 0.00404434\n",
      "[43]\tcv_agg's rmse: 0.866784 + 0.0039693\n",
      "[44]\tcv_agg's rmse: 0.866305 + 0.00377743\n",
      "[45]\tcv_agg's rmse: 0.865841 + 0.00397907\n",
      "[46]\tcv_agg's rmse: 0.865615 + 0.00401405\n",
      "[47]\tcv_agg's rmse: 0.865182 + 0.003965\n",
      "[48]\tcv_agg's rmse: 0.864963 + 0.00403041\n",
      "[49]\tcv_agg's rmse: 0.864215 + 0.0046386\n",
      "[50]\tcv_agg's rmse: 0.86391 + 0.00476203\n",
      "[51]\tcv_agg's rmse: 0.863636 + 0.00472004\n",
      "[52]\tcv_agg's rmse: 0.863279 + 0.00465803\n",
      "[53]\tcv_agg's rmse: 0.862976 + 0.00450392\n",
      "[54]\tcv_agg's rmse: 0.862003 + 0.00402494\n",
      "[55]\tcv_agg's rmse: 0.861658 + 0.00390904\n",
      "[56]\tcv_agg's rmse: 0.861231 + 0.00404285\n",
      "[57]\tcv_agg's rmse: 0.860777 + 0.0038461\n",
      "[58]\tcv_agg's rmse: 0.860104 + 0.00397514\n",
      "[59]\tcv_agg's rmse: 0.859619 + 0.00383765\n",
      "[60]\tcv_agg's rmse: 0.859225 + 0.00381977\n",
      "[61]\tcv_agg's rmse: 0.859134 + 0.00382727\n",
      "[62]\tcv_agg's rmse: 0.858843 + 0.00378404\n",
      "[63]\tcv_agg's rmse: 0.8587 + 0.00379257\n",
      "[64]\tcv_agg's rmse: 0.858106 + 0.00411458\n",
      "[65]\tcv_agg's rmse: 0.857835 + 0.00423048\n",
      "[66]\tcv_agg's rmse: 0.857532 + 0.00447426\n",
      "[67]\tcv_agg's rmse: 0.856423 + 0.0044707\n",
      "[68]\tcv_agg's rmse: 0.8553 + 0.00419247\n",
      "[69]\tcv_agg's rmse: 0.854967 + 0.00400725\n",
      "[70]\tcv_agg's rmse: 0.854698 + 0.00405431\n",
      "[71]\tcv_agg's rmse: 0.854208 + 0.00433056\n",
      "[72]\tcv_agg's rmse: 0.853972 + 0.00441893\n",
      "[73]\tcv_agg's rmse: 0.853748 + 0.00448459\n",
      "[74]\tcv_agg's rmse: 0.853595 + 0.00438616\n",
      "[75]\tcv_agg's rmse: 0.853451 + 0.00444391\n",
      "[76]\tcv_agg's rmse: 0.852999 + 0.00461308\n",
      "[77]\tcv_agg's rmse: 0.852894 + 0.00460249\n",
      "[78]\tcv_agg's rmse: 0.85277 + 0.00448703\n",
      "[79]\tcv_agg's rmse: 0.852202 + 0.00462301\n",
      "[80]\tcv_agg's rmse: 0.851948 + 0.00449431\n",
      "[81]\tcv_agg's rmse: 0.851357 + 0.00501109\n",
      "[82]\tcv_agg's rmse: 0.850971 + 0.00505744\n",
      "[83]\tcv_agg's rmse: 0.850471 + 0.00477527\n",
      "[84]\tcv_agg's rmse: 0.849405 + 0.00444951\n",
      "[85]\tcv_agg's rmse: 0.84898 + 0.00395629\n",
      "[86]\tcv_agg's rmse: 0.84846 + 0.00406181\n",
      "[87]\tcv_agg's rmse: 0.847826 + 0.00359062\n",
      "[88]\tcv_agg's rmse: 0.847539 + 0.00340086\n",
      "[89]\tcv_agg's rmse: 0.846756 + 0.00281177\n",
      "[90]\tcv_agg's rmse: 0.846536 + 0.00284818\n",
      "[91]\tcv_agg's rmse: 0.846495 + 0.00283156\n",
      "[92]\tcv_agg's rmse: 0.844919 + 0.00150111\n",
      "[93]\tcv_agg's rmse: 0.844807 + 0.00150466\n",
      "[94]\tcv_agg's rmse: 0.8446 + 0.0013567\n",
      "[95]\tcv_agg's rmse: 0.844546 + 0.00136099\n",
      "[96]\tcv_agg's rmse: 0.844061 + 0.00138553\n",
      "[97]\tcv_agg's rmse: 0.842624 + 0.00218113\n",
      "[98]\tcv_agg's rmse: 0.842553 + 0.00213448\n",
      "[99]\tcv_agg's rmse: 0.842477 + 0.002076\n",
      "[100]\tcv_agg's rmse: 0.842257 + 0.00227123\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(X_train,y_train)\n",
    "# lgb_cv = lgb.Dataset(X_cv,y_cv,reference=lgb_train)\n",
    "gbm_cv = lgb.cv(params,lgb_train,early_stopping_rounds=5,verbose_eval=True)\n",
    "# lgb_cv = lgb.Dataset(X_cv,y_cv,reference=lgb_train)\n",
    "# lgb.cv(params,lgb_train,nfold=5,early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse-mean': [1.0323381721608214,\n",
       "  0.96986926719416322,\n",
       "  0.94568036585486515,\n",
       "  0.93216103030699848,\n",
       "  0.92496029162308024,\n",
       "  0.91999034231293031,\n",
       "  0.91606042745827043,\n",
       "  0.91233804952695652,\n",
       "  0.90973680437232818,\n",
       "  0.90774318265118903,\n",
       "  0.90528102143619105,\n",
       "  0.90352834988947561,\n",
       "  0.90059925149454811,\n",
       "  0.89860582904161357,\n",
       "  0.89604894591197615,\n",
       "  0.89411724656026281,\n",
       "  0.89185592138487579,\n",
       "  0.88958898904249417,\n",
       "  0.88647949168224061,\n",
       "  0.88547550760346749,\n",
       "  0.88468781195352442,\n",
       "  0.88399973334494741,\n",
       "  0.88257942989701699,\n",
       "  0.88203680904850668,\n",
       "  0.88075385169054576,\n",
       "  0.87974546278586607,\n",
       "  0.87861323981317929,\n",
       "  0.87763999667357484,\n",
       "  0.87685597770751955,\n",
       "  0.87574756411099808,\n",
       "  0.87487981170824691,\n",
       "  0.87450659036740785,\n",
       "  0.87366356665092071,\n",
       "  0.87326665483544252,\n",
       "  0.87218910670782113,\n",
       "  0.87071539408735588,\n",
       "  0.86994109757767146,\n",
       "  0.86955280108706978,\n",
       "  0.86906921304653584,\n",
       "  0.86837614740944091,\n",
       "  0.86772251466890249,\n",
       "  0.86717486832851731,\n",
       "  0.86678444189720238,\n",
       "  0.86630523555138095,\n",
       "  0.86584102313378575,\n",
       "  0.8656145021292323,\n",
       "  0.8651820700643722,\n",
       "  0.86496306876810469,\n",
       "  0.86421460629408275,\n",
       "  0.8639101361093523,\n",
       "  0.86363627688642697,\n",
       "  0.86327888210327097,\n",
       "  0.86297636717156334,\n",
       "  0.86200311248211769,\n",
       "  0.86165753815804358,\n",
       "  0.86123054545049982,\n",
       "  0.86077693676211864,\n",
       "  0.8601042274506796,\n",
       "  0.85961926178837833,\n",
       "  0.85922530854011148,\n",
       "  0.85913392951102807,\n",
       "  0.85884257274449405,\n",
       "  0.85870012715357869,\n",
       "  0.85810561324614798,\n",
       "  0.85783509959578286,\n",
       "  0.85753205195667304,\n",
       "  0.85642342143486272,\n",
       "  0.85529958892074665,\n",
       "  0.85496674651202709,\n",
       "  0.85469774557414357,\n",
       "  0.85420750188499284,\n",
       "  0.853971786744539,\n",
       "  0.85374844334577404,\n",
       "  0.85359466611760393,\n",
       "  0.85345063898961604,\n",
       "  0.85299860349915291,\n",
       "  0.85289430510168818,\n",
       "  0.85276966873990345,\n",
       "  0.85220203287334451,\n",
       "  0.85194767434990015,\n",
       "  0.85135742308292262,\n",
       "  0.8509705463568672,\n",
       "  0.85047061601207141,\n",
       "  0.84940519788423674,\n",
       "  0.84898028395322667,\n",
       "  0.84846020908958764,\n",
       "  0.84782553522222659,\n",
       "  0.84753907755854674,\n",
       "  0.84675617320265173,\n",
       "  0.84653603396004817,\n",
       "  0.84649488447582932,\n",
       "  0.84491886923328607,\n",
       "  0.84480653849686393,\n",
       "  0.84459980254950917,\n",
       "  0.84454581612730384,\n",
       "  0.84406094031212042,\n",
       "  0.84262379921827013,\n",
       "  0.84255261257027292,\n",
       "  0.84247749877369138,\n",
       "  0.84225748317093974],\n",
       " 'rmse-stdv': [0.001431982172555931,\n",
       "  0.0021762788645639836,\n",
       "  0.0021252939068458145,\n",
       "  0.0021926140009543844,\n",
       "  0.0024813908756847005,\n",
       "  0.0028844684938161905,\n",
       "  0.0029298836589390738,\n",
       "  0.0033923129809781852,\n",
       "  0.0029508840290484455,\n",
       "  0.0026498561257605377,\n",
       "  0.0027109288154572161,\n",
       "  0.0025114642369174233,\n",
       "  0.0027402846763208088,\n",
       "  0.0028183148724363421,\n",
       "  0.0025178578999301001,\n",
       "  0.0020088468223175742,\n",
       "  0.0019282609433715133,\n",
       "  0.0015130358196991421,\n",
       "  0.0032427909451257664,\n",
       "  0.0032922604471348556,\n",
       "  0.0035194458977569239,\n",
       "  0.0033043996702527621,\n",
       "  0.0033812031683891929,\n",
       "  0.0031244019567349458,\n",
       "  0.0034975259835784054,\n",
       "  0.0034948652596713779,\n",
       "  0.003937137399681644,\n",
       "  0.0041791173933111176,\n",
       "  0.0041873620553599103,\n",
       "  0.0040106457457242733,\n",
       "  0.0037318514219704252,\n",
       "  0.0037270845532078956,\n",
       "  0.0042008953098437093,\n",
       "  0.0043040791174925206,\n",
       "  0.0038384391129980358,\n",
       "  0.0035189460301377736,\n",
       "  0.003526281513925306,\n",
       "  0.0035615619466439589,\n",
       "  0.0036062090190404519,\n",
       "  0.0040670230206458092,\n",
       "  0.0042115718912340517,\n",
       "  0.0040443430554270429,\n",
       "  0.0039692966104777861,\n",
       "  0.0037774323305883309,\n",
       "  0.0039790736188996152,\n",
       "  0.0040140504429877428,\n",
       "  0.0039649976613263275,\n",
       "  0.0040304062395658683,\n",
       "  0.0046385987425945005,\n",
       "  0.0047620349259408622,\n",
       "  0.0047200423933299448,\n",
       "  0.0046580286991690966,\n",
       "  0.0045039150551458183,\n",
       "  0.0040249355908986897,\n",
       "  0.0039090400232389766,\n",
       "  0.0040428487443480337,\n",
       "  0.0038461009831917553,\n",
       "  0.0039751439072673355,\n",
       "  0.0038376509020343944,\n",
       "  0.00381977375834977,\n",
       "  0.0038272713417831909,\n",
       "  0.0037840444702759192,\n",
       "  0.0037925651044931059,\n",
       "  0.0041145817453385209,\n",
       "  0.0042304804096445041,\n",
       "  0.0044742626531306231,\n",
       "  0.0044706961859876772,\n",
       "  0.0041924678918383628,\n",
       "  0.0040072539879495517,\n",
       "  0.0040543148626444817,\n",
       "  0.004330558224182106,\n",
       "  0.0044189308690621319,\n",
       "  0.0044845947673856036,\n",
       "  0.0043861644663879063,\n",
       "  0.0044439057779406942,\n",
       "  0.0046130792384482516,\n",
       "  0.0046024891076002642,\n",
       "  0.0044870320172338907,\n",
       "  0.0046230123569440951,\n",
       "  0.0044943074854219495,\n",
       "  0.0050110908980600267,\n",
       "  0.0050574426672940244,\n",
       "  0.0047752680181100083,\n",
       "  0.00444950789438474,\n",
       "  0.0039562936824529818,\n",
       "  0.0040618094978380967,\n",
       "  0.0035906206750384584,\n",
       "  0.0034008601495972204,\n",
       "  0.0028117664639044637,\n",
       "  0.0028481831049028275,\n",
       "  0.0028315569489742514,\n",
       "  0.0015011118410758789,\n",
       "  0.0015046600923964159,\n",
       "  0.0013566991266477574,\n",
       "  0.0013609862906186095,\n",
       "  0.0013855326158090217,\n",
       "  0.0021811303518057146,\n",
       "  0.0021344832645120268,\n",
       "  0.002075996081727476,\n",
       "  0.0022712302144438116]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84225748317093974"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_cv['rmse-mean'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_objective(params):\n",
    "    ## stolen from :https://github.com/hyperopt/hyperopt/issues/357\n",
    "    lgb_train = lgb.Dataset(X_train,y_train)\n",
    "#     lgb_cv = lgb.Dataset(X_cv,y_cv,reference=lgb_train)\n",
    "    params_set = {\n",
    "        'bossting_type':'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'learning_rate' : 0.2,\n",
    "        'max_depth' : int(params['max_depth']),\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'feature_fraction': '{:.3f}'.format(params['feature_fraction']),\n",
    "#         'bagging_fraction' : '{:.3f}'.format(params['bagging_fraction']),\n",
    "        'reg_lambda' : '{:.3f}'.format(params['reg_lambda']),\n",
    "        'gamma' : '{:.3f}'.format(params['gamma'])        \n",
    "    }\n",
    "    cv = lgb.cv(params_set,\n",
    "                lgb_train,\n",
    "                early_stopping_rounds=5,\n",
    "                verbose_eval=True)\n",
    "\n",
    "    print('params:{}'.format(params))\n",
    "    rmse_best_mean = cv['rmse-mean'][-1]\n",
    "#     rmse_best_std = cv['rmse-std'][-1]\n",
    "    print(\"rmse_mean_best:{:.5f}\".format(rmse_best_mean))\n",
    "    return {'loss':rmse_best_mean, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tcv_agg's rmse: 1.13876 + 0.000676979\n",
      "[2]\tcv_agg's rmse: 1.08564 + 0.00115226\n",
      "[3]\tcv_agg's rmse: 1.04814 + 0.00157905\n",
      "[4]\tcv_agg's rmse: 1.01471 + 0.00176372\n",
      "[5]\tcv_agg's rmse: 0.991152 + 0.00189205\n",
      "[6]\tcv_agg's rmse: 0.976679 + 0.00197484\n",
      "[7]\tcv_agg's rmse: 0.963949 + 0.0020115\n",
      "[8]\tcv_agg's rmse: 0.956396 + 0.00203034\n",
      "[9]\tcv_agg's rmse: 0.949293 + 0.00221109\n",
      "[10]\tcv_agg's rmse: 0.942661 + 0.00234467\n",
      "[11]\tcv_agg's rmse: 0.938496 + 0.00258566\n",
      "[12]\tcv_agg's rmse: 0.93519 + 0.00252524\n",
      "[13]\tcv_agg's rmse: 0.932616 + 0.00238383\n",
      "[14]\tcv_agg's rmse: 0.928105 + 0.00221575\n",
      "[15]\tcv_agg's rmse: 0.925668 + 0.0022476\n",
      "[16]\tcv_agg's rmse: 0.922782 + 0.00214559\n",
      "[17]\tcv_agg's rmse: 0.919523 + 0.00216259\n",
      "[18]\tcv_agg's rmse: 0.917129 + 0.00214855\n",
      "[19]\tcv_agg's rmse: 0.914898 + 0.00243131\n",
      "[20]\tcv_agg's rmse: 0.91365 + 0.00228592\n",
      "[21]\tcv_agg's rmse: 0.912266 + 0.00275061\n",
      "[22]\tcv_agg's rmse: 0.911001 + 0.00285008\n",
      "[23]\tcv_agg's rmse: 0.909703 + 0.00291307\n",
      "[24]\tcv_agg's rmse: 0.908728 + 0.00287276\n",
      "[25]\tcv_agg's rmse: 0.907279 + 0.00349779\n",
      "[26]\tcv_agg's rmse: 0.905969 + 0.00348643\n",
      "[27]\tcv_agg's rmse: 0.904557 + 0.00334367\n",
      "[28]\tcv_agg's rmse: 0.903086 + 0.0032159\n",
      "[29]\tcv_agg's rmse: 0.902253 + 0.0032244\n",
      "[30]\tcv_agg's rmse: 0.901265 + 0.00311829\n",
      "[31]\tcv_agg's rmse: 0.900516 + 0.00307628\n",
      "[32]\tcv_agg's rmse: 0.899691 + 0.003273\n",
      "[33]\tcv_agg's rmse: 0.898825 + 0.00303979\n",
      "[34]\tcv_agg's rmse: 0.897893 + 0.00289611\n",
      "[35]\tcv_agg's rmse: 0.896898 + 0.00288914\n",
      "[36]\tcv_agg's rmse: 0.896052 + 0.00298141\n",
      "[37]\tcv_agg's rmse: 0.894973 + 0.00273368\n",
      "[38]\tcv_agg's rmse: 0.894554 + 0.00268953\n",
      "[39]\tcv_agg's rmse: 0.893399 + 0.00251805\n",
      "[40]\tcv_agg's rmse: 0.892524 + 0.00284138\n",
      "[41]\tcv_agg's rmse: 0.891232 + 0.00256558\n",
      "[42]\tcv_agg's rmse: 0.890457 + 0.00240352\n",
      "[43]\tcv_agg's rmse: 0.889723 + 0.00242393\n",
      "[44]\tcv_agg's rmse: 0.888966 + 0.0026338\n",
      "[45]\tcv_agg's rmse: 0.888106 + 0.00253518\n",
      "[46]\tcv_agg's rmse: 0.887223 + 0.00254863\n",
      "[47]\tcv_agg's rmse: 0.886526 + 0.00273089\n",
      "[48]\tcv_agg's rmse: 0.885998 + 0.0027986\n",
      "[49]\tcv_agg's rmse: 0.884967 + 0.00279319\n",
      "[50]\tcv_agg's rmse: 0.884407 + 0.00267795\n",
      "[51]\tcv_agg's rmse: 0.883837 + 0.00264579\n",
      "[52]\tcv_agg's rmse: 0.883414 + 0.00270893\n",
      "[53]\tcv_agg's rmse: 0.882752 + 0.002797\n",
      "[54]\tcv_agg's rmse: 0.882073 + 0.00283794\n",
      "[55]\tcv_agg's rmse: 0.8818 + 0.00278334\n",
      "[56]\tcv_agg's rmse: 0.881247 + 0.00253451\n",
      "[57]\tcv_agg's rmse: 0.881026 + 0.00257368\n",
      "[58]\tcv_agg's rmse: 0.880246 + 0.00244026\n",
      "[59]\tcv_agg's rmse: 0.8791 + 0.00202169\n",
      "[60]\tcv_agg's rmse: 0.878603 + 0.00202706\n",
      "[61]\tcv_agg's rmse: 0.878219 + 0.00194008\n",
      "[62]\tcv_agg's rmse: 0.877438 + 0.00206394\n",
      "[63]\tcv_agg's rmse: 0.877016 + 0.00212809\n",
      "[64]\tcv_agg's rmse: 0.876412 + 0.00216699\n",
      "[65]\tcv_agg's rmse: 0.875998 + 0.00214768\n",
      "[66]\tcv_agg's rmse: 0.875568 + 0.00217983\n",
      "[67]\tcv_agg's rmse: 0.874983 + 0.00214765\n",
      "[68]\tcv_agg's rmse: 0.874379 + 0.00213897\n",
      "[69]\tcv_agg's rmse: 0.87393 + 0.00215029\n",
      "[70]\tcv_agg's rmse: 0.873707 + 0.00220693\n",
      "[71]\tcv_agg's rmse: 0.873328 + 0.00220641\n",
      "[72]\tcv_agg's rmse: 0.87304 + 0.00212009\n",
      "[73]\tcv_agg's rmse: 0.872578 + 0.00215261\n",
      "[74]\tcv_agg's rmse: 0.872064 + 0.00220952\n",
      "[75]\tcv_agg's rmse: 0.871722 + 0.00226483\n",
      "[76]\tcv_agg's rmse: 0.871327 + 0.00239089\n",
      "[77]\tcv_agg's rmse: 0.871073 + 0.00239732\n",
      "[78]\tcv_agg's rmse: 0.870896 + 0.00237442\n",
      "[79]\tcv_agg's rmse: 0.87022 + 0.00215341\n",
      "[80]\tcv_agg's rmse: 0.869999 + 0.00221753\n",
      "[81]\tcv_agg's rmse: 0.869544 + 0.00231106\n",
      "[82]\tcv_agg's rmse: 0.869176 + 0.00201301\n",
      "[83]\tcv_agg's rmse: 0.868861 + 0.0020471\n",
      "[84]\tcv_agg's rmse: 0.868415 + 0.00218415\n",
      "[85]\tcv_agg's rmse: 0.868098 + 0.00225225\n",
      "[86]\tcv_agg's rmse: 0.867919 + 0.00224531\n",
      "[87]\tcv_agg's rmse: 0.867679 + 0.00222259\n",
      "[88]\tcv_agg's rmse: 0.867383 + 0.00194819\n",
      "[89]\tcv_agg's rmse: 0.867227 + 0.00199459\n",
      "[90]\tcv_agg's rmse: 0.867001 + 0.00195699\n",
      "[91]\tcv_agg's rmse: 0.866775 + 0.00199338\n",
      "[92]\tcv_agg's rmse: 0.86656 + 0.00196999\n",
      "[93]\tcv_agg's rmse: 0.866373 + 0.00198407\n",
      "[94]\tcv_agg's rmse: 0.865984 + 0.00167114\n",
      "[95]\tcv_agg's rmse: 0.865754 + 0.00163717\n",
      "[96]\tcv_agg's rmse: 0.865584 + 0.00163506\n",
      "[97]\tcv_agg's rmse: 0.865283 + 0.00163318\n",
      "[98]\tcv_agg's rmse: 0.865069 + 0.00161503\n",
      "[99]\tcv_agg's rmse: 0.864886 + 0.00160063\n",
      "[100]\tcv_agg's rmse: 0.864619 + 0.00163568\n",
      "params:{'feature_fraction': 0.5442418911287341, 'gamma': 0.46198691535451775, 'max_depth': 9.0, 'num_leaves': 66.0, 'reg_lambda': 0.3835023683713793}\n",
      "rmse_mean_best:0.86462\n",
      "[1]\tcv_agg's rmse: 1.13342 + 0.00063934\n",
      "[2]\tcv_agg's rmse: 1.07033 + 0.00107568\n",
      "[3]\tcv_agg's rmse: 1.02654 + 0.00136069\n",
      "[4]\tcv_agg's rmse: 0.99611 + 0.00146846\n",
      "[5]\tcv_agg's rmse: 0.974037 + 0.00147037\n",
      "[6]\tcv_agg's rmse: 0.958208 + 0.00158277\n",
      "[7]\tcv_agg's rmse: 0.947303 + 0.00151043\n",
      "[8]\tcv_agg's rmse: 0.938275 + 0.00131996\n",
      "[9]\tcv_agg's rmse: 0.931717 + 0.00147415\n",
      "[10]\tcv_agg's rmse: 0.926207 + 0.00141846\n",
      "[11]\tcv_agg's rmse: 0.922197 + 0.0013809\n",
      "[12]\tcv_agg's rmse: 0.91825 + 0.00114753\n",
      "[13]\tcv_agg's rmse: 0.914711 + 0.00138536\n",
      "[14]\tcv_agg's rmse: 0.911456 + 0.00127126\n",
      "[15]\tcv_agg's rmse: 0.908477 + 0.00139446\n",
      "[16]\tcv_agg's rmse: 0.905965 + 0.00154066\n",
      "[17]\tcv_agg's rmse: 0.903547 + 0.00161843\n",
      "[18]\tcv_agg's rmse: 0.901346 + 0.0017956\n",
      "[19]\tcv_agg's rmse: 0.899328 + 0.00142466\n",
      "[20]\tcv_agg's rmse: 0.897417 + 0.00105293\n",
      "[21]\tcv_agg's rmse: 0.896044 + 0.00156328\n",
      "[22]\tcv_agg's rmse: 0.894565 + 0.00156769\n",
      "[23]\tcv_agg's rmse: 0.893177 + 0.00158862\n",
      "[24]\tcv_agg's rmse: 0.892062 + 0.00154669\n",
      "[25]\tcv_agg's rmse: 0.891084 + 0.00150279\n",
      "[26]\tcv_agg's rmse: 0.889999 + 0.00144152\n",
      "[27]\tcv_agg's rmse: 0.888773 + 0.00126172\n",
      "[28]\tcv_agg's rmse: 0.887342 + 0.00144963\n",
      "[29]\tcv_agg's rmse: 0.886367 + 0.00130883\n",
      "[30]\tcv_agg's rmse: 0.885247 + 0.00116433\n",
      "[31]\tcv_agg's rmse: 0.884244 + 0.00131262\n",
      "[32]\tcv_agg's rmse: 0.883367 + 0.00117401\n",
      "[33]\tcv_agg's rmse: 0.882565 + 0.00119904\n",
      "[34]\tcv_agg's rmse: 0.881947 + 0.00122206\n",
      "[35]\tcv_agg's rmse: 0.881338 + 0.00120684\n",
      "[36]\tcv_agg's rmse: 0.880428 + 0.00149055\n",
      "[37]\tcv_agg's rmse: 0.879379 + 0.00160713\n",
      "[38]\tcv_agg's rmse: 0.878802 + 0.00168163\n",
      "[39]\tcv_agg's rmse: 0.878287 + 0.00171511\n",
      "[40]\tcv_agg's rmse: 0.877602 + 0.0017684\n",
      "[41]\tcv_agg's rmse: 0.87694 + 0.00174415\n",
      "[42]\tcv_agg's rmse: 0.875791 + 0.00154288\n",
      "[43]\tcv_agg's rmse: 0.875467 + 0.00150001\n",
      "[44]\tcv_agg's rmse: 0.874768 + 0.00171332\n",
      "[45]\tcv_agg's rmse: 0.873686 + 0.00211083\n",
      "[46]\tcv_agg's rmse: 0.87305 + 0.00200013\n",
      "[47]\tcv_agg's rmse: 0.8725 + 0.00225009\n",
      "[48]\tcv_agg's rmse: 0.871429 + 0.00196541\n",
      "[49]\tcv_agg's rmse: 0.87051 + 0.00173617\n",
      "[50]\tcv_agg's rmse: 0.870106 + 0.00168601\n",
      "[51]\tcv_agg's rmse: 0.869389 + 0.0015852\n",
      "[52]\tcv_agg's rmse: 0.869018 + 0.00178086\n",
      "[53]\tcv_agg's rmse: 0.868382 + 0.00157665\n",
      "[54]\tcv_agg's rmse: 0.867648 + 0.00157276\n",
      "[55]\tcv_agg's rmse: 0.867111 + 0.00128462\n",
      "[56]\tcv_agg's rmse: 0.866227 + 0.00147988\n",
      "[57]\tcv_agg's rmse: 0.865839 + 0.00135015\n",
      "[58]\tcv_agg's rmse: 0.865183 + 0.00116985\n",
      "[59]\tcv_agg's rmse: 0.864773 + 0.00112161\n",
      "[60]\tcv_agg's rmse: 0.863826 + 0.00225726\n",
      "[61]\tcv_agg's rmse: 0.863371 + 0.00212221\n",
      "[62]\tcv_agg's rmse: 0.862996 + 0.00209736\n",
      "[63]\tcv_agg's rmse: 0.862388 + 0.0020968\n",
      "[64]\tcv_agg's rmse: 0.861767 + 0.00251308\n",
      "[65]\tcv_agg's rmse: 0.861383 + 0.00255026\n",
      "[66]\tcv_agg's rmse: 0.860063 + 0.00281431\n",
      "[67]\tcv_agg's rmse: 0.859562 + 0.00293455\n",
      "[68]\tcv_agg's rmse: 0.859026 + 0.00307636\n",
      "[69]\tcv_agg's rmse: 0.858806 + 0.00303781\n",
      "[70]\tcv_agg's rmse: 0.858316 + 0.00292897\n",
      "[71]\tcv_agg's rmse: 0.857887 + 0.0028627\n",
      "[72]\tcv_agg's rmse: 0.85762 + 0.00294308\n",
      "[73]\tcv_agg's rmse: 0.85743 + 0.0028849\n",
      "[74]\tcv_agg's rmse: 0.857051 + 0.00277152\n",
      "[75]\tcv_agg's rmse: 0.856538 + 0.00270513\n",
      "[76]\tcv_agg's rmse: 0.856214 + 0.00274889\n",
      "[77]\tcv_agg's rmse: 0.855916 + 0.00272178\n",
      "[78]\tcv_agg's rmse: 0.855681 + 0.00275868\n",
      "[79]\tcv_agg's rmse: 0.854874 + 0.00267939\n",
      "[80]\tcv_agg's rmse: 0.854742 + 0.00265126\n",
      "[81]\tcv_agg's rmse: 0.854553 + 0.00263198\n",
      "[82]\tcv_agg's rmse: 0.854223 + 0.0026909\n",
      "[83]\tcv_agg's rmse: 0.853917 + 0.00262224\n",
      "[84]\tcv_agg's rmse: 0.853407 + 0.0024148\n",
      "[85]\tcv_agg's rmse: 0.853182 + 0.00245303\n",
      "[86]\tcv_agg's rmse: 0.853049 + 0.00241045\n",
      "[87]\tcv_agg's rmse: 0.85264 + 0.00253489\n",
      "[88]\tcv_agg's rmse: 0.852226 + 0.00260055\n",
      "[89]\tcv_agg's rmse: 0.851975 + 0.00260889\n",
      "[90]\tcv_agg's rmse: 0.851308 + 0.00217913\n",
      "[91]\tcv_agg's rmse: 0.850927 + 0.00220627\n",
      "[92]\tcv_agg's rmse: 0.850599 + 0.0024942\n",
      "[93]\tcv_agg's rmse: 0.850311 + 0.00254187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94]\tcv_agg's rmse: 0.849143 + 0.00207078\n",
      "[95]\tcv_agg's rmse: 0.849016 + 0.00201142\n",
      "[96]\tcv_agg's rmse: 0.848733 + 0.0022129\n",
      "[97]\tcv_agg's rmse: 0.848509 + 0.00210078\n",
      "[98]\tcv_agg's rmse: 0.847845 + 0.00213655\n",
      "[99]\tcv_agg's rmse: 0.847366 + 0.00229821\n",
      "[100]\tcv_agg's rmse: 0.84709 + 0.00224333\n",
      "params:{'feature_fraction': 0.8978024800556195, 'gamma': 0.4421742402175145, 'max_depth': 10.0, 'num_leaves': 120.0, 'reg_lambda': 0.2741790624991707}\n",
      "rmse_mean_best:0.84709\n",
      "[1]\tcv_agg's rmse: 1.14015 + 0.000603661\n",
      "[2]\tcv_agg's rmse: 1.0844 + 0.00101019\n",
      "[3]\tcv_agg's rmse: 1.04511 + 0.00141809\n",
      "[4]\tcv_agg's rmse: 1.02052 + 0.00145112\n",
      "[5]\tcv_agg's rmse: 0.994775 + 0.00170994\n",
      "[6]\tcv_agg's rmse: 0.981066 + 0.00182888\n",
      "[7]\tcv_agg's rmse: 0.963231 + 0.00197232\n",
      "[8]\tcv_agg's rmse: 0.956099 + 0.0021206\n",
      "[9]\tcv_agg's rmse: 0.94569 + 0.00214409\n",
      "[10]\tcv_agg's rmse: 0.941714 + 0.00221676\n",
      "[11]\tcv_agg's rmse: 0.935787 + 0.0022997\n",
      "[12]\tcv_agg's rmse: 0.931413 + 0.00221757\n",
      "[13]\tcv_agg's rmse: 0.928059 + 0.00227857\n",
      "[14]\tcv_agg's rmse: 0.924602 + 0.00229428\n",
      "[15]\tcv_agg's rmse: 0.921513 + 0.00237287\n",
      "[16]\tcv_agg's rmse: 0.914726 + 0.00226952\n",
      "[17]\tcv_agg's rmse: 0.910258 + 0.0020122\n",
      "[18]\tcv_agg's rmse: 0.906226 + 0.00192347\n",
      "[19]\tcv_agg's rmse: 0.90218 + 0.00192392\n",
      "[20]\tcv_agg's rmse: 0.900245 + 0.00206126\n",
      "[21]\tcv_agg's rmse: 0.897872 + 0.00196484\n",
      "[22]\tcv_agg's rmse: 0.895427 + 0.00229233\n",
      "[23]\tcv_agg's rmse: 0.891526 + 0.00215555\n",
      "[24]\tcv_agg's rmse: 0.89042 + 0.00212536\n",
      "[25]\tcv_agg's rmse: 0.88885 + 0.00221743\n",
      "[26]\tcv_agg's rmse: 0.887066 + 0.00226799\n",
      "[27]\tcv_agg's rmse: 0.885853 + 0.00222706\n",
      "[28]\tcv_agg's rmse: 0.883606 + 0.00200095\n",
      "[29]\tcv_agg's rmse: 0.882647 + 0.00207742\n",
      "[30]\tcv_agg's rmse: 0.880922 + 0.00219637\n",
      "[31]\tcv_agg's rmse: 0.8802 + 0.0021979\n",
      "[32]\tcv_agg's rmse: 0.879691 + 0.00218733\n",
      "[33]\tcv_agg's rmse: 0.878533 + 0.00219092\n",
      "[34]\tcv_agg's rmse: 0.877495 + 0.00217026\n",
      "[35]\tcv_agg's rmse: 0.877019 + 0.00215115\n",
      "[36]\tcv_agg's rmse: 0.876441 + 0.00217766\n",
      "[37]\tcv_agg's rmse: 0.873965 + 0.00212486\n",
      "[38]\tcv_agg's rmse: 0.873285 + 0.00220212\n",
      "[39]\tcv_agg's rmse: 0.871815 + 0.00217015\n",
      "[40]\tcv_agg's rmse: 0.870936 + 0.00211804\n",
      "[41]\tcv_agg's rmse: 0.869977 + 0.00202879\n",
      "[42]\tcv_agg's rmse: 0.868849 + 0.00207386\n",
      "[43]\tcv_agg's rmse: 0.868152 + 0.00203106\n",
      "[44]\tcv_agg's rmse: 0.867056 + 0.00203726\n",
      "[45]\tcv_agg's rmse: 0.866004 + 0.00202094\n",
      "[46]\tcv_agg's rmse: 0.864518 + 0.00211259\n",
      "[47]\tcv_agg's rmse: 0.863755 + 0.00204526\n",
      "[48]\tcv_agg's rmse: 0.863429 + 0.00199601\n",
      "[49]\tcv_agg's rmse: 0.86292 + 0.0019809\n",
      "[50]\tcv_agg's rmse: 0.862249 + 0.00188445\n",
      "[51]\tcv_agg's rmse: 0.861819 + 0.00177758\n",
      "[52]\tcv_agg's rmse: 0.861255 + 0.00177679\n",
      "[53]\tcv_agg's rmse: 0.860659 + 0.00176417\n",
      "[54]\tcv_agg's rmse: 0.86018 + 0.00175465\n",
      "[55]\tcv_agg's rmse: 0.859893 + 0.00176535\n",
      "[56]\tcv_agg's rmse: 0.859359 + 0.0016919\n",
      "[57]\tcv_agg's rmse: 0.858957 + 0.00165193\n",
      "[58]\tcv_agg's rmse: 0.858711 + 0.001547\n",
      "[59]\tcv_agg's rmse: 0.857774 + 0.00177612\n",
      "[60]\tcv_agg's rmse: 0.857521 + 0.00169149\n",
      "[61]\tcv_agg's rmse: 0.857314 + 0.00169673\n",
      "[62]\tcv_agg's rmse: 0.856733 + 0.00183333\n",
      "[63]\tcv_agg's rmse: 0.856519 + 0.00183279\n",
      "[64]\tcv_agg's rmse: 0.855822 + 0.00179418\n",
      "[65]\tcv_agg's rmse: 0.855342 + 0.00185178\n",
      "[66]\tcv_agg's rmse: 0.854964 + 0.00189145\n",
      "[67]\tcv_agg's rmse: 0.854384 + 0.00179665\n",
      "[68]\tcv_agg's rmse: 0.853208 + 0.00157743\n",
      "[69]\tcv_agg's rmse: 0.85279 + 0.00160944\n",
      "[70]\tcv_agg's rmse: 0.852638 + 0.00161835\n",
      "[71]\tcv_agg's rmse: 0.852209 + 0.00161944\n",
      "[72]\tcv_agg's rmse: 0.851777 + 0.00163304\n",
      "[73]\tcv_agg's rmse: 0.851382 + 0.00163083\n",
      "[74]\tcv_agg's rmse: 0.851054 + 0.00168079\n",
      "[75]\tcv_agg's rmse: 0.850791 + 0.00167089\n",
      "[76]\tcv_agg's rmse: 0.850249 + 0.00175682\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-c7c56dc995b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mtrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             max_evals=10)\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         )\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    318\u001b[0m                     verbose=verbose)\n\u001b[0;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-45af88855beb>\u001b[0m in \u001b[0;36mlgbm_objective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mlgb_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 verbose_eval=True)\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'params:{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks)\u001b[0m\n\u001b[0;32m    445\u001b[0m                                     \u001b[0mend_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m--> 447\u001b[1;33m         \u001b[0mcvfolds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_agg_cv_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mhandlerFunction\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbooster\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboosters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m                 \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandlerFunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1519\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1521\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lgbm_space = { \n",
    "    'max_depth' : hp.quniform(\"max_depth\", 4, 16, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 8, 128, 2),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.3, 1.0),\n",
    "#     'bagging_fraction': hp.uniform ('bagging_fraction', 0.7, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda',0,1),\n",
    "    'gamma' : hp.uniform('gamma', 0.1,0.5),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "lgbm_best = fmin(fn=lgbm_objective,\n",
    "            space=lgbm_space,\n",
    "            algo=tpe.suggest,\n",
    "            trials = trials,\n",
    "            max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_best['num_leaves'] = int(lgbm_best['num_leaves'])\n",
    "lgbm_best['max_depth'] = int(lgbm_best['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.87143992494405,\n",
       " 'feature_fraction': 0.9515360120106497,\n",
       " 'gamma': 0.49541466113602695,\n",
       " 'max_depth': 16,\n",
       " 'num_leaves': 110,\n",
       " 'reg_lambda': 0.1649307254568939}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book_time': datetime.datetime(2018, 2, 13, 7, 11, 32, 9000),\n",
       " 'exp_key': None,\n",
       " 'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'idxs': {'bagging_fraction': [95],\n",
       "   'feature_fraction': [95],\n",
       "   'gamma': [95],\n",
       "   'max_depth': [95],\n",
       "   'num_leaves': [95],\n",
       "   'reg_lambda': [95]},\n",
       "  'tid': 95,\n",
       "  'vals': {'bagging_fraction': [0.87143992494405],\n",
       "   'feature_fraction': [0.9515360120106497],\n",
       "   'gamma': [0.49541466113602695],\n",
       "   'max_depth': [16.0],\n",
       "   'num_leaves': [110.0],\n",
       "   'reg_lambda': [0.1649307254568939]},\n",
       "  'workdir': None},\n",
       " 'owner': None,\n",
       " 'refresh_time': datetime.datetime(2018, 2, 13, 7, 14, 18, 477000),\n",
       " 'result': {'loss': 0.8149392926296526, 'status': 'ok'},\n",
       " 'spec': None,\n",
       " 'state': 2,\n",
       " 'tid': 95,\n",
       " 'version': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(max_train_size=None, n_splits=3)\n",
      "TRAIN: [0] TEST: [1]\n",
      "TRAIN: [0 1] TEST: [2]\n",
      "TRAIN: [0 1 2] TEST: [3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "print(tscv)  \n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = X_train.head(1000)\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (170, 54)\n",
      "train shape: (336, 54)\n",
      "train shape: (502, 54)\n",
      "train shape: (668, 54)\n",
      "train shape: (834, 54)\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in tscv.split(temp_df,groups=temp_df.date_block_num):\n",
    "    print('train shape:',temp_df.iloc[train_index].shape)\n",
    "#     print('test shape:',temp_df.iloc[test_index].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_name = list(X_train.columns)\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',    \n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5\n",
    "#     'verbose': 0\n",
    "#     'feature_name' : feature_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lgb_train = lgb.Dataset(X_train,y_train)\n",
    "def train_lgbm(X_train,y_train,params,cv_splits=5):\n",
    "    tscv = TimeSeriesSplit(n_splits = cv_splits)\n",
    "    lgbm = lgb.LGBMRegressor(**params)\n",
    "    model_eval = []\n",
    "    ii = 0\n",
    "    for train_idx, test_idx in tscv.split(X_train):\n",
    "        ii += 1\n",
    "        lgbm.fit(X_train.iloc[train_idx], y_train.iloc[train_idx],                \n",
    "                 eval_metric='l2',eval_set=[(X_train.iloc[test_idx],y_train.iloc[test_idx])],verbose=False)\n",
    "        print('{} folds, loss:{:.4f}'.format(ii, lgbm.best_score_['valid_0']['l2']))\n",
    "        model_eval.append(lgbm.best_score_['valid_0']['l2'])\n",
    "    loss_mean, loss_std = np.mean(model_eval), np.std(model_eval)\n",
    "    \n",
    "    print('mean:{:.4f} + {:.4f}'.format(loss_mean,loss_std))\n",
    "#     print('====================')\n",
    "    return model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 folds, loss:0.8325\n",
      "2 folds, loss:1.0198\n",
      "3 folds, loss:0.6495\n",
      "4 folds, loss:0.9993\n",
      "5 folds, loss:0.6753\n",
      "mean:0.8353 + 0.1556\n"
     ]
    }
   ],
   "source": [
    "model_eval = train_lgbm(X_train,y_train,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.83252872914602716,\n",
       " 1.0197854446450194,\n",
       " 0.64945661679877431,\n",
       " 0.9993193574787691,\n",
       " 0.67527629594972116]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprintint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_objective(params):\n",
    "    ## stolen from :https://github.com/hyperopt/hyperopt/issues/357    \n",
    "    params_set = {\n",
    "        'bossting_type':'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'learning_rate' : 0.2,         \n",
    "        'max_depth' : int(params['max_depth']),\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'feature_fraction': '{:.3f}'.format(params['feature_fraction']),\n",
    "#         'bagging_fraction' : '{:.3f}'.format(params['bagging_fraction']),\n",
    "        'reg_lambda' : '{:.3f}'.format(params['reg_lambda']),\n",
    "        'gamma' : '{:.3f}'.format(params['gamma'])        \n",
    "    }\n",
    "    \n",
    "    evals = train_lgbm(X_train,y_train,params_set,cv_splits=5) # time series cv l2 loss \n",
    "    \n",
    "    print('params:{}'.format(params))\n",
    "    print('====================')\n",
    "    rmse_mean = np.mean(evals)\n",
    "    std = np.std(evals)    \n",
    "    return {'loss':rmse_mean, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 folds, loss:0.8175\n",
      "2 folds, loss:1.0248\n",
      "3 folds, loss:0.6379\n",
      "4 folds, loss:1.0050\n",
      "5 folds, loss:0.6633\n",
      "mean:0.8297 + 0.1633\n",
      "params:{'feature_fraction': 0.8699990722356254, 'gamma': 0.22151693358752042, 'max_depth': 7.0, 'num_leaves': 48.0, 'reg_lambda': 0.9105037577316176}\n",
      "====================\n",
      "1 folds, loss:0.8234\n",
      "2 folds, loss:1.0235\n",
      "3 folds, loss:0.6416\n",
      "4 folds, loss:0.9985\n",
      "5 folds, loss:0.6655\n",
      "mean:0.8305 + 0.1603\n",
      "params:{'feature_fraction': 0.4904258447845349, 'gamma': 0.3400007853551891, 'max_depth': 6.0, 'num_leaves': 110.0, 'reg_lambda': 0.5789469135590799}\n",
      "====================\n",
      "1 folds, loss:0.8180\n",
      "2 folds, loss:1.0155\n",
      "3 folds, loss:0.6375\n",
      "4 folds, loss:0.9929\n",
      "5 folds, loss:0.6607\n",
      "mean:0.8249 + 0.1591\n",
      "params:{'feature_fraction': 0.8316086619931005, 'gamma': 0.4010901097955395, 'max_depth': 7.0, 'num_leaves': 102.0, 'reg_lambda': 0.41849126195620734}\n",
      "====================\n",
      "1 folds, loss:0.8382\n",
      "2 folds, loss:1.0169\n",
      "3 folds, loss:0.6417\n",
      "4 folds, loss:0.9907\n",
      "5 folds, loss:0.6608\n",
      "mean:0.8297 + 0.1581\n",
      "params:{'feature_fraction': 0.9632833797772626, 'gamma': 0.17065806772175965, 'max_depth': 12.0, 'num_leaves': 108.0, 'reg_lambda': 0.8941219351643181}\n",
      "====================\n",
      "1 folds, loss:0.8329\n",
      "2 folds, loss:1.0307\n",
      "3 folds, loss:0.6440\n",
      "4 folds, loss:1.0018\n",
      "5 folds, loss:0.6669\n",
      "mean:0.8352 + 0.1618\n",
      "params:{'feature_fraction': 0.3357742058814762, 'gamma': 0.32484127809141694, 'max_depth': 6.0, 'num_leaves': 74.0, 'reg_lambda': 0.5215327837445524}\n",
      "====================\n",
      "1 folds, loss:0.8294\n",
      "2 folds, loss:1.0298\n",
      "3 folds, loss:0.6431\n",
      "4 folds, loss:0.9963\n",
      "5 folds, loss:0.6710\n",
      "mean:0.8339 + 0.1598\n",
      "params:{'feature_fraction': 0.5943560625032315, 'gamma': 0.20285193483998862, 'max_depth': 7.0, 'num_leaves': 32.0, 'reg_lambda': 0.8215385759441853}\n",
      "====================\n",
      "1 folds, loss:0.8399\n",
      "2 folds, loss:1.0368\n",
      "3 folds, loss:0.6591\n",
      "4 folds, loss:1.0190\n",
      "5 folds, loss:0.6803\n",
      "mean:0.8470 + 0.1605\n",
      "params:{'feature_fraction': 0.7264375232824376, 'gamma': 0.1685638468485155, 'max_depth': 4.0, 'num_leaves': 24.0, 'reg_lambda': 0.05033366372561887}\n",
      "====================\n",
      "1 folds, loss:0.8226\n",
      "2 folds, loss:1.0278\n",
      "3 folds, loss:0.6396\n",
      "4 folds, loss:0.9991\n",
      "5 folds, loss:0.6638\n",
      "mean:0.8306 + 0.1623\n",
      "params:{'feature_fraction': 0.969761814038838, 'gamma': 0.46558269651977136, 'max_depth': 16.0, 'num_leaves': 54.0, 'reg_lambda': 0.7229964858174411}\n",
      "====================\n",
      "1 folds, loss:0.8275\n",
      "2 folds, loss:1.0371\n",
      "3 folds, loss:0.6470\n",
      "4 folds, loss:1.0144\n",
      "5 folds, loss:0.6720\n",
      "mean:0.8396 + 0.1642\n",
      "params:{'feature_fraction': 0.4711852814610651, 'gamma': 0.4164072524647606, 'max_depth': 5.0, 'num_leaves': 56.0, 'reg_lambda': 0.626260285435774}\n",
      "====================\n",
      "1 folds, loss:0.8198\n",
      "2 folds, loss:1.0251\n",
      "3 folds, loss:0.6456\n",
      "4 folds, loss:1.0088\n",
      "5 folds, loss:0.6638\n",
      "mean:0.8326 + 0.1623\n",
      "params:{'feature_fraction': 0.5063879650676978, 'gamma': 0.13119804780228084, 'max_depth': 8.0, 'num_leaves': 90.0, 'reg_lambda': 0.11141961912782461}\n",
      "====================\n",
      "1 folds, loss:0.8222\n",
      "2 folds, loss:1.0086\n",
      "3 folds, loss:0.6537\n",
      "4 folds, loss:1.0076\n",
      "5 folds, loss:0.6627\n",
      "mean:0.8310 + 0.1566\n",
      "params:{'feature_fraction': 0.9091261707193115, 'gamma': 0.13283795415756008, 'max_depth': 9.0, 'num_leaves': 94.0, 'reg_lambda': 0.7036009966028578}\n",
      "====================\n",
      "1 folds, loss:0.8191\n",
      "2 folds, loss:1.0281\n",
      "3 folds, loss:0.6554\n",
      "4 folds, loss:0.9870\n",
      "5 folds, loss:0.6601\n",
      "mean:0.8299 + 0.1571\n",
      "params:{'feature_fraction': 0.7627986213654505, 'gamma': 0.26153250571025843, 'max_depth': 10.0, 'num_leaves': 122.0, 'reg_lambda': 0.5869167987153744}\n",
      "====================\n",
      "1 folds, loss:0.8212\n",
      "2 folds, loss:1.0081\n",
      "3 folds, loss:0.6546\n",
      "4 folds, loss:0.9876\n",
      "5 folds, loss:0.6604\n",
      "mean:0.8264 + 0.1524\n",
      "params:{'feature_fraction': 0.9382036513132572, 'gamma': 0.1968603056609176, 'max_depth': 13.0, 'num_leaves': 66.0, 'reg_lambda': 0.5387122724533695}\n",
      "====================\n",
      "1 folds, loss:0.8347\n",
      "2 folds, loss:1.0290\n",
      "3 folds, loss:0.6539\n",
      "4 folds, loss:0.9860\n",
      "5 folds, loss:0.6575\n",
      "mean:0.8322 + 0.1579\n",
      "params:{'feature_fraction': 0.4257576784404963, 'gamma': 0.4965563644127474, 'max_depth': 14.0, 'num_leaves': 114.0, 'reg_lambda': 0.09758514589774048}\n",
      "====================\n",
      "1 folds, loss:0.8336\n",
      "2 folds, loss:1.0298\n",
      "3 folds, loss:0.6328\n",
      "4 folds, loss:0.9845\n",
      "5 folds, loss:0.6580\n",
      "mean:0.8278 + 0.1626\n",
      "params:{'feature_fraction': 0.6335594339860372, 'gamma': 0.2890425458466884, 'max_depth': 13.0, 'num_leaves': 124.0, 'reg_lambda': 0.10424477112398312}\n",
      "====================\n",
      "1 folds, loss:0.8355\n",
      "2 folds, loss:1.0254\n",
      "3 folds, loss:0.6410\n",
      "4 folds, loss:0.9787\n",
      "5 folds, loss:0.6585\n",
      "mean:0.8278 + 0.1584\n",
      "params:{'feature_fraction': 0.5237725002056183, 'gamma': 0.274276360534633, 'max_depth': 15.0, 'num_leaves': 118.0, 'reg_lambda': 0.9400281049377188}\n",
      "====================\n",
      "1 folds, loss:0.8310\n",
      "2 folds, loss:1.0258\n",
      "3 folds, loss:0.6414\n",
      "4 folds, loss:1.0051\n",
      "5 folds, loss:0.6729\n",
      "mean:0.8352 + 0.1607\n",
      "params:{'feature_fraction': 0.8879734872526639, 'gamma': 0.3033252135031652, 'max_depth': 11.0, 'num_leaves': 12.0, 'reg_lambda': 0.6469131702680603}\n",
      "====================\n",
      "1 folds, loss:0.8239\n",
      "2 folds, loss:1.0197\n",
      "3 folds, loss:0.6443\n",
      "4 folds, loss:0.9877\n",
      "5 folds, loss:0.6588\n",
      "mean:0.8269 + 0.1579\n",
      "params:{'feature_fraction': 0.5992173103324148, 'gamma': 0.31015878026758326, 'max_depth': 14.0, 'num_leaves': 114.0, 'reg_lambda': 0.1830774051351982}\n",
      "====================\n",
      "1 folds, loss:0.8271\n",
      "2 folds, loss:1.0179\n",
      "3 folds, loss:0.6520\n",
      "4 folds, loss:0.9977\n",
      "5 folds, loss:0.6660\n",
      "mean:0.8322 + 0.1562\n",
      "params:{'feature_fraction': 0.4080559384231952, 'gamma': 0.22208485244493034, 'max_depth': 9.0, 'num_leaves': 44.0, 'reg_lambda': 0.5979585012936148}\n",
      "====================\n",
      "1 folds, loss:0.8248\n",
      "2 folds, loss:1.0159\n",
      "3 folds, loss:0.6497\n",
      "4 folds, loss:0.9860\n",
      "5 folds, loss:0.6626\n",
      "mean:0.8278 + 0.1546\n",
      "params:{'feature_fraction': 0.5965687741672636, 'gamma': 0.48606171208593196, 'max_depth': 11.0, 'num_leaves': 74.0, 'reg_lambda': 0.16701927726260757}\n",
      "====================\n",
      "1 folds, loss:0.8275\n",
      "2 folds, loss:1.0278\n",
      "3 folds, loss:0.6446\n",
      "4 folds, loss:0.9890\n",
      "5 folds, loss:0.6595\n",
      "mean:0.8297 + 0.1599\n",
      "params:{'feature_fraction': 0.7883305400317739, 'gamma': 0.37215550773508244, 'max_depth': 12.0, 'num_leaves': 88.0, 'reg_lambda': 0.3146963017639722}\n",
      "====================\n",
      "1 folds, loss:0.8299\n",
      "2 folds, loss:1.0075\n",
      "3 folds, loss:0.6403\n",
      "4 folds, loss:0.9877\n",
      "5 folds, loss:0.6643\n",
      "mean:0.8259 + 0.1547\n",
      "params:{'feature_fraction': 0.8256227930487346, 'gamma': 0.4270634817303617, 'max_depth': 16.0, 'num_leaves': 66.0, 'reg_lambda': 0.3348816527576097}\n",
      "====================\n",
      "1 folds, loss:0.8345\n",
      "2 folds, loss:1.0336\n",
      "3 folds, loss:0.6552\n",
      "4 folds, loss:1.0241\n",
      "5 folds, loss:0.6817\n",
      "mean:0.8458 + 0.1615\n",
      "params:{'feature_fraction': 0.8308533667037827, 'gamma': 0.42916598167773884, 'max_depth': 4.0, 'num_leaves': 100.0, 'reg_lambda': 0.3772232472525474}\n",
      "====================\n",
      "1 folds, loss:0.8157\n",
      "2 folds, loss:1.0205\n",
      "3 folds, loss:0.6390\n",
      "4 folds, loss:1.0030\n",
      "5 folds, loss:0.6631\n",
      "mean:0.8283 + 0.1617\n",
      "params:{'feature_fraction': 0.70436309726349, 'gamma': 0.39135105324533226, 'max_depth': 8.0, 'num_leaves': 80.0, 'reg_lambda': 0.40894749858348384}\n",
      "====================\n",
      "1 folds, loss:0.8244\n",
      "2 folds, loss:0.9984\n",
      "3 folds, loss:0.6446\n",
      "4 folds, loss:0.9853\n",
      "5 folds, loss:0.6579\n",
      "mean:0.8221 + 0.1524\n",
      "params:{'feature_fraction': 0.8193245800572152, 'gamma': 0.451373461314437, 'max_depth': 16.0, 'num_leaves': 64.0, 'reg_lambda': 0.2767722852917748}\n",
      "====================\n",
      "1 folds, loss:0.8299\n",
      "2 folds, loss:1.0291\n",
      "3 folds, loss:0.6495\n",
      "4 folds, loss:0.9991\n",
      "5 folds, loss:0.6759\n",
      "mean:0.8367 + 0.1577\n",
      "params:{'feature_fraction': 0.6846669621367238, 'gamma': 0.4590889676140279, 'max_depth': 5.0, 'num_leaves': 100.0, 'reg_lambda': 0.2658225268801211}\n",
      "====================\n",
      "1 folds, loss:0.8203\n",
      "2 folds, loss:1.0332\n",
      "3 folds, loss:0.6408\n",
      "4 folds, loss:1.0015\n",
      "5 folds, loss:0.6653\n",
      "mean:0.8322 + 0.1635\n",
      "params:{'feature_fraction': 0.7721341089098503, 'gamma': 0.3494855707039555, 'max_depth': 9.0, 'num_leaves': 82.0, 'reg_lambda': 0.43492758378281066}\n",
      "====================\n",
      "1 folds, loss:0.8178\n",
      "2 folds, loss:1.0268\n",
      "3 folds, loss:0.6373\n",
      "4 folds, loss:0.9983\n",
      "5 folds, loss:0.6641\n",
      "mean:0.8289 + 0.1624\n",
      "params:{'feature_fraction': 0.8307240957032537, 'gamma': 0.3954811903993902, 'max_depth': 7.0, 'num_leaves': 34.0, 'reg_lambda': 0.23020867199019232}\n",
      "====================\n",
      "1 folds, loss:0.8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 folds, loss:1.0303\n",
      "3 folds, loss:0.6401\n",
      "4 folds, loss:0.9955\n",
      "5 folds, loss:0.6703\n",
      "mean:0.8313 + 0.1607\n",
      "params:{'feature_fraction': 0.8789156750134186, 'gamma': 0.4576720076877544, 'max_depth': 6.0, 'num_leaves': 58.0, 'reg_lambda': 0.4710828735730814}\n",
      "====================\n",
      "1 folds, loss:0.8201\n",
      "2 folds, loss:1.0212\n",
      "3 folds, loss:0.6437\n",
      "4 folds, loss:0.9999\n",
      "5 folds, loss:0.6651\n",
      "mean:0.8300 + 0.1596\n",
      "params:{'feature_fraction': 0.9819168881328044, 'gamma': 0.36299824444784956, 'max_depth': 8.0, 'num_leaves': 42.0, 'reg_lambda': 0.2837953157818128}\n",
      "====================\n",
      "1 folds, loss:0.8333\n",
      "2 folds, loss:1.0214\n",
      "3 folds, loss:0.6418\n",
      "4 folds, loss:1.0065\n",
      "5 folds, loss:0.6642\n",
      "mean:0.8335 + 0.1616\n",
      "params:{'feature_fraction': 0.6732018390114148, 'gamma': 0.3967449115682945, 'max_depth': 10.0, 'num_leaves': 72.0, 'reg_lambda': 0.0023809007427819107}\n",
      "====================\n",
      "1 folds, loss:0.8237\n",
      "2 folds, loss:1.0270\n",
      "3 folds, loss:0.6486\n",
      "4 folds, loss:1.0057\n",
      "5 folds, loss:0.6728\n",
      "mean:0.8356 + 0.1595\n",
      "params:{'feature_fraction': 0.8059873350339093, 'gamma': 0.4827040577669618, 'max_depth': 5.0, 'num_leaves': 104.0, 'reg_lambda': 0.3614880004550574}\n",
      "====================\n",
      "1 folds, loss:0.8374\n",
      "2 folds, loss:1.0360\n",
      "3 folds, loss:0.6594\n",
      "4 folds, loss:1.0185\n",
      "5 folds, loss:0.6858\n",
      "mean:0.8474 + 0.1590\n",
      "params:{'feature_fraction': 0.7433728979850882, 'gamma': 0.33578838734669464, 'max_depth': 7.0, 'num_leaves': 10.0, 'reg_lambda': 0.48076513729971604}\n",
      "====================\n",
      "1 folds, loss:0.8392\n",
      "2 folds, loss:1.0151\n",
      "3 folds, loss:0.6436\n",
      "4 folds, loss:1.0045\n",
      "5 folds, loss:0.6578\n",
      "mean:0.8320 + 0.1607\n",
      "params:{'feature_fraction': 0.9288305139656742, 'gamma': 0.4342427395169259, 'max_depth': 11.0, 'num_leaves': 128.0, 'reg_lambda': 0.20717449594708556}\n",
      "====================\n",
      "1 folds, loss:0.8208\n",
      "2 folds, loss:1.0251\n",
      "3 folds, loss:0.6456\n",
      "4 folds, loss:1.0112\n",
      "5 folds, loss:0.6722\n",
      "mean:0.8350 + 0.1611\n",
      "params:{'feature_fraction': 0.8585063650784035, 'gamma': 0.3766262083790085, 'max_depth': 6.0, 'num_leaves': 82.0, 'reg_lambda': 0.8344632050589714}\n",
      "====================\n",
      "1 folds, loss:0.8221\n",
      "2 folds, loss:1.0104\n",
      "3 folds, loss:0.6531\n",
      "4 folds, loss:0.9851\n",
      "5 folds, loss:0.6583\n",
      "mean:0.8258 + 0.1532\n",
      "params:{'feature_fraction': 0.6495374846243164, 'gamma': 0.24560598139297227, 'max_depth': 15.0, 'num_leaves': 60.0, 'reg_lambda': 0.0006189087670239735}\n",
      "====================\n",
      "1 folds, loss:0.8339\n",
      "2 folds, loss:1.0381\n",
      "3 folds, loss:0.6550\n",
      "4 folds, loss:1.0165\n",
      "5 folds, loss:0.6796\n",
      "mean:0.8446 + 0.1614\n",
      "params:{'feature_fraction': 0.9864513094991209, 'gamma': 0.44882975377349704, 'max_depth': 4.0, 'num_leaves': 20.0, 'reg_lambda': 0.5348964163438676}\n",
      "====================\n",
      "1 folds, loss:0.8185\n",
      "2 folds, loss:1.0206\n",
      "3 folds, loss:0.6368\n",
      "4 folds, loss:0.9916\n",
      "5 folds, loss:0.6672\n",
      "mean:0.8269 + 0.1590\n",
      "params:{'feature_fraction': 0.86004304576591, 'gamma': 0.4045490126510728, 'max_depth': 7.0, 'num_leaves': 50.0, 'reg_lambda': 0.43152301903444645}\n",
      "====================\n",
      "1 folds, loss:0.8156\n",
      "2 folds, loss:1.0184\n",
      "3 folds, loss:0.6422\n",
      "4 folds, loss:1.0068\n",
      "5 folds, loss:0.6643\n",
      "mean:0.8295 + 0.1611\n",
      "params:{'feature_fraction': 0.5446833929887689, 'gamma': 0.4771801796481706, 'max_depth': 8.0, 'num_leaves': 94.0, 'reg_lambda': 0.7329224006351434}\n",
      "====================\n",
      "1 folds, loss:0.8435\n",
      "2 folds, loss:1.0329\n",
      "3 folds, loss:0.6515\n",
      "4 folds, loss:1.0080\n",
      "5 folds, loss:0.6730\n",
      "mean:0.8418 + 0.1605\n",
      "params:{'feature_fraction': 0.30722969654471566, 'gamma': 0.10136006581342111, 'max_depth': 5.0, 'num_leaves': 36.0, 'reg_lambda': 0.15086575899554716}\n",
      "====================\n",
      "1 folds, loss:0.8290\n",
      "2 folds, loss:1.0169\n",
      "3 folds, loss:0.6445\n",
      "4 folds, loss:0.9916\n",
      "5 folds, loss:0.6696\n",
      "mean:0.8303 + 0.1557\n",
      "params:{'feature_fraction': 0.7215845639734065, 'gamma': 0.3325120160188033, 'max_depth': 12.0, 'num_leaves': 26.0, 'reg_lambda': 0.24744388975736262}\n",
      "====================\n",
      "1 folds, loss:0.8254\n",
      "2 folds, loss:1.0264\n",
      "3 folds, loss:0.6406\n",
      "4 folds, loss:1.0049\n",
      "5 folds, loss:0.6655\n",
      "mean:0.8325 + 0.1625\n",
      "params:{'feature_fraction': 0.9175297859656069, 'gamma': 0.49676663782883373, 'max_depth': 6.0, 'num_leaves': 62.0, 'reg_lambda': 0.31097076247884936}\n",
      "====================\n",
      "1 folds, loss:0.8163\n",
      "2 folds, loss:1.0155\n",
      "3 folds, loss:0.6403\n",
      "4 folds, loss:0.9952\n",
      "5 folds, loss:0.6624\n",
      "mean:0.8260 + 0.1587\n",
      "params:{'feature_fraction': 0.76142861725545, 'gamma': 0.35287688490884983, 'max_depth': 9.0, 'num_leaves': 106.0, 'reg_lambda': 0.6802995412183407}\n",
      "====================\n",
      "1 folds, loss:0.8372\n",
      "2 folds, loss:1.0269\n",
      "3 folds, loss:0.6484\n",
      "4 folds, loss:0.9926\n",
      "5 folds, loss:0.6659\n",
      "mean:0.8342 + 0.1582\n",
      "params:{'feature_fraction': 0.9512319783473884, 'gamma': 0.4437869422986159, 'max_depth': 15.0, 'num_leaves': 78.0, 'reg_lambda': 0.9966917283202152}\n",
      "====================\n",
      "1 folds, loss:0.8314\n",
      "2 folds, loss:1.0150\n",
      "3 folds, loss:0.6468\n",
      "4 folds, loss:0.9881\n",
      "5 folds, loss:0.6607\n",
      "mean:0.8284 + 0.1559\n",
      "params:{'feature_fraction': 0.7991121651753095, 'gamma': 0.41473051726075805, 'max_depth': 13.0, 'num_leaves': 88.0, 'reg_lambda': 0.5095929964291084}\n",
      "====================\n",
      "1 folds, loss:0.8259\n",
      "2 folds, loss:1.0237\n",
      "3 folds, loss:0.6442\n",
      "4 folds, loss:0.9862\n",
      "5 folds, loss:0.6648\n",
      "mean:0.8290 + 0.1573\n",
      "params:{'feature_fraction': 0.6193865513930101, 'gamma': 0.31463697676761965, 'max_depth': 10.0, 'num_leaves': 48.0, 'reg_lambda': 0.052765883542907066}\n",
      "====================\n",
      "1 folds, loss:0.8308\n",
      "2 folds, loss:1.0080\n",
      "3 folds, loss:0.6602\n",
      "4 folds, loss:0.9885\n",
      "5 folds, loss:0.6556\n",
      "mean:0.8286 + 0.1523\n",
      "params:{'feature_fraction': 0.5497049535289433, 'gamma': 0.2920093626462139, 'max_depth': 14.0, 'num_leaves': 70.0, 'reg_lambda': 0.8062060361584837}\n",
      "====================\n",
      "1 folds, loss:0.8177\n",
      "2 folds, loss:1.0237\n",
      "3 folds, loss:0.6405\n",
      "4 folds, loss:0.9963\n",
      "5 folds, loss:0.6599\n",
      "mean:0.8276 + 0.1613\n",
      "params:{'feature_fraction': 0.8905217295827962, 'gamma': 0.37876133479831237, 'max_depth': 7.0, 'num_leaves': 110.0, 'reg_lambda': 0.569628843686006}\n",
      "====================\n",
      "1 folds, loss:0.8225\n",
      "2 folds, loss:1.0097\n",
      "3 folds, loss:0.6393\n",
      "4 folds, loss:0.9897\n",
      "5 folds, loss:0.6568\n",
      "mean:0.8236 + 0.1575\n",
      "params:{'feature_fraction': 0.46062676740527797, 'gamma': 0.4717489022791823, 'max_depth': 16.0, 'num_leaves': 42.0, 'reg_lambda': 0.38057315341523335}\n",
      "====================\n",
      "1 folds, loss:0.8406\n",
      "2 folds, loss:1.0307\n",
      "3 folds, loss:0.6411\n",
      "4 folds, loss:0.9936\n",
      "5 folds, loss:0.6681\n",
      "mean:0.8348 + 0.1606\n",
      "params:{'feature_fraction': 0.36254095712459833, 'gamma': 0.16196380984870043, 'max_depth': 15.0, 'num_leaves': 18.0, 'reg_lambda': 0.03988663884068694}\n",
      "====================\n",
      "1 folds, loss:0.8193\n",
      "2 folds, loss:1.0041\n",
      "3 folds, loss:0.6482\n",
      "4 folds, loss:0.9820\n",
      "5 folds, loss:0.6602\n",
      "mean:0.8228 + 0.1518\n",
      "params:{'feature_fraction': 0.4807949922275503, 'gamma': 0.4701844767389448, 'max_depth': 16.0, 'num_leaves': 38.0, 'reg_lambda': 0.14139388587313345}\n",
      "====================\n",
      "1 folds, loss:0.8281\n",
      "2 folds, loss:1.0161\n",
      "3 folds, loss:0.6392\n",
      "4 folds, loss:0.9927\n",
      "5 folds, loss:0.6625\n",
      "mean:0.8277 + 0.1584\n",
      "params:{'feature_fraction': 0.38499366320937517, 'gamma': 0.2395251728913847, 'max_depth': 16.0, 'num_leaves': 26.0, 'reg_lambda': 0.1473323104015462}\n",
      "====================\n",
      "1 folds, loss:0.8231\n",
      "2 folds, loss:1.0017\n",
      "3 folds, loss:0.6412\n",
      "4 folds, loss:0.9860\n",
      "5 folds, loss:0.6566\n",
      "mean:0.8217 + 0.1544\n",
      "params:{'feature_fraction': 0.5686878623273418, 'gamma': 0.4980439597699591, 'max_depth': 14.0, 'num_leaves': 54.0, 'reg_lambda': 0.07189071978964584}\n",
      "====================\n",
      "1 folds, loss:0.8323\n",
      "2 folds, loss:1.0111\n",
      "3 folds, loss:0.6394\n",
      "4 folds, loss:0.9975\n",
      "5 folds, loss:0.6573\n",
      "mean:0.8275 + 0.1593\n",
      "params:{'feature_fraction': 0.5639117270861438, 'gamma': 0.4868615490580303, 'max_depth': 13.0, 'num_leaves': 50.0, 'reg_lambda': 0.08769194493743904}\n",
      "====================\n",
      "1 folds, loss:0.8261\n",
      "2 folds, loss:1.0194\n",
      "3 folds, loss:0.6469\n",
      "4 folds, loss:0.9900\n",
      "5 folds, loss:0.6624\n",
      "mean:0.8290 + 0.1569\n",
      "params:{'feature_fraction': 0.44604898911854607, 'gamma': 0.4144863676175609, 'max_depth': 12.0, 'num_leaves': 54.0, 'reg_lambda': 0.2057681656925864}\n",
      "====================\n",
      "1 folds, loss:0.8261\n",
      "2 folds, loss:1.0143\n",
      "3 folds, loss:0.6322\n",
      "4 folds, loss:0.9667\n",
      "5 folds, loss:0.6586\n",
      "mean:0.8196 + 0.1553\n",
      "params:{'feature_fraction': 0.5768298970544862, 'gamma': 0.4959732457252676, 'max_depth': 14.0, 'num_leaves': 64.0, 'reg_lambda': 0.041991163528273576}\n",
      "====================\n",
      "1 folds, loss:0.8218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 folds, loss:1.0139\n",
      "3 folds, loss:0.6442\n",
      "4 folds, loss:0.9842\n",
      "5 folds, loss:0.6620\n",
      "mean:0.8252 + 0.1551\n",
      "params:{'feature_fraction': 0.5702107711802988, 'gamma': 0.1977217187134886, 'max_depth': 14.0, 'num_leaves': 30.0, 'reg_lambda': 0.02937906663770139}\n",
      "====================\n",
      "1 folds, loss:0.8296\n",
      "2 folds, loss:1.0143\n",
      "3 folds, loss:0.6444\n",
      "4 folds, loss:0.9814\n",
      "5 folds, loss:0.6572\n",
      "mean:0.8254 + 0.1556\n",
      "params:{'feature_fraction': 0.5119207507861615, 'gamma': 0.49807953564281005, 'max_depth': 11.0, 'num_leaves': 96.0, 'reg_lambda': 0.1126619327305996}\n",
      "====================\n",
      "1 folds, loss:0.8399\n",
      "2 folds, loss:1.0281\n",
      "3 folds, loss:0.6458\n",
      "4 folds, loss:0.9970\n",
      "5 folds, loss:0.6593\n",
      "mean:0.8340 + 0.1614\n",
      "params:{'feature_fraction': 0.305393418797462, 'gamma': 0.14338348125776423, 'max_depth': 14.0, 'num_leaves': 76.0, 'reg_lambda': 0.18276435742637714}\n",
      "====================\n",
      "1 folds, loss:0.8136\n",
      "2 folds, loss:1.0056\n",
      "3 folds, loss:0.6479\n",
      "4 folds, loss:0.9798\n",
      "5 folds, loss:0.6582\n",
      "mean:0.8210 + 0.1522\n",
      "params:{'feature_fraction': 0.5018619206441843, 'gamma': 0.10443494585719665, 'max_depth': 15.0, 'num_leaves': 68.0, 'reg_lambda': 0.11577394534920836}\n",
      "====================\n",
      "1 folds, loss:0.8414\n",
      "2 folds, loss:1.0286\n",
      "3 folds, loss:0.6462\n",
      "4 folds, loss:0.9870\n",
      "5 folds, loss:0.6582\n",
      "mean:0.8323 + 0.1597\n",
      "params:{'feature_fraction': 0.3361352313222018, 'gamma': 0.11492462514654944, 'max_depth': 15.0, 'num_leaves': 84.0, 'reg_lambda': 0.010936446585113224}\n",
      "====================\n",
      "1 folds, loss:0.8304\n",
      "2 folds, loss:1.0259\n",
      "3 folds, loss:0.6469\n",
      "4 folds, loss:0.9877\n",
      "5 folds, loss:0.6555\n",
      "mean:0.8293 + 0.1595\n",
      "params:{'feature_fraction': 0.40282552811364075, 'gamma': 0.1573772843342315, 'max_depth': 12.0, 'num_leaves': 68.0, 'reg_lambda': 0.3267916456760076}\n",
      "====================\n",
      "1 folds, loss:0.8330\n",
      "2 folds, loss:1.0129\n",
      "3 folds, loss:0.6499\n",
      "4 folds, loss:0.9789\n",
      "5 folds, loss:0.6578\n",
      "mean:0.8265 + 0.1534\n",
      "params:{'feature_fraction': 0.5008520934670232, 'gamma': 0.18363482235349426, 'max_depth': 13.0, 'num_leaves': 92.0, 'reg_lambda': 0.11353722031611652}\n",
      "====================\n",
      "1 folds, loss:0.8155\n",
      "2 folds, loss:1.0171\n",
      "3 folds, loss:0.6411\n",
      "4 folds, loss:0.9798\n",
      "5 folds, loss:0.6586\n",
      "mean:0.8224 + 0.1565\n",
      "params:{'feature_fraction': 0.43807876093315956, 'gamma': 0.26193418391532125, 'max_depth': 15.0, 'num_leaves': 44.0, 'reg_lambda': 0.23968033042884015}\n",
      "====================\n",
      "1 folds, loss:0.8234\n",
      "2 folds, loss:1.0123\n",
      "3 folds, loss:0.6394\n",
      "4 folds, loss:0.9915\n",
      "5 folds, loss:0.6611\n",
      "mean:0.8255 + 0.1576\n",
      "params:{'feature_fraction': 0.5269019542483763, 'gamma': 0.21280690667574767, 'max_depth': 13.0, 'num_leaves': 64.0, 'reg_lambda': 0.466438342353246}\n",
      "====================\n",
      "1 folds, loss:0.8170\n",
      "2 folds, loss:1.0152\n",
      "3 folds, loss:0.6331\n",
      "4 folds, loss:0.9747\n",
      "5 folds, loss:0.6582\n",
      "mean:0.8196 + 0.1570\n",
      "params:{'feature_fraction': 0.6235516564297751, 'gamma': 0.12213336887323106, 'max_depth': 14.0, 'num_leaves': 56.0, 'reg_lambda': 0.06933411963054989}\n",
      "====================\n",
      "1 folds, loss:0.8220\n",
      "2 folds, loss:1.0130\n",
      "3 folds, loss:0.6419\n",
      "4 folds, loss:0.9734\n",
      "5 folds, loss:0.6561\n",
      "mean:0.8213 + 0.1545\n",
      "params:{'feature_fraction': 0.6168505315166408, 'gamma': 0.11625832973533788, 'max_depth': 14.0, 'num_leaves': 58.0, 'reg_lambda': 0.2071109813017875}\n",
      "====================\n",
      "1 folds, loss:0.8246\n",
      "2 folds, loss:1.0167\n",
      "3 folds, loss:0.6392\n",
      "4 folds, loss:0.9872\n",
      "5 folds, loss:0.6541\n",
      "mean:0.8244 + 0.1592\n",
      "params:{'feature_fraction': 0.6739207049759994, 'gamma': 0.18176046167332333, 'max_depth': 15.0, 'num_leaves': 86.0, 'reg_lambda': 0.06435351877644592}\n",
      "====================\n",
      "1 folds, loss:0.8301\n",
      "2 folds, loss:1.0171\n",
      "3 folds, loss:0.6463\n",
      "4 folds, loss:0.9873\n",
      "5 folds, loss:0.6582\n",
      "mean:0.8278 + 0.1568\n",
      "params:{'feature_fraction': 0.6513124232293144, 'gamma': 0.10173033064383859, 'max_depth': 12.0, 'num_leaves': 70.0, 'reg_lambda': 0.022454737486503423}\n",
      "====================\n",
      "1 folds, loss:0.8310\n",
      "2 folds, loss:1.0098\n",
      "3 folds, loss:0.6417\n",
      "4 folds, loss:0.9778\n",
      "5 folds, loss:0.6574\n",
      "mean:0.8235 + 0.1544\n",
      "params:{'feature_fraction': 0.6945343016227314, 'gamma': 0.1431821931026483, 'max_depth': 16.0, 'num_leaves': 74.0, 'reg_lambda': 0.1242702895696218}\n",
      "====================\n",
      "1 folds, loss:0.8268\n",
      "2 folds, loss:1.0184\n",
      "3 folds, loss:0.6361\n",
      "4 folds, loss:0.9888\n",
      "5 folds, loss:0.6544\n",
      "mean:0.8249 + 0.1606\n",
      "params:{'feature_fraction': 0.5874151302213525, 'gamma': 0.21864194739730425, 'max_depth': 11.0, 'num_leaves': 48.0, 'reg_lambda': 0.29416053385652147}\n",
      "====================\n",
      "1 folds, loss:0.8220\n",
      "2 folds, loss:1.0088\n",
      "3 folds, loss:0.6408\n",
      "4 folds, loss:0.9778\n",
      "5 folds, loss:0.6542\n",
      "mean:0.8207 + 0.1550\n",
      "params:{'feature_fraction': 0.6429168576416966, 'gamma': 0.11963674384355855, 'max_depth': 13.0, 'num_leaves': 62.0, 'reg_lambda': 0.174789362249176}\n",
      "====================\n",
      "1 folds, loss:0.8207\n",
      "2 folds, loss:1.0045\n",
      "3 folds, loss:0.6357\n",
      "4 folds, loss:0.9893\n",
      "5 folds, loss:0.6610\n",
      "mean:0.8222 + 0.1562\n",
      "params:{'feature_fraction': 0.6488880188996672, 'gamma': 0.12145050958980029, 'max_depth': 13.0, 'num_leaves': 40.0, 'reg_lambda': 0.1713004088865029}\n",
      "====================\n",
      "1 folds, loss:0.8247\n",
      "2 folds, loss:1.0084\n",
      "3 folds, loss:0.6461\n",
      "4 folds, loss:0.9789\n",
      "5 folds, loss:0.6607\n",
      "mean:0.8238 + 0.1525\n",
      "params:{'feature_fraction': 0.7093575031976215, 'gamma': 0.2397335273781851, 'max_depth': 13.0, 'num_leaves': 52.0, 'reg_lambda': 0.35325606131465}\n",
      "====================\n",
      "1 folds, loss:0.8239\n",
      "2 folds, loss:1.0143\n",
      "3 folds, loss:0.6379\n",
      "4 folds, loss:0.9883\n",
      "5 folds, loss:0.6598\n",
      "mean:0.8249 + 0.1580\n",
      "params:{'feature_fraction': 0.7330106019915033, 'gamma': 0.18091609487745167, 'max_depth': 11.0, 'num_leaves': 62.0, 'reg_lambda': 0.07163007960833383}\n",
      "====================\n",
      "1 folds, loss:0.8231\n",
      "2 folds, loss:1.0192\n",
      "3 folds, loss:0.6432\n",
      "4 folds, loss:0.9878\n",
      "5 folds, loss:0.6691\n",
      "mean:0.8285 + 0.1559\n",
      "params:{'feature_fraction': 0.6200442790396264, 'gamma': 0.2782893254751235, 'max_depth': 10.0, 'num_leaves': 30.0, 'reg_lambda': 0.39508739905940277}\n",
      "====================\n",
      "1 folds, loss:0.8168\n",
      "2 folds, loss:1.0159\n",
      "3 folds, loss:0.6445\n",
      "4 folds, loss:0.9814\n",
      "5 folds, loss:0.6557\n",
      "mean:0.8229 + 0.1563\n",
      "params:{'feature_fraction': 0.5877233890563811, 'gamma': 0.14152620656233905, 'max_depth': 12.0, 'num_leaves': 58.0, 'reg_lambda': 0.2585518582328962}\n",
      "====================\n",
      "1 folds, loss:0.8257\n",
      "2 folds, loss:1.0065\n",
      "3 folds, loss:0.6354\n",
      "4 folds, loss:0.9875\n",
      "5 folds, loss:0.6595\n",
      "mean:0.8229 + 0.1566\n",
      "params:{'feature_fraction': 0.5333562981875127, 'gamma': 0.1292471679287394, 'max_depth': 14.0, 'num_leaves': 46.0, 'reg_lambda': 0.0025611583792346515}\n",
      "====================\n",
      "1 folds, loss:0.8319\n",
      "2 folds, loss:1.0081\n",
      "3 folds, loss:0.6401\n",
      "4 folds, loss:0.9899\n",
      "5 folds, loss:0.6640\n",
      "mean:0.8268 + 0.1555\n",
      "params:{'feature_fraction': 0.7760737661245003, 'gamma': 0.20773564979793613, 'max_depth': 11.0, 'num_leaves': 34.0, 'reg_lambda': 0.09240027280954773}\n",
      "====================\n",
      "1 folds, loss:0.8267\n",
      "2 folds, loss:1.0234\n",
      "3 folds, loss:0.6367\n",
      "4 folds, loss:0.9921\n",
      "5 folds, loss:0.6564\n",
      "mean:0.8271 + 0.1620\n",
      "params:{'feature_fraction': 0.658754470550852, 'gamma': 0.15826794384302062, 'max_depth': 14.0, 'num_leaves': 78.0, 'reg_lambda': 0.22822625754759904}\n",
      "====================\n",
      "1 folds, loss:0.8323\n",
      "2 folds, loss:1.0261\n",
      "3 folds, loss:0.6443\n",
      "4 folds, loss:0.9989\n",
      "5 folds, loss:0.6753\n",
      "mean:0.8354 + 0.1583\n",
      "params:{'feature_fraction': 0.7457729248958365, 'gamma': 0.17282877225294074, 'max_depth': 13.0, 'num_leaves': 14.0, 'reg_lambda': 0.03955406660210977}\n",
      "====================\n",
      "1 folds, loss:0.8248\n",
      "2 folds, loss:1.0146\n",
      "3 folds, loss:0.6345\n",
      "4 folds, loss:0.9826\n",
      "5 folds, loss:0.6555\n",
      "mean:0.8224 + 0.1586\n",
      "params:{'feature_fraction': 0.6305336073499946, 'gamma': 0.2525295289611006, 'max_depth': 16.0, 'num_leaves': 64.0, 'reg_lambda': 0.2939971223056886}\n",
      "====================\n",
      "1 folds, loss:0.8201\n",
      "2 folds, loss:1.0153\n",
      "3 folds, loss:0.6316\n",
      "4 folds, loss:0.9977\n",
      "5 folds, loss:0.6564\n",
      "mean:0.8242 + 0.1624\n",
      "params:{'feature_fraction': 0.6056299309605933, 'gamma': 0.22895191624441408, 'max_depth': 12.0, 'num_leaves': 72.0, 'reg_lambda': 0.6209422349307091}\n",
      "====================\n",
      "1 folds, loss:0.8263\n",
      "2 folds, loss:1.0223\n",
      "3 folds, loss:0.6466\n",
      "4 folds, loss:0.9849\n",
      "5 folds, loss:0.6565\n",
      "mean:0.8273 + 0.1579\n",
      "params:{'feature_fraction': 0.47822074954931737, 'gamma': 0.32378320738346056, 'max_depth': 10.0, 'num_leaves': 56.0, 'reg_lambda': 0.19349697547137795}\n",
      "====================\n",
      "1 folds, loss:0.8163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 folds, loss:1.0216\n",
      "3 folds, loss:0.6468\n",
      "4 folds, loss:0.9866\n",
      "5 folds, loss:0.6632\n",
      "mean:0.8269 + 0.1567\n",
      "params:{'feature_fraction': 0.5561435644754202, 'gamma': 0.2725608152076332, 'max_depth': 9.0, 'num_leaves': 98.0, 'reg_lambda': 0.1594656456659238}\n",
      "====================\n",
      "1 folds, loss:0.8255\n",
      "2 folds, loss:1.0075\n",
      "3 folds, loss:0.6462\n",
      "4 folds, loss:0.9832\n",
      "5 folds, loss:0.6536\n",
      "mean:0.8232 + 0.1547\n",
      "params:{'feature_fraction': 0.6779731555891023, 'gamma': 0.1954428732598678, 'max_depth': 15.0, 'num_leaves': 80.0, 'reg_lambda': 0.5677892623033521}\n",
      "====================\n",
      "1 folds, loss:0.8259\n",
      "2 folds, loss:1.0234\n",
      "3 folds, loss:0.6391\n",
      "4 folds, loss:0.9757\n",
      "5 folds, loss:0.6610\n",
      "mean:0.8250 + 0.1572\n",
      "params:{'feature_fraction': 0.708540602187811, 'gamma': 0.29923849927385104, 'max_depth': 12.0, 'num_leaves': 52.0, 'reg_lambda': 0.34523848260998247}\n",
      "====================\n",
      "1 folds, loss:0.8293\n",
      "2 folds, loss:1.0263\n",
      "3 folds, loss:0.6416\n",
      "4 folds, loss:0.9937\n",
      "5 folds, loss:0.6668\n",
      "mean:0.8315 + 0.1597\n",
      "params:{'feature_fraction': 0.4565244202752325, 'gamma': 0.38543726371921744, 'max_depth': 14.0, 'num_leaves': 22.0, 'reg_lambda': 0.136499267660397}\n",
      "====================\n",
      "1 folds, loss:0.8135\n",
      "2 folds, loss:1.0260\n",
      "3 folds, loss:0.6423\n",
      "4 folds, loss:0.9789\n",
      "5 folds, loss:0.6575\n",
      "mean:0.8237 + 0.1585\n",
      "params:{'feature_fraction': 0.4135629321288159, 'gamma': 0.15049055100271155, 'max_depth': 16.0, 'num_leaves': 38.0, 'reg_lambda': 0.9655528458156203}\n",
      "====================\n",
      "1 folds, loss:0.8267\n",
      "2 folds, loss:1.0175\n",
      "3 folds, loss:0.6421\n",
      "4 folds, loss:1.0011\n",
      "5 folds, loss:0.6534\n",
      "mean:0.8282 + 0.1618\n",
      "params:{'feature_fraction': 0.6381854042367315, 'gamma': 0.36371966059987537, 'max_depth': 13.0, 'num_leaves': 114.0, 'reg_lambda': 0.22640821333295552}\n",
      "====================\n",
      "1 folds, loss:0.8220\n",
      "2 folds, loss:1.0093\n",
      "3 folds, loss:0.6589\n",
      "4 folds, loss:0.9890\n",
      "5 folds, loss:0.6603\n",
      "mean:0.8279 + 0.1520\n",
      "params:{'feature_fraction': 0.8451229592910277, 'gamma': 0.13322669655387734, 'max_depth': 15.0, 'num_leaves': 62.0, 'reg_lambda': 0.8716048933542035}\n",
      "====================\n",
      "1 folds, loss:0.8296\n",
      "2 folds, loss:1.0132\n",
      "3 folds, loss:0.6464\n",
      "4 folds, loss:0.9926\n",
      "5 folds, loss:0.6577\n",
      "mean:0.8279 + 0.1571\n",
      "params:{'feature_fraction': 0.7261974534296561, 'gamma': 0.22839925001531403, 'max_depth': 13.0, 'num_leaves': 90.0, 'reg_lambda': 0.07098655478942428}\n",
      "====================\n",
      "1 folds, loss:0.8275\n",
      "2 folds, loss:1.0088\n",
      "3 folds, loss:0.6448\n",
      "4 folds, loss:0.9765\n",
      "5 folds, loss:0.6554\n",
      "mean:0.8226 + 0.1536\n",
      "params:{'feature_fraction': 0.5392638281733334, 'gamma': 0.1256623583165667, 'max_depth': 14.0, 'num_leaves': 76.0, 'reg_lambda': 0.7789207723552958}\n",
      "====================\n",
      "1 folds, loss:0.8198\n",
      "2 folds, loss:1.0200\n",
      "3 folds, loss:0.6387\n",
      "4 folds, loss:0.9943\n",
      "5 folds, loss:0.6666\n",
      "mean:0.8279 + 0.1591\n",
      "params:{'feature_fraction': 0.7580840405254212, 'gamma': 0.10683473287400586, 'max_depth': 8.0, 'num_leaves': 44.0, 'reg_lambda': 0.04871447484605097}\n",
      "====================\n",
      "1 folds, loss:0.8293\n",
      "2 folds, loss:1.0195\n",
      "3 folds, loss:0.6340\n",
      "4 folds, loss:0.9975\n",
      "5 folds, loss:0.6624\n",
      "mean:0.8285 + 0.1615\n",
      "params:{'feature_fraction': 0.5802003054329872, 'gamma': 0.1699974062159217, 'max_depth': 11.0, 'num_leaves': 66.0, 'reg_lambda': 0.43870134542651484}\n",
      "====================\n",
      "1 folds, loss:0.8312\n",
      "2 folds, loss:1.0042\n",
      "3 folds, loss:0.6538\n",
      "4 folds, loss:0.9888\n",
      "5 folds, loss:0.6586\n",
      "mean:0.8273 + 0.1523\n",
      "params:{'feature_fraction': 0.5136906985611541, 'gamma': 0.3495699184476846, 'max_depth': 16.0, 'num_leaves': 120.0, 'reg_lambda': 0.085066879162974}\n",
      "====================\n",
      "1 folds, loss:0.8198\n",
      "2 folds, loss:1.0233\n",
      "3 folds, loss:0.6431\n",
      "4 folds, loss:0.9950\n",
      "5 folds, loss:0.6594\n",
      "mean:0.8281 + 0.1604\n",
      "params:{'feature_fraction': 0.6070706108664294, 'gamma': 0.43883395738223135, 'max_depth': 9.0, 'num_leaves': 102.0, 'reg_lambda': 0.1735181007877397}\n",
      "====================\n",
      "1 folds, loss:0.8272\n",
      "2 folds, loss:1.0196\n",
      "3 folds, loss:0.6382\n",
      "4 folds, loss:0.9853\n",
      "5 folds, loss:0.6544\n",
      "mean:0.8249 + 0.1597\n",
      "params:{'feature_fraction': 0.6924585212864138, 'gamma': 0.42303627042264724, 'max_depth': 15.0, 'num_leaves': 82.0, 'reg_lambda': 0.4926769025957506}\n",
      "====================\n",
      "1 folds, loss:0.8232\n",
      "2 folds, loss:1.0131\n",
      "3 folds, loss:0.6557\n",
      "4 folds, loss:0.9884\n",
      "5 folds, loss:0.6591\n",
      "mean:0.8279 + 0.1538\n",
      "params:{'feature_fraction': 0.7906831464648402, 'gamma': 0.11192745391628814, 'max_depth': 14.0, 'num_leaves': 60.0, 'reg_lambda': 0.26487751700016415}\n",
      "====================\n",
      "1 folds, loss:0.8391\n",
      "2 folds, loss:1.0236\n",
      "3 folds, loss:0.6488\n",
      "4 folds, loss:0.9954\n",
      "5 folds, loss:0.6660\n",
      "mean:0.8346 + 0.1578\n",
      "params:{'feature_fraction': 0.3377839344021967, 'gamma': 0.19461875650313262, 'max_depth': 13.0, 'num_leaves': 28.0, 'reg_lambda': 0.02026672273592628}\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "lgbm_space = { \n",
    "    'max_depth' : hp.quniform(\"max_depth\", 4, 16, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 8, 128, 2),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.3, 1.0),\n",
    "#     'bagging_fraction': hp.uniform ('bagging_fraction', 0.7, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda',0,1),\n",
    "    'gamma' : hp.uniform('gamma', 0.1,0.5)\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "lgbm_best = fmin(fn=lgbm_objective,\n",
    "            space=lgbm_space,\n",
    "            algo=tpe.suggest,\n",
    "            trials = trials,\n",
    "            max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book_time': datetime.datetime(2018, 2, 13, 12, 51, 25, 302000),\n",
       " 'exp_key': None,\n",
       " 'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'idxs': {'feature_fraction': [55],\n",
       "   'gamma': [55],\n",
       "   'max_depth': [55],\n",
       "   'num_leaves': [55],\n",
       "   'reg_lambda': [55]},\n",
       "  'tid': 55,\n",
       "  'vals': {'feature_fraction': [0.5768298970544862],\n",
       "   'gamma': [0.4959732457252676],\n",
       "   'max_depth': [14.0],\n",
       "   'num_leaves': [64.0],\n",
       "   'reg_lambda': [0.041991163528273576]},\n",
       "  'workdir': None},\n",
       " 'owner': None,\n",
       " 'refresh_time': datetime.datetime(2018, 2, 13, 12, 54, 28, 579000),\n",
       " 'result': {'loss': 0.8195726997605574, 'status': 'ok'},\n",
       " 'spec': None,\n",
       " 'state': 2,\n",
       " 'tid': 55,\n",
       " 'version': 0}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55, 65, 71, 59, 66, 52, 24, 72, 81, 63, 92, 50, 76, 77, 85, 69, 48,\n",
       "       88, 73, 82, 67, 74, 70,  2, 97, 86, 56, 57, 64, 35, 21, 42, 12, 62,\n",
       "       78, 17, 84, 37, 79, 95, 83, 53, 47, 51, 14, 19, 15, 68, 91, 93, 98,\n",
       "       90, 96, 89, 23, 44, 75, 94, 46, 27, 54, 45, 61, 38,  3, 20,  0, 11,\n",
       "       29, 40,  1,  7, 10, 28, 87, 33, 18, 13, 26, 60, 41,  9, 30,  5, 58,\n",
       "       43, 99, 49, 34, 16,  4, 80, 31, 25,  8, 39, 36, 22,  6, 32], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(trials.losses())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_best = {\n",
    "    'feature_fraction': 0.5768298970544862,\n",
    "    'gamma': 0.4959732457252676,\n",
    "    'max_depth': 14,\n",
    "    'num_leaves': 64,\n",
    "    'reg_lambda': 0.041991163528273576}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "defalut_params = {\n",
    "    'bossting_type':'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate' : 0.1,\n",
    "    'num_iterations' : 200\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bossting_type': 'gbdt',\n",
       " 'feature_fraction': 0.5768298970544862,\n",
       " 'gamma': 0.4959732457252676,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 14,\n",
       " 'metric': 'rmse',\n",
       " 'num_iterations': 200,\n",
       " 'num_leaves': 64,\n",
       " 'objective': 'regression',\n",
       " 'reg_lambda': 0.041991163528273576}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_best = {**defalut_params,**lgbm_best}\n",
    "params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 1.09983\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's rmse: 1.07576\n",
      "[3]\tvalid_0's rmse: 1.05453\n",
      "[4]\tvalid_0's rmse: 1.03348\n",
      "[5]\tvalid_0's rmse: 1.0161\n",
      "[6]\tvalid_0's rmse: 1.00196\n",
      "[7]\tvalid_0's rmse: 0.98993\n",
      "[8]\tvalid_0's rmse: 0.98148\n",
      "[9]\tvalid_0's rmse: 0.972278\n",
      "[10]\tvalid_0's rmse: 0.967235\n",
      "[11]\tvalid_0's rmse: 0.960818\n",
      "[12]\tvalid_0's rmse: 0.955609\n",
      "[13]\tvalid_0's rmse: 0.952638\n",
      "[14]\tvalid_0's rmse: 0.948014\n",
      "[15]\tvalid_0's rmse: 0.944631\n",
      "[16]\tvalid_0's rmse: 0.943705\n",
      "[17]\tvalid_0's rmse: 0.942057\n",
      "[18]\tvalid_0's rmse: 0.941555\n",
      "[19]\tvalid_0's rmse: 0.939173\n",
      "[20]\tvalid_0's rmse: 0.938168\n",
      "[21]\tvalid_0's rmse: 0.939607\n",
      "[22]\tvalid_0's rmse: 0.938534\n",
      "[23]\tvalid_0's rmse: 0.937674\n",
      "[24]\tvalid_0's rmse: 0.936796\n",
      "[25]\tvalid_0's rmse: 0.937291\n",
      "[26]\tvalid_0's rmse: 0.936779\n",
      "[27]\tvalid_0's rmse: 0.93563\n",
      "[28]\tvalid_0's rmse: 0.936219\n",
      "[29]\tvalid_0's rmse: 0.935689\n",
      "[30]\tvalid_0's rmse: 0.935922\n",
      "[31]\tvalid_0's rmse: 0.935828\n",
      "[32]\tvalid_0's rmse: 0.935325\n",
      "[33]\tvalid_0's rmse: 0.935782\n",
      "[34]\tvalid_0's rmse: 0.935738\n",
      "[35]\tvalid_0's rmse: 0.935668\n",
      "[36]\tvalid_0's rmse: 0.934655\n",
      "[37]\tvalid_0's rmse: 0.933552\n",
      "[38]\tvalid_0's rmse: 0.933881\n",
      "[39]\tvalid_0's rmse: 0.933584\n",
      "[40]\tvalid_0's rmse: 0.93368\n",
      "[41]\tvalid_0's rmse: 0.933535\n",
      "[42]\tvalid_0's rmse: 0.933519\n",
      "[43]\tvalid_0's rmse: 0.933272\n",
      "[44]\tvalid_0's rmse: 0.933164\n",
      "[45]\tvalid_0's rmse: 0.932991\n",
      "[46]\tvalid_0's rmse: 0.933145\n",
      "[47]\tvalid_0's rmse: 0.932995\n",
      "[48]\tvalid_0's rmse: 0.932404\n",
      "[49]\tvalid_0's rmse: 0.932496\n",
      "[50]\tvalid_0's rmse: 0.93231\n",
      "[51]\tvalid_0's rmse: 0.933512\n",
      "[52]\tvalid_0's rmse: 0.93327\n",
      "[53]\tvalid_0's rmse: 0.933272\n",
      "[54]\tvalid_0's rmse: 0.932608\n",
      "[55]\tvalid_0's rmse: 0.932425\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's rmse: 0.93231\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(X_train,y_train)\n",
    "lgb_cv = lgb.Dataset(X_cv,y_cv,reference=lgb_train) # cv : 2015 Oct data\n",
    "reg = lgb.train(params_best,\n",
    "                    early_stopping_rounds = 5,\n",
    "                    train_set = lgb_train,\n",
    "                    valid_sets=lgb_cv,\n",
    "                    verbose_eval = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3334"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
