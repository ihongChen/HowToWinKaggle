{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/X_cv', '/X_test', '/X_train', '/y_cv', '/y_train']\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('../data/feat/data.h5') as store:\n",
    "    print(store.keys())\n",
    "    X_train = store['X_train']\n",
    "    X_cv = store['X_cv']\n",
    "    y_train = store['y_train']\n",
    "    y_cv = store['y_cv']\n",
    "    X_test = store['X_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.date_block_num.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clip to (0,20)\n",
    "y_train = y_train.clip(0,20)\n",
    "y_cv = y_cv.clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10675632, 54)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = downcast_dtypes(X_train)\n",
    "X_cv = downcast_dtypes(X_cv)\n",
    "X_test = downcast_dtypes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.float32)\n",
    "y_cv = y_cv.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train /test reduce\n",
    "- memory issue\n",
    "- time cost issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates = X_train.date_block_num\n",
    "mask = train_dates >= 12\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates = train_dates[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6186922, 54)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Level Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates = X_train.date_block_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level2_date_block = [27, 28, 29, 30, 31, 32]\n",
    "level2_date_block = [32]\n",
    "level2_mask = train_dates.isin(level2_date_block)\n",
    "# level2_mask = pd.Series(train_dates).isin(level2_date_block)\n",
    "train_dates_level2 = train_dates[level2_mask]\n",
    "train_y_level2 = y_train[level2_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def customized_grid_search_cv_evaluate(clf, X_train, y_train, param_grid):\n",
    "    \n",
    "    params_list = list(ParameterGrid(param_grid))\n",
    "    res_df = pd.DataFrame(data=np.zeros((len(params_list),3)), columns=['params', 'mean_test_score', 'std_test_score'])\n",
    "    res_df.loc[:,'params'] = params_list\n",
    "    \n",
    "    for i, params in enumerate(params_list):\n",
    "        scores = []\n",
    "        print('Fitting: ', params, '...', end='\\n\\tscores= ')\n",
    "        for cur_block in level2_date_block:\n",
    "            copy_clf = copy.deepcopy(clf)\n",
    "            original_param = copy_clf.get_params()\n",
    "            original_param.update(params)\n",
    "            copy_clf.set_params(**original_param) # update copy clf with trying params \n",
    "            \n",
    "            copy_clf.fit(X_train[train_dates < cur_block].values, y_train[train_dates < cur_block])\n",
    "            pred_y = copy_clf.predict(X_train[train_dates == cur_block].values)\n",
    "            pred_y = np.clip(pred_y, 0., 20.)\n",
    "            score = mean_squared_error(y_train[train_dates == cur_block], pred_y)**.5\n",
    "            print('{:.5f} '.format(score), end='')\n",
    "            scores.append(score)\n",
    "            del copy_clf; gc.collect()\n",
    "        \n",
    "        print('')\n",
    "        res_df.loc[i, 'mean_test_score'] = np.mean(scores)\n",
    "        res_df.loc[i, 'std_test_score'] = np.std(scores)\n",
    "        \n",
    "    print('Fitting finished')\n",
    "    res_df = res_df.sort_values(by=['mean_test_score', 'std_test_score'], ascending=True).reset_index(drop=True)\n",
    "    best_params = res_df.loc[0, 'params']\n",
    "    \n",
    "    print('Selected hyper-params:', best_params)\n",
    "    print('cv score: {:.4f}, std: {:.4f}'.format(res_df.loc[0, 'mean_test_score'], res_df.loc[0, 'std_test_score']))\n",
    "    del res_df, params_list; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_grid_search_simple_holdout_evaluate(clf, X_train, y_train, param_grid, level2_date_block=[32]):\n",
    "    \n",
    "    params_list = list(ParameterGrid(param_grid))\n",
    "    res_df = pd.DataFrame(data=np.zeros((len(params_list),2)), columns=['params', 'val_score'])\n",
    "    res_df.loc[:,'params'] = params_list\n",
    "    \n",
    "    train_mask = train_dates < level2_date_block[0]\n",
    "    validation_mask = (train_dates >= level2_date_block[0]) & (train_dates <= level2_date_block[-1])\n",
    "    for i, params in enumerate(params_list):\n",
    "        print('Fitting: ', params, '...', end='\\n\\tscore= ')\n",
    "        \n",
    "        copy_clf = copy.deepcopy(clf)\n",
    "        original_param = copy_clf.get_params()\n",
    "        original_param.update(params)\n",
    "        copy_clf.set_params(**original_param) # update copy clf with trying params \n",
    "\n",
    "        copy_clf.fit(X_train[train_mask].values, y_train[train_mask])\n",
    "        pred_y = copy_clf.predict(X_train[validation_mask].values)\n",
    "        pred_y = np.clip(pred_y, 0., 20.)\n",
    "        score = mean_squared_error(y_train[validation_mask], pred_y)**.5\n",
    "        print('{:.5f} '.format(score), end='\\n')\n",
    "        del copy_clf; gc.collect()\n",
    "\n",
    "        res_df.loc[i, 'val_score'] = score\n",
    "        \n",
    "    print('Fitting finished')\n",
    "    res_df = res_df.sort_values(by=['val_score'], ascending=True).reset_index(drop=True)\n",
    "    best_params = res_df.loc[0, 'params']\n",
    "    \n",
    "    print('Selected hyper-params:', best_params)\n",
    "    print('cv score: {:.4f}'.format(res_df.loc[0, 'val_score']))\n",
    "    del res_df, params_list; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = { \n",
    "    'max_depth' : hp.quniform(\"max_depth\", 4, 16, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 8, 128, 2),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.3, 1.0),\n",
    "    'bagging_fraction': hp.uniform ('bagging_fraction', 0.7, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda',0,1),\n",
    "    'gamma' : hp.uniform('gamma', 0.1,0.5),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_opt_simple_holdout_evaluate(clf, X_train, y_train, params, level2_date_block=[32]):\n",
    "    \"\"\" \n",
    "    use hyperopt to find `best` params for clf \n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \n",
    "    clf = params.get('clf')\n",
    "    new_params = params.get('params') ## update params\n",
    "#     print(params,clf.get_params())\n",
    "\n",
    "    copy_clf = copy.deepcopy(clf)\n",
    "    original_params = copy_clf.get_params()\n",
    "    original_params.update(new_params)\n",
    "    copy_clf.set_params(**original_params) # update copy clf with trying new_params     \n",
    "    \n",
    "    train_mask = train_dates < level2_date_block[0]\n",
    "    validation_mask = (train_dates >= level2_date_block[0]) & (train_dates <= level2_date_block[-1])\n",
    "    \n",
    "    copy_clf.fit(X_train[train_mask].values, y_train[train_mask])\n",
    "    \n",
    "    \n",
    "    pred_y = copy_clf.predict(X_train[validation_mask].values)\n",
    "    pred_y = np.clip(pred_y, 0., 20.)\n",
    "    rmse = mean_squared_error(y_train[validation_mask], pred_y)**.5\n",
    "    print('rmse: {:.5f} '.format(rmse), end='\\n')\n",
    "    \n",
    "    return {'loss':rmse,'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 1.06686 \n",
      "rmse: 1.06106 \n",
      "rmse: 1.06349 \n",
      "rmse: 1.05911 \n",
      "rmse: 1.06687 \n",
      "rmse: 1.06715 \n",
      "rmse: 1.05252 \n",
      "rmse: 1.06831 \n",
      "rmse: 1.06796 \n",
      "rmse: 1.06450 \n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "rg_clf = Pipeline([\n",
    "    ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "    ('rg', Ridge(fit_intercept=True, normalize=True, max_iter=2000, random_state=0))\n",
    "])\n",
    "clf_params = {\n",
    "    'clf':rg_clf,\n",
    "    'params': {'rg__alpha': hp.uniform('rg__alpha', 0.01, 1.0)},\n",
    "}\n",
    "\n",
    "best = fmin(fn = objective,\n",
    "            space = clf_params,\n",
    "            algo = tpe.suggest,\n",
    "            trials = trials,\n",
    "            max_evals = 10\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rg__alpha': 0.012834387887666377}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model \n",
    "- Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso #featuring L2/L1 regularized linear models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  {'rg__alpha': 0.1} ...\n",
      "\tscores= 4.47786 3.66831 2.06927 1.88897 1.97926 6.70534 \n",
      "Fitting:  {'rg__alpha': 1.0} ...\n",
      "\tscores= 4.47854 3.66718 2.06686 1.89577 1.98347 6.72269 \n",
      "Fitting:  {'rg__alpha': 2.0} ...\n",
      "\tscores= 4.47944 3.66787 2.06959 1.89999 1.99009 6.73109 \n",
      "Fitting:  {'rg__alpha': 4.0} ...\n",
      "\tscores= 4.48113 3.67167 2.07809 1.90774 2.00280 6.74004 \n",
      "Fitting finished\n",
      "Selected hyper-params: {'rg__alpha': 0.1}\n",
      "cv score: 3.4648, std: 1.7420\n"
     ]
    }
   ],
   "source": [
    "rg_clf = Pipeline([\n",
    "    ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "    ('rg', Ridge(fit_intercept=True, normalize=True, max_iter=2000, random_state=0))\n",
    "])\n",
    "\n",
    "rg_params = {\n",
    "    'rg__alpha': [0.1, 1., 2., 4.],\n",
    "}\n",
    "customized_grid_search_cv_evaluate(rg_clf, X_train, y_train, rg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  {'rg__alpha': 0.01} ...\n",
      "\tscores= 4.47895 3.66958 2.07293 1.88877 1.98052 6.70177 \n",
      "Fitting:  {'rg__alpha': 0.05} ...\n",
      "\tscores= 4.47828 3.66887 2.07093 1.88875 1.97977 6.70344 \n",
      "Fitting:  {'rg__alpha': 0.1} ...\n",
      "\tscores= 4.47786 3.66831 2.06927 1.88897 1.97926 6.70534 \n",
      "Fitting:  {'rg__alpha': 0.25} ...\n",
      "\tscores= 4.47758 3.66745 2.06701 1.89016 1.97912 6.70990 \n",
      "Fitting:  {'rg__alpha': 0.5} ...\n",
      "\tscores= 4.47787 3.66703 2.06623 1.89239 1.98027 6.71513 \n",
      "Fitting finished\n",
      "Selected hyper-params: {'rg__alpha': 0.1}\n",
      "cv score: 3.4648, std: 1.7420\n"
     ]
    }
   ],
   "source": [
    "rg_clf = Pipeline([\n",
    "    ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "    ('rg', Ridge(fit_intercept=True, normalize=True, max_iter=2000, random_state=0))\n",
    "])\n",
    "\n",
    "rg_params = {\n",
    "    'rg__alpha': [0.01, 0.05, 0.1, 0.25, 0.5],\n",
    "}\n",
    "customized_grid_search_cv_evaluate(rg_clf, X_train, y_train, rg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': None,\n",
       " 'normalize': False,\n",
       " 'random_state': None,\n",
       " 'solver': 'auto',\n",
       " 'tol': 0.001}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  {'rg__alpha': 0.01} ...\n",
      "\tscore= 1.04800 \n",
      "Fitting:  {'rg__alpha': 0.05} ...\n",
      "\tscore= 1.04902 \n",
      "Fitting:  {'rg__alpha': 0.1} ...\n",
      "\tscore= 1.05023 \n",
      "Fitting:  {'rg__alpha': 0.25} ...\n",
      "\tscore= 1.05349 \n",
      "Fitting:  {'rg__alpha': 0.5} ...\n",
      "\tscore= 1.05799 \n",
      "Fitting finished\n",
      "Selected hyper-params: {'rg__alpha': 0.01}\n",
      "cv score: 1.0480\n"
     ]
    }
   ],
   "source": [
    "rg_clf = Pipeline([\n",
    "    ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "    ('rg', Ridge(fit_intercept=True, normalize=True, max_iter=2000, random_state=0))\n",
    "])\n",
    "\n",
    "rg_params = {\n",
    "    'rg__alpha': [0.01, 0.05, 0.1, 0.25, 0.5],\n",
    "}\n",
    "customized_grid_search_simple_holdout_evaluate(rg_clf,X_train,y_train,rg_params,level2_date_block=[32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting with lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "       min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "       n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "       subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  {'boosting_type': 'gbdt'} ...\n",
      "\tscore= 3.86143 \n",
      "Fitting:  {'boosting_type': 'dart'} ...\n",
      "\tscore= 3.86417 \n",
      "Fitting finished\n",
      "Selected hyper-params: {'boosting_type': 'gbdt'}\n",
      "cv score: 3.8614\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.LGBMRegressor(random_state=0, n_jobs=4)\n",
    "\n",
    "# 1. find an optimal n_esti for rather larger learning rate\n",
    "lgb_params = {\n",
    "    'boosting_type': ['gbdt', 'dart']\n",
    "}\n",
    "customized_grid_search_simple_holdout_evaluate(lgb_clf, X_train, y_train, lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 1.25148\n",
      "[2]\tvalid_0's l2: 1.21532\n",
      "[3]\tvalid_0's l2: 1.18213\n",
      "[4]\tvalid_0's l2: 1.15218\n",
      "[5]\tvalid_0's l2: 1.12544\n",
      "[6]\tvalid_0's l2: 1.10107\n",
      "[7]\tvalid_0's l2: 1.08161\n",
      "[8]\tvalid_0's l2: 1.06201\n",
      "[9]\tvalid_0's l2: 1.04644\n",
      "[10]\tvalid_0's l2: 1.03051\n",
      "[11]\tvalid_0's l2: 1.01674\n",
      "[12]\tvalid_0's l2: 1.00508\n",
      "[13]\tvalid_0's l2: 0.994445\n",
      "[14]\tvalid_0's l2: 0.983983\n",
      "[15]\tvalid_0's l2: 0.976331\n",
      "[16]\tvalid_0's l2: 0.967952\n",
      "[17]\tvalid_0's l2: 0.961462\n",
      "[18]\tvalid_0's l2: 0.955311\n",
      "[19]\tvalid_0's l2: 0.949478\n",
      "[20]\tvalid_0's l2: 0.944066\n",
      "[21]\tvalid_0's l2: 0.939371\n",
      "[22]\tvalid_0's l2: 0.934854\n",
      "[23]\tvalid_0's l2: 0.931173\n",
      "[24]\tvalid_0's l2: 0.927503\n",
      "[25]\tvalid_0's l2: 0.92477\n",
      "[26]\tvalid_0's l2: 0.922092\n",
      "[27]\tvalid_0's l2: 0.919534\n",
      "[28]\tvalid_0's l2: 0.917342\n",
      "[29]\tvalid_0's l2: 0.914299\n",
      "[30]\tvalid_0's l2: 0.912371\n",
      "[31]\tvalid_0's l2: 0.91075\n",
      "[32]\tvalid_0's l2: 0.907972\n",
      "[33]\tvalid_0's l2: 0.906328\n",
      "[34]\tvalid_0's l2: 0.904798\n",
      "[35]\tvalid_0's l2: 0.9034\n",
      "[36]\tvalid_0's l2: 0.902357\n",
      "[37]\tvalid_0's l2: 0.901762\n",
      "[38]\tvalid_0's l2: 0.900695\n",
      "[39]\tvalid_0's l2: 0.899594\n",
      "[40]\tvalid_0's l2: 0.898507\n",
      "[41]\tvalid_0's l2: 0.89771\n",
      "[42]\tvalid_0's l2: 0.89709\n",
      "[43]\tvalid_0's l2: 0.896823\n",
      "[44]\tvalid_0's l2: 0.896154\n",
      "[45]\tvalid_0's l2: 0.895206\n",
      "[46]\tvalid_0's l2: 0.8941\n",
      "[47]\tvalid_0's l2: 0.893458\n",
      "[48]\tvalid_0's l2: 0.892858\n",
      "[49]\tvalid_0's l2: 0.891942\n",
      "[50]\tvalid_0's l2: 0.891421\n",
      "[51]\tvalid_0's l2: 0.89099\n",
      "[52]\tvalid_0's l2: 0.889762\n",
      "[53]\tvalid_0's l2: 0.889622\n",
      "[54]\tvalid_0's l2: 0.889275\n",
      "[55]\tvalid_0's l2: 0.888709\n",
      "[56]\tvalid_0's l2: 0.887983\n",
      "[57]\tvalid_0's l2: 0.887323\n",
      "[58]\tvalid_0's l2: 0.886829\n",
      "[59]\tvalid_0's l2: 0.886571\n",
      "[60]\tvalid_0's l2: 0.886285\n",
      "[61]\tvalid_0's l2: 0.885943\n",
      "[62]\tvalid_0's l2: 0.885388\n",
      "[63]\tvalid_0's l2: 0.885065\n",
      "[64]\tvalid_0's l2: 0.884912\n",
      "[65]\tvalid_0's l2: 0.884123\n",
      "[66]\tvalid_0's l2: 0.883287\n",
      "[67]\tvalid_0's l2: 0.883066\n",
      "[68]\tvalid_0's l2: 0.8831\n",
      "[69]\tvalid_0's l2: 0.882906\n",
      "[70]\tvalid_0's l2: 0.882091\n",
      "[71]\tvalid_0's l2: 0.880737\n",
      "[72]\tvalid_0's l2: 0.879755\n",
      "[73]\tvalid_0's l2: 0.879498\n",
      "[74]\tvalid_0's l2: 0.879075\n",
      "[75]\tvalid_0's l2: 0.878883\n",
      "[76]\tvalid_0's l2: 0.878501\n",
      "[77]\tvalid_0's l2: 0.878065\n",
      "[78]\tvalid_0's l2: 0.877612\n",
      "[79]\tvalid_0's l2: 0.876986\n",
      "[80]\tvalid_0's l2: 0.876582\n",
      "[81]\tvalid_0's l2: 0.876417\n",
      "[82]\tvalid_0's l2: 0.875974\n",
      "[83]\tvalid_0's l2: 0.875749\n",
      "[84]\tvalid_0's l2: 0.875349\n",
      "[85]\tvalid_0's l2: 0.874998\n",
      "[86]\tvalid_0's l2: 0.874686\n",
      "[87]\tvalid_0's l2: 0.874049\n",
      "[88]\tvalid_0's l2: 0.873943\n",
      "[89]\tvalid_0's l2: 0.873652\n",
      "[90]\tvalid_0's l2: 0.873526\n",
      "[91]\tvalid_0's l2: 0.874015\n",
      "[92]\tvalid_0's l2: 0.873947\n",
      "[93]\tvalid_0's l2: 0.87372\n",
      "[94]\tvalid_0's l2: 0.873449\n",
      "[95]\tvalid_0's l2: 0.873596\n",
      "[96]\tvalid_0's l2: 0.872617\n",
      "[97]\tvalid_0's l2: 0.872357\n",
      "[98]\tvalid_0's l2: 0.872166\n",
      "[99]\tvalid_0's l2: 0.872034\n",
      "[100]\tvalid_0's l2: 0.871858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',\n",
       "       class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,\n",
       "       learning_rate=0.05, max_depth=-1, metric={'l2', 'mse'},\n",
       "       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "       n_estimators=100, n_jobs=-1, num_leaves=31, objective='regression',\n",
       "       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=200000, subsample_freq=1,\n",
       "       task='train', verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'mse'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "gbm = lgb.LGBMRegressor(**params)\n",
    "gbm.fit(X_train,y_train,eval_metric='l2',eval_set=[(X_cv,y_cv)],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
