{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Level Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load pre-processing data\n",
    "    - downcast to float32, int32 \n",
    "2. Train the first level models\n",
    "    - validate model with simple hold out method\n",
    "    - several models\n",
    "        - linear \n",
    "        - tree based\n",
    "        - knn\n",
    "        - kmean\n",
    "    - features gen by stacking \n",
    "3. Text features extraction \n",
    "    - tfidf + svd\n",
    "    - tfidf(Binary) + svd\n",
    "    - hash + svd\n",
    "    - hash(Binary) + svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/X_cv', '/X_test', '/X_train', '/y_cv', '/y_train']\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('../data/feat/data.h5') as store:\n",
    "    print(store.keys())\n",
    "    X_train = store['X_train']\n",
    "    X_cv = store['X_cv']\n",
    "    y_train = store['y_train']\n",
    "    y_cv = store['y_cv']\n",
    "    X_test = store['X_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.date_block_num.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - clip to (0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.clip(0,20)\n",
    "y_cv = y_cv.clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10675632, 54)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- downcast to `float32`, `int32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = downcast_dtypes(X_train)\n",
    "X_cv = downcast_dtypes(X_cv)\n",
    "X_test = downcast_dtypes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.float32)\n",
    "y_cv = y_cv.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `fillna` with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(0,inplace=True)\n",
    "X_cv.fillna(0,inplace=True)\n",
    "X_test.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Train /test reduce\n",
    "We take only `date_block_num` between `12~32`\n",
    "- memory issue\n",
    "- time cost issue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates = X_train.date_block_num\n",
    "\n",
    "mask = train_dates >= 12 # mask=0 : all consider , mask>=12\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "train_dates = train_dates[mask]\n",
    "test_dates = X_test.date_block_num\n",
    "cv_dates = X_cv.date_block_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6186922, 54)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. First Level Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "level2_date_block @ 31,32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates = X_train.date_block_num\n",
    "\n",
    "# level2_date_block = [27, 28, 29, 30, 31, 32]\n",
    "level2_date_block = [31,32]\n",
    "# level2_date_block = [32]\n",
    "level2_mask = train_dates.isin(level2_date_block)\n",
    "train_dates_level2 = train_dates[level2_mask]\n",
    "train_y_level2 = y_train[level2_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433191,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dates_level2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 custom grid search \n",
    "    - stolen from top20 kaggler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_grid_search_cv_evaluate(clf, X_train, y_train, param_grid):\n",
    "    \n",
    "    params_list = list(ParameterGrid(param_grid))\n",
    "    res_df = pd.DataFrame(data=np.zeros((len(params_list),3)), columns=['params', 'mean_test_score', 'std_test_score'])\n",
    "    res_df.loc[:,'params'] = params_list\n",
    "    \n",
    "    for i, params in enumerate(params_list):\n",
    "        scores = []\n",
    "        print('Fitting: ', params, '...', end='\\n\\tscores= ')\n",
    "        for cur_block in level2_date_block:\n",
    "            copy_clf = copy.deepcopy(clf)\n",
    "            original_param = copy_clf.get_params()\n",
    "            original_param.update(params)\n",
    "            copy_clf.set_params(**original_param) # update copy clf with trying params \n",
    "            \n",
    "            copy_clf.fit(X_train[train_dates < cur_block].values, y_train[train_dates < cur_block])\n",
    "            pred_y = copy_clf.predict(X_train[train_dates == cur_block].values)\n",
    "            pred_y = np.clip(pred_y, 0., 20.)\n",
    "            score = mean_squared_error(y_train[train_dates == cur_block], pred_y)**.5\n",
    "            print('{:.5f} '.format(score), end='')\n",
    "            scores.append(score)\n",
    "            del copy_clf; gc.collect()\n",
    "        \n",
    "        print('')\n",
    "        res_df.loc[i, 'mean_test_score'] = np.mean(scores)\n",
    "        res_df.loc[i, 'std_test_score'] = np.std(scores)\n",
    "        \n",
    "    print('Fitting finished')\n",
    "    res_df = res_df.sort_values(by=['mean_test_score', 'std_test_score'], ascending=True).reset_index(drop=True)\n",
    "    best_params = res_df.loc[0, 'params']\n",
    "    \n",
    "    print('Selected hyper-params:', best_params)\n",
    "    print('cv score: {:.4f}, std: {:.4f}'.format(res_df.loc[0, 'mean_test_score'], res_df.loc[0, 'std_test_score']))\n",
    "    del res_df, params_list; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_grid_search_simple_holdout_evaluate(clf, X_train, y_train, param_grid, level2_date_block=[32]):\n",
    "    \n",
    "    params_list = list(ParameterGrid(param_grid))\n",
    "    res_df = pd.DataFrame(data=np.zeros((len(params_list),2)), columns=['params', 'val_score'])\n",
    "    res_df.loc[:,'params'] = params_list\n",
    "    \n",
    "    train_mask = train_dates < level2_date_block[0]\n",
    "    validation_mask = (train_dates >= level2_date_block[0]) & (train_dates <= level2_date_block[-1])\n",
    "    for i, params in enumerate(params_list):\n",
    "        print('Fitting: ', params, '...', end='\\n\\tscore= ')\n",
    "        \n",
    "        copy_clf = copy.deepcopy(clf)\n",
    "        original_param = copy_clf.get_params()\n",
    "        original_param.update(params)\n",
    "        copy_clf.set_params(**original_param) # update copy clf with trying params \n",
    "\n",
    "        copy_clf.fit(X_train[train_mask].values, y_train[train_mask])\n",
    "        pred_y = copy_clf.predict(X_train[validation_mask].values)\n",
    "        pred_y = np.clip(pred_y, 0., 20.)\n",
    "        score = mean_squared_error(y_train[validation_mask], pred_y)**.5\n",
    "        print('{:.5f} '.format(score), end='\\n')\n",
    "        del copy_clf; gc.collect()\n",
    "\n",
    "        res_df.loc[i, 'val_score'] = score\n",
    "        \n",
    "    print('Fitting finished')\n",
    "    res_df = res_df.sort_values(by=['val_score'], ascending=True).reset_index(drop=True)\n",
    "    best_params = res_df.loc[0, 'params']\n",
    "    \n",
    "    print('Selected hyper-params:', best_params)\n",
    "    print('cv score: {:.4f}'.format(res_df.loc[0, 'val_score']))\n",
    "    del res_df, params_list; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Optimization\n",
    "- with `hyperopt` library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- simple hold out method to optimize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    '''\n",
    "        calculate rmse with simple holdout method \n",
    "        \n",
    "        -- train on `train_dates < level2_date_block[0]` \n",
    "        -- validate on `leve2_date_block`  (date_block_num : 27-32)\n",
    "    '''\n",
    "    ## extract clf and new_params from `params`\n",
    "    clf = params.get('clf')\n",
    "    new_params = params.get('params') ## update params\n",
    "    \n",
    "    ## update params\n",
    "    copy_clf = copy.deepcopy(clf)\n",
    "    original_params = copy_clf.get_params()\n",
    "    original_params.update(new_params)\n",
    "    copy_clf.set_params(**original_params) # update copy clf with trying new_params     \n",
    "    \n",
    "    train_mask = train_dates < level2_date_block[0]\n",
    "    \n",
    "    ## simple hold out method\n",
    "    ## validate on the level2_date_block\n",
    "    validation_mask = (train_dates >= level2_date_block[0]) & (train_dates <= level2_date_block[-1]) \n",
    "    \n",
    "    copy_clf.fit(X_train[train_mask].values, y_train[train_mask]) ## train on <27 , validate on 27-32\n",
    "        \n",
    "    pred_y = copy_clf.predict(X_train[validation_mask].values)\n",
    "    pred_y = np.clip(pred_y, 0., 20.) # clip to (0,20)\n",
    "    rmse = mean_squared_error(y_train[validation_mask], pred_y)**.5\n",
    "    print('rmse: {:.5f} '.format(rmse), end='\\t')\n",
    "    print('params: {}'.format(new_params))\n",
    "    \n",
    "    return {'loss':rmse,'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model \n",
    "- Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso #featuring L2/L1 regularized linear models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  {'rg__alpha': 0.0} ...\n",
      "\tscore= 0.96775 \n",
      "Fitting:  {'rg__alpha': 0.20000000000000001} ...\n",
      "\tscore= 0.96510 \n",
      "Fitting:  {'rg__alpha': 0.40000000000000002} ...\n",
      "\tscore= 0.96600 \n",
      "Fitting:  {'rg__alpha': 0.60000000000000009} ...\n",
      "\tscore= 0.96738 \n",
      "Fitting:  {'rg__alpha': 0.80000000000000004} ...\n",
      "\tscore= 0.96910 \n",
      "Fitting finished\n",
      "Selected hyper-params: {'rg__alpha': 0.20000000000000001}\n",
      "cv score: 0.9651\n"
     ]
    }
   ],
   "source": [
    "## try simple-hold-out grid serach\n",
    "rg_clf = Pipeline([\n",
    "    ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "    ('rg', Ridge(fit_intercept=True, normalize=True, max_iter=2000, random_state=0))\n",
    "])\n",
    "rg_params = {\n",
    "    'rg__alpha': np.arange(0,1,0.2)\n",
    "}\n",
    "\n",
    "customized_grid_search_simple_holdout_evaluate(rg_clf,X_train,y_train,param_grid=rg_params,level2_date_block=level2_date_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 1.00357 \tparams: {'rg__alpha': 0.04080360347886225}\n",
      "rmse: 1.00317 \tparams: {'rg__alpha': 0.025410732521240376}\n",
      "rmse: 1.00342 \tparams: {'rg__alpha': 0.034911349319165064}\n",
      "rmse: 1.01571 \tparams: {'rg__alpha': 0.7118020171649374}\n",
      "rmse: 1.01847 \tparams: {'rg__alpha': 0.9214224958287398}\n",
      "rmse: 1.00790 \tparams: {'rg__alpha': 0.23520375805316973}\n",
      "rmse: 1.01593 \tparams: {'rg__alpha': 0.7279100564363649}\n",
      "rmse: 1.01644 \tparams: {'rg__alpha': 0.7650441014491024}\n",
      "rmse: 1.01877 \tparams: {'rg__alpha': 0.945986312934316}\n",
      "rmse: 1.01007 \tparams: {'rg__alpha': 0.35088290894136054}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "rg_clf = Pipeline([\n",
    "    ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "    ('rg', Ridge(fit_intercept=True, normalize=True, max_iter=2000, random_state=0))\n",
    "])\n",
    "rg_params = {\n",
    "    'clf':rg_clf,\n",
    "    'params': {'rg__alpha': hp.uniform('rg__alpha', 0, 1)},\n",
    "}\n",
    "\n",
    "best = fmin(fn = objective,\n",
    "            space = rg_params,\n",
    "            algo = tpe.suggest,\n",
    "            trials = trials,\n",
    "            max_evals = 10\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rg__alpha': 0.025410732521240376}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">rmse:0.96508 \n",
    " - alpha : 0.193929"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* linear svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.LinearSVR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 1.00416 \tparams: {'lasso__alpha': 0.009869086395721482}\n",
      "rmse: 1.02777 \tparams: {'lasso__alpha': 0.0907611500382878}\n",
      "rmse: 1.02902 \tparams: {'lasso__alpha': 0.09572609233971596}\n",
      "rmse: 1.02897 \tparams: {'lasso__alpha': 0.09552780779733748}\n",
      "rmse: 1.01632 \tparams: {'lasso__alpha': 0.050759576343417726}\n",
      "rmse: 1.01541 \tparams: {'lasso__alpha': 0.047752693076762553}\n",
      "rmse: 1.01148 \tparams: {'lasso__alpha': 0.03489274382258616}\n",
      "rmse: 1.00366 \tparams: {'lasso__alpha': 0.006940518212747282}\n",
      "rmse: 1.01811 \tparams: {'lasso__alpha': 0.05646730195223748}\n",
      "rmse: 1.02094 \tparams: {'lasso__alpha': 0.06545538392838314}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "lasso_clf = Pipeline([\n",
    "    ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "    ('lasso', Lasso(random_state=0))\n",
    "])\n",
    "\n",
    "lasso_params = {\n",
    "    'clf':lasso_clf,\n",
    "    'params': {\n",
    "        'lasso__alpha': hp.uniform('lasso__alpha',0,0.1)\n",
    "    },    \n",
    "}\n",
    "\n",
    "best = fmin(fn = objective,\n",
    "            space = lasso_params,\n",
    "            algo = tpe.suggest,\n",
    "            trials = trials,\n",
    "            max_evals = 10\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso__alpha': 0.006940518212747282}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.96565 \tparams: {'lasso__alpha': 0.021311}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.9656547294753367, 'status': 'ok'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lasso_params = {\n",
    "#     'clf':lasso_clf,\n",
    "#     'params': {\n",
    "#         'lasso__alpha': 0.021311\n",
    "#     },    \n",
    "# }\n",
    "# objective(lasso_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> rmse: 0.96565\n",
    "    - alpha: 0.021311"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree based model \n",
    "- lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "       min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "       n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "       subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = lgb.LGBMRegressor(random_state=0, n_jobs=4)\n",
    "\n",
    "# 1. find an optimal n_esti for rather larger learning rate\n",
    "lgb_params = {\n",
    "    'boosting_type': ['gbdt', 'dart']\n",
    "}\n",
    "\n",
    "\n",
    "customized_grid_search_simple_holdout_evaluate(lgb_clf, X_train, y_train, lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  {'learning_rate': 0.2, 'n_estimators': 10} ...\n",
      "\tscore= 0.90978 \n",
      "Fitting:  {'learning_rate': 0.2, 'n_estimators': 20} ...\n",
      "\tscore= 0.89607 \n",
      "Fitting:  {'learning_rate': 0.2, 'n_estimators': 40} ...\n",
      "\tscore= 0.89238 \n",
      "Fitting:  {'learning_rate': 0.2, 'n_estimators': 60} ...\n",
      "\tscore= 0.89089 \n",
      "Fitting:  {'learning_rate': 0.2, 'n_estimators': 80} ...\n",
      "\tscore= 0.89274 \n",
      "Fitting:  {'learning_rate': 0.1, 'n_estimators': 10} ...\n",
      "\tscore= 0.94879 \n",
      "Fitting:  {'learning_rate': 0.1, 'n_estimators': 20} ...\n",
      "\tscore= 0.91117 \n",
      "Fitting:  {'learning_rate': 0.1, 'n_estimators': 40} ...\n",
      "\tscore= 0.89477 \n",
      "Fitting:  {'learning_rate': 0.1, 'n_estimators': 60} ...\n",
      "\tscore= 0.89334 \n",
      "Fitting:  {'learning_rate': 0.1, 'n_estimators': 80} ...\n",
      "\tscore= 0.89265 \n",
      "Fitting:  {'learning_rate': 0.075, 'n_estimators': 10} ...\n",
      "\tscore= 0.97447 \n",
      "Fitting:  {'learning_rate': 0.075, 'n_estimators': 20} ...\n",
      "\tscore= 0.92518 \n",
      "Fitting:  {'learning_rate': 0.075, 'n_estimators': 40} ...\n",
      "\tscore= 0.90328 \n",
      "Fitting:  {'learning_rate': 0.075, 'n_estimators': 60} ...\n",
      "\tscore= "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-34b056cdb550>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.075\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m }\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcustomized_grid_search_simple_holdout_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgb_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlgb_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-7fc7631bf6c2>\u001b[0m in \u001b[0;36mcustomized_grid_search_simple_holdout_evaluate\u001b[1;34m(clf, X_train, y_train, param_grid, level2_date_block)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mcopy_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0moriginal_param\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# update copy clf with trying params\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mcopy_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalidation_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    616\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m                                        callbacks=callbacks)\n\u001b[0m\u001b[0;32m    619\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    471\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1519\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1521\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.LGBMRegressor(boosting_type='gbdt', learning_rate=0.1, random_state=0, n_jobs =4)\n",
    "\n",
    "# 1. find an optimal n_esti for rather larger learning rate\n",
    "lgb_params = {\n",
    "    'n_estimators': [10, 20, 40, 60, 80],\n",
    "    'learning_rate': [0.2, 0.1, 0.075, 0.05]\n",
    "}\n",
    "customized_grid_search_simple_holdout_evaluate(lgb_clf, X_train, y_train, lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = lgb.LGBMRegressor(boosting_type='gbdt', learning_rate=0.1, n_estimators=40,\n",
    "                            random_state=0, n_jobs =4)\n",
    "\n",
    "\n",
    "\n",
    "# 2. tune tree-specific params\n",
    "lgb_params = {\n",
    "    'max_depth': [4, 6, 8, 10, 12],\n",
    "}\n",
    "customized_grid_search_simple_holdout_evaluate(lgb_clf, X_train, y_train, lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = lgb.LGBMRegressor(boosting_type='gbdt', learning_rate=0.1, n_estimators=40,\n",
    "                            max_depth=12, \n",
    "                            random_state=0, n_jobs =4)\n",
    "\n",
    "\n",
    "# 2. tune tree-specific params\n",
    "lgb_params = {\n",
    "    'min_split_gain': [.0, .1, .2],\n",
    "    'min_child_samples': [20, 40, 80], ## min_data_in_leaf\n",
    "}\n",
    "customized_grid_search_simple_holdout_evaluate(lgb_clf, X_train, y_train, lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = lgb.LGBMRegressor(boosting_type='gbdt', learning_rate=0.1, n_estimators=40,\n",
    "                            max_depth=12, min_child_samples=20, min_split_gain=0.0,\n",
    "                            random_state=0, n_jobs=4)\n",
    "\n",
    "# 2. tune tree-specific params\n",
    "lgb_params = {\n",
    "    'subsample': [.2, .4, .6, .8, 1.],\n",
    "    'colsample_bytree': [.2, .4, .6, .8, 1.]\n",
    "}\n",
    "customized_grid_search_simple_holdout_evaluate(lgb_clf, X_train, y_train, lgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> use hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.86781 \tparams: {'bagging_fraction': 0.8526347938264912, 'boosting_type': 'dart', 'feature_fraction': 0.3713832005356714, 'gamma': 0.3513437876057838, 'max_depth': 12, 'num_leaves': 36, 'reg_lambda': 0.3314183540297525}\n",
      "rmse: 0.88221 \tparams: {'bagging_fraction': 0.7561365505609431, 'boosting_type': 'dart', 'feature_fraction': 0.6631183939697767, 'gamma': 0.10476140323208019, 'max_depth': 4, 'num_leaves': 30, 'reg_lambda': 0.6313148071988549}\n",
      "rmse: 0.83194 \tparams: {'bagging_fraction': 0.9187387422237163, 'boosting_type': 'gbdt', 'feature_fraction': 0.8084801260455161, 'gamma': 0.25342233715729756, 'max_depth': 12, 'num_leaves': 36, 'reg_lambda': 0.9346223808836792}\n",
      "rmse: 0.83162 \tparams: {'bagging_fraction': 0.8914728193944422, 'boosting_type': 'gbdt', 'feature_fraction': 0.6805724910142892, 'gamma': 0.49912184111068736, 'max_depth': 7, 'num_leaves': 106, 'reg_lambda': 0.4603614731830482}\n",
      "rmse: 0.85809 \tparams: {'bagging_fraction': 0.8772487776479582, 'boosting_type': 'dart', 'feature_fraction': 0.4096305424714555, 'gamma': 0.34929281868219775, 'max_depth': 13, 'num_leaves': 80, 'reg_lambda': 0.37188951741776977}\n",
      "rmse: 0.86709 \tparams: {'bagging_fraction': 0.7016913073260398, 'boosting_type': 'dart', 'feature_fraction': 0.8560400574024338, 'gamma': 0.4246273160859152, 'max_depth': 13, 'num_leaves': 16, 'reg_lambda': 0.09779791198380083}\n",
      "rmse: 0.88383 \tparams: {'bagging_fraction': 0.8273198270382809, 'boosting_type': 'dart', 'feature_fraction': 0.40781683054464307, 'gamma': 0.1742814800689673, 'max_depth': 13, 'num_leaves': 10, 'reg_lambda': 0.49649820520767607}\n",
      "rmse: 0.87527 \tparams: {'bagging_fraction': 0.9535359532202721, 'boosting_type': 'dart', 'feature_fraction': 0.6018465918295672, 'gamma': 0.1382373751404884, 'max_depth': 6, 'num_leaves': 20, 'reg_lambda': 0.2261521732335654}\n",
      "rmse: 0.88467 \tparams: {'bagging_fraction': 0.9404125524291072, 'boosting_type': 'dart', 'feature_fraction': 0.32254933830736887, 'gamma': 0.2679727801814501, 'max_depth': 5, 'num_leaves': 62, 'reg_lambda': 0.0223068806459501}\n",
      "rmse: 0.86143 \tparams: {'bagging_fraction': 0.8397376580620999, 'boosting_type': 'dart', 'feature_fraction': 0.43487846011614495, 'gamma': 0.1389156916188244, 'max_depth': 15, 'num_leaves': 48, 'reg_lambda': 0.059362258036086635}\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.LGBMRegressor(random_state=0, n_jobs=8)\n",
    "trials = Trials()\n",
    "# 1. find an optimal n_esti for rather larger learning rate\n",
    "lgb_params = {\n",
    "    'clf' : lgb_clf,\n",
    "    'params': {\n",
    "        'boosting_type': hp.choice('boosting_type',['gbdt', 'dart']), ## gbdt \n",
    "#         'boosting_type': []'gbdt',\n",
    "        'num_leaves'   : hp.choice('num_leaves', np.arange(8,129,2,dtype=int)),\n",
    "        'max_depth' : hp.choice(\"max_depth\", np.arange(4, 17, dtype=int)),    \n",
    "        'feature_fraction': hp.uniform('feature_fraction', 0.3, 1.0),\n",
    "        'bagging_fraction': hp.uniform ('bagging_fraction', 0.7, 1),\n",
    "        'reg_lambda': hp.uniform('reg_lambda',0,1),\n",
    "        'gamma' : hp.uniform('gamma', 0.1,0.5)\n",
    "    }\n",
    "    \n",
    "}\n",
    "best =fmin(fn = objective,\n",
    "           space = lgb_params,\n",
    "           algo = tpe.suggest,\n",
    "           trials = trials,\n",
    "           max_evals = 10\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.8316196011425457, 'status': 'ok'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rmse: 0.83162 \n",
    "\n",
    "params: {'bagging_fraction': 0.8914728193944422, 'boosting_type': 'gbdt', 'feature_fraction': 0.6805724910142892, 'gamma': 0.49912184111068736, 'max_depth': 7, 'num_leaves': 106, 'reg_lambda': 0.4603614731830482}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.81909 \tparams: {'bagging_fraction': 0.9568845079308161, 'bossting_type': 'gbdt', 'feature_fraction': 0.6203248801718259, 'gamma': 0.39624896070423066, 'max_depth': 12, 'metric': 'rmse', 'num_leaves': 64, 'objective': 'regression', 'reg_lambda': 0.38856229720270463}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.81908550940125358, 'status': 'ok'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use pre-train params from lgb_model1\n",
    "lgb_clf = lgb.LGBMRegressor(random_state=0)\n",
    "lgb_params = {\n",
    "    'clf':lgb_clf,\n",
    "    'params':{\n",
    "        'bagging_fraction': 0.9568845079308161,\n",
    "        'bossting_type': 'gbdt',\n",
    "        'feature_fraction': 0.6203248801718259,\n",
    "        'gamma': 0.39624896070423066,\n",
    "        'max_depth': 12,\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': 64,\n",
    "        'objective': 'regression',\n",
    "        'reg_lambda': 0.38856229720270463\n",
    "    }\n",
    "}\n",
    "objective(lgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> rmse: 0.81909\n",
    "    - {'bagging_fraction': 0.9568845079308161, 'bossting_type': 'gbdt', 'feature_fraction': 0.6203248801718259, 'gamma': 0.39624896070423066, 'max_depth': 12, 'metric': 'rmse', 'num_leaves': 64, 'objective': 'regression', 'reg_lambda': 0.38856229720270463}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.9194917662233979,\n",
       " 'boosting_type': 0,\n",
       " 'feature_fraction': 0.4682043014298397,\n",
       " 'gamma': 0.3957261011649602,\n",
       " 'max_depth': 8,\n",
       " 'num_leaves': 37,\n",
       " 'reg_lambda': 0.14857448039561033}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> rmse:0.81525\n",
    "\n",
    "    > bagging_fraction:`0.9789`, \n",
    "    > feature_fraction:`0.759`,\n",
    "    > gamma : `0.1517`,\n",
    "    > reg_labmda : `0.6813`\n",
    "    > max_depth : `12`,\n",
    "    > num_leaves : `110`,\n",
    "    > bossting_type : `gbdt`,\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.85051 \tparams: {'max_depth': 16, 'min_samples_leaf': 30, 'min_samples_split': 400, 'n_estimators': 150}\n",
      "rmse: 0.88084 \tparams: {'max_depth': 8, 'min_samples_leaf': 30, 'min_samples_split': 200, 'n_estimators': 300}\n",
      "rmse: 0.92693 \tparams: {'max_depth': 4, 'min_samples_leaf': 30, 'min_samples_split': 400, 'n_estimators': 250}\n",
      "rmse: 0.86244 \tparams: {'max_depth': 12, 'min_samples_leaf': 50, 'min_samples_split': 400, 'n_estimators': 200}\n",
      "rmse: 0.92699 \tparams: {'max_depth': 4, 'min_samples_leaf': 80, 'min_samples_split': 200, 'n_estimators': 250}\n",
      "rmse: 0.84882 \tparams: {'max_depth': 16, 'min_samples_leaf': 40, 'min_samples_split': 100, 'n_estimators': 300}\n",
      "rmse: 0.85072 \tparams: {'max_depth': 16, 'min_samples_leaf': 70, 'min_samples_split': 100, 'n_estimators': 300}\n",
      "rmse: 0.92655 \tparams: {'max_depth': 4, 'min_samples_leaf': 50, 'min_samples_split': 200, 'n_estimators': 200}\n",
      "rmse: 0.92616 \tparams: {'max_depth': 4, 'min_samples_leaf': 70, 'min_samples_split': 200, 'n_estimators': 100}\n",
      "rmse: 0.86209 \tparams: {'max_depth': 12, 'min_samples_leaf': 30, 'min_samples_split': 400, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestRegressor(min_samples_split=300, min_samples_leaf=30, max_features='sqrt',n_estimators=50,\n",
    "                               max_depth=4, n_jobs=4, criterion='mse',random_state=0)\n",
    "\n",
    "rf_clf.estimators_=1 # need to set a value otherwise rise AttributeError in hyperopt\n",
    "rf_params = {\n",
    "    'clf' : rf_clf,\n",
    "    'params' : {\n",
    "        'min_samples_split' : hp.choice('min_samples_split',np.arange(100,500,100)),\n",
    "        'min_samples_leaf': hp.choice('min_samples_leaf',np.arange(30,100,10)),\n",
    "        'n_estimators' : hp.choice('n_estimators', np.arange(50,301,50)),\n",
    "        'max_depth': hp.choice('max_depth',[4, 8, 12, 16])        \n",
    "    }    \n",
    "}\n",
    "\n",
    "best =fmin(fn = objective,\n",
    "           space = rf_params,\n",
    "           algo = tpe.suggest,\n",
    "           max_evals = 10\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> rmse: `0.82801`\n",
    " - max_depth = `16`\n",
    " - min_samples_leaf = `50`\n",
    " - min_samples_split = `200`\n",
    " - n_estimators = `300`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN  model\n",
    "\n",
    "- KNN: Prediction and Neighbor distances features\n",
    "\n",
    " Time cost a lot(>2 days), I give it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "knn_clf = KNeighborsRegressor(algorithm='auto', leaf_size=100, metric='minkowski',\n",
    "                              metric_params=None, n_jobs=4, n_neighbors=5, p=1,\n",
    "                              weights='uniform')\n",
    "knn_params = {\n",
    "    'clf' : knn_clf,\n",
    "    'params' :{\n",
    "        'p': hp.choice('p',[1,2]),\n",
    "        'weights': hp.choice('weights',['uniform', 'distance']),\n",
    "        'n_neighbors': hp.choice('n_neighbors', np.arange(10, 101, 10,dtype=int))\n",
    "    }\n",
    "}\n",
    "best = fmin(fn = objective,\n",
    "            space = knn_params,\n",
    "            algo = tpe.suggest,\n",
    "            trials = trials,\n",
    "            max_evals = 5\n",
    "           )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> knn: \n",
    "    - n_neighbors = `15`\n",
    "    - weights = `distance`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans\n",
    "- mini-batch kmeans cast to low dimensional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.metrics import calinski_harabaz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238172, 54)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.concat([X_train, X_cv,X_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294, 54)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_id_avg_item_price_lag_1</th>\n",
       "      <th>item_id_sum_item_cnt_day_lag_1</th>\n",
       "      <th>item_id_avg_item_cnt_day_lag_1</th>\n",
       "      <th>shop_id_avg_item_price_lag_1</th>\n",
       "      <th>shop_id_sum_item_cnt_day_lag_1</th>\n",
       "      <th>shop_id_avg_item_cnt_day_lag_1</th>\n",
       "      <th>...</th>\n",
       "      <th>item_id_avg_item_price_lag_12</th>\n",
       "      <th>item_id_sum_item_cnt_day_lag_12</th>\n",
       "      <th>item_id_avg_item_cnt_day_lag_12</th>\n",
       "      <th>shop_id_avg_item_price_lag_12</th>\n",
       "      <th>shop_id_sum_item_cnt_day_lag_12</th>\n",
       "      <th>shop_id_avg_item_cnt_day_lag_12</th>\n",
       "      <th>item_category_id_avg_item_price_lag_12</th>\n",
       "      <th>item_category_id_sum_item_cnt_day_lag_12</th>\n",
       "      <th>item_category_id_avg_item_cnt_day_lag_12</th>\n",
       "      <th>item_cnt_month_lag_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6639289</th>\n",
       "      <td>45</td>\n",
       "      <td>18454</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1176.795898</td>\n",
       "      <td>702.0</td>\n",
       "      <td>1.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639290</th>\n",
       "      <td>45</td>\n",
       "      <td>16188</td>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1176.795898</td>\n",
       "      <td>702.0</td>\n",
       "      <td>1.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639291</th>\n",
       "      <td>45</td>\n",
       "      <td>15757</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1176.795898</td>\n",
       "      <td>702.0</td>\n",
       "      <td>1.125</td>\n",
       "      <td>...</td>\n",
       "      <td>199.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1273.734375</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>1.268763</td>\n",
       "      <td>297.181396</td>\n",
       "      <td>9809.0</td>\n",
       "      <td>1.041406</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639292</th>\n",
       "      <td>45</td>\n",
       "      <td>19648</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>89.099998</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1176.795898</td>\n",
       "      <td>702.0</td>\n",
       "      <td>1.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639293</th>\n",
       "      <td>45</td>\n",
       "      <td>969</td>\n",
       "      <td>34</td>\n",
       "      <td>37</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1176.795898</td>\n",
       "      <td>702.0</td>\n",
       "      <td>1.125</td>\n",
       "      <td>...</td>\n",
       "      <td>549.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1273.734375</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>1.268763</td>\n",
       "      <td>457.671997</td>\n",
       "      <td>5185.0</td>\n",
       "      <td>1.076620</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         shop_id  item_id  date_block_num  item_category_id  \\\n",
       "6639289       45    18454              34                55   \n",
       "6639290       45    16188              34                64   \n",
       "6639291       45    15757              34                55   \n",
       "6639292       45    19648              34                40   \n",
       "6639293       45      969              34                37   \n",
       "\n",
       "         item_id_avg_item_price_lag_1  item_id_sum_item_cnt_day_lag_1  \\\n",
       "6639289                     99.000000                             2.0   \n",
       "6639290                   1359.000000                             1.0   \n",
       "6639291                    229.000000                             5.0   \n",
       "6639292                     89.099998                             2.0   \n",
       "6639293                    198.000000                             3.0   \n",
       "\n",
       "         item_id_avg_item_cnt_day_lag_1  shop_id_avg_item_price_lag_1  \\\n",
       "6639289                             1.0                   1176.795898   \n",
       "6639290                             1.0                   1176.795898   \n",
       "6639291                             1.0                   1176.795898   \n",
       "6639292                             1.0                   1176.795898   \n",
       "6639293                             1.0                   1176.795898   \n",
       "\n",
       "         shop_id_sum_item_cnt_day_lag_1  shop_id_avg_item_cnt_day_lag_1  \\\n",
       "6639289                           702.0                           1.125   \n",
       "6639290                           702.0                           1.125   \n",
       "6639291                           702.0                           1.125   \n",
       "6639292                           702.0                           1.125   \n",
       "6639293                           702.0                           1.125   \n",
       "\n",
       "                 ...            item_id_avg_item_price_lag_12  \\\n",
       "6639289          ...                                      0.0   \n",
       "6639290          ...                                      0.0   \n",
       "6639291          ...                                    199.0   \n",
       "6639292          ...                                      0.0   \n",
       "6639293          ...                                    549.0   \n",
       "\n",
       "         item_id_sum_item_cnt_day_lag_12  item_id_avg_item_cnt_day_lag_12  \\\n",
       "6639289                              0.0                              0.0   \n",
       "6639290                              0.0                              0.0   \n",
       "6639291                              9.0                              1.0   \n",
       "6639292                              0.0                              0.0   \n",
       "6639293                              6.0                              1.0   \n",
       "\n",
       "         shop_id_avg_item_price_lag_12  shop_id_sum_item_cnt_day_lag_12  \\\n",
       "6639289                       0.000000                              0.0   \n",
       "6639290                       0.000000                              0.0   \n",
       "6639291                    1273.734375                           1251.0   \n",
       "6639292                       0.000000                              0.0   \n",
       "6639293                    1273.734375                           1251.0   \n",
       "\n",
       "         shop_id_avg_item_cnt_day_lag_12  \\\n",
       "6639289                         0.000000   \n",
       "6639290                         0.000000   \n",
       "6639291                         1.268763   \n",
       "6639292                         0.000000   \n",
       "6639293                         1.268763   \n",
       "\n",
       "         item_category_id_avg_item_price_lag_12  \\\n",
       "6639289                                0.000000   \n",
       "6639290                                0.000000   \n",
       "6639291                              297.181396   \n",
       "6639292                                0.000000   \n",
       "6639293                              457.671997   \n",
       "\n",
       "         item_category_id_sum_item_cnt_day_lag_12  \\\n",
       "6639289                                       0.0   \n",
       "6639290                                       0.0   \n",
       "6639291                                    9809.0   \n",
       "6639292                                       0.0   \n",
       "6639293                                    5185.0   \n",
       "\n",
       "         item_category_id_avg_item_cnt_day_lag_12  item_cnt_month_lag_12  \n",
       "6639289                                  0.000000                    0.0  \n",
       "6639290                                  0.000000                    0.0  \n",
       "6639291                                  1.041406                    0.0  \n",
       "6639292                                  0.000000                    0.0  \n",
       "6639293                                  1.076620                    0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters = 4 score= 341409.019388\n",
      "n_clusters = 6 score= 263314.025485\n",
      "n_clusters = 8 score= 809444.498912\n",
      "n_clusters = 10 score= 723085.429986\n",
      "n_clusters = 12 score= 744213.776063\n",
      "n_clusters = 14 score= 632340.335443\n"
     ]
    }
   ],
   "source": [
    "for c in np.arange(4,16,2):\n",
    "    print('n_clusters =', c, end=' score= ')\n",
    "    km = Pipeline([\n",
    "        ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "        ('kmean', MiniBatchKMeans(n_clusters=c, max_no_improvement=30, \n",
    "                                  verbose=0, batch_size=1000000, random_state=0))\n",
    "    ])\n",
    "#     mini_kmean = MiniBatchKMeans(n_clusters=8, batch_size=10000, verbose=2, random_state=0)\n",
    "    labels = km.fit_predict(merge)\n",
    "    print(calinski_harabaz_score(merge, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `n_cluster = 8` ... highest score means better clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dates = np.concatenate([train_dates,cv_dates, test_dates], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_dates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6639294,)\n"
     ]
    }
   ],
   "source": [
    "merge_y = np.concatenate([y_train,y_cv, np.zeros((len(test_dates),))], axis=0)\n",
    "print(merge_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_train_dates = merge_dates[merge_dates>=level2_date_block[0]] ## 27 - 34\n",
    "stage2_train_mask = (stage2_train_dates <= level2_date_block[-1]) # train on : 27-32\n",
    "stage2_valid_mask = (stage2_train_dates == 33) ## validate on : 33\n",
    "stage2_final_train_mask = (stage2_train_dates <= 33) ## \n",
    "stage2_test_mask = (stage2_train_dates==34)\n",
    "stage2_train_y = merge_y[merge_dates>=level2_date_block[0]] ## 27-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_models = {\n",
    "    'rg': Pipeline([\n",
    "                ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "                ('rg', Ridge(alpha=0.025, fit_intercept=True, normalize=True, max_iter=2000, random_state=0))\n",
    "            ]),\n",
    "    'lasso':Pipeline([\n",
    "                    ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "                    ('lasso', Lasso(alpha=0.0094, normalize=False, fit_intercept=True, max_iter=2000, random_state=0))\n",
    "                ]),\n",
    "    'rf': RandomForestRegressor(n_estimators=300,\n",
    "                               min_samples_split=100, min_samples_leaf=40, max_features='sqrt',\n",
    "                               max_depth=16, n_jobs=4, criterion='mse', random_state=0),    \n",
    "    'lgbm': lgb.LGBMRegressor(boosting_type='gbdt', \n",
    "                                max_depth=7,\n",
    "                                num_leaves=106,\n",
    "                                bagging_fraction=0.8914728193944422,\n",
    "                                feature_fraction=0.6805724910142892,\n",
    "                                reg_lambda = 0.4603614731830482,\n",
    "                                gamma = 0.49912184111068736,\n",
    "                                metric='rmse',                            \n",
    "#                               subsample=.55, colsample_bytree=.75, ## \n",
    "                                n_jobs=4,\n",
    "                                random_state=0)\n",
    "}\n",
    "\n",
    " \n",
    "# knn = KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "#                               metric_params=None, n_jobs=4, n_neighbors=15, p=1,\n",
    "#                               weights='distance')\n",
    "\n",
    "mini_kmean = Pipeline([\n",
    "                ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "                ('kmean', MiniBatchKMeans(n_clusters=8, max_no_improvement=30, \n",
    "                                          verbose=0, batch_size=1000000, random_state=0))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(885563,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage2_feature_generate():\n",
    "    \n",
    "#     print('Training supervised models')\n",
    "    \n",
    "    all_preds = []\n",
    "    for model_name, model in supervised_models.items():\n",
    "        \n",
    "        print(model_name, end=': ')\n",
    "        preds = []\n",
    "        for cur_block in np.arange(31,35,1):#np.arange(27, 35, 1):\n",
    "            X_tr = merge[merge_dates < cur_block].values ## ndarray\n",
    "            y_tr = merge_y[merge_dates < cur_block]\n",
    "            X_test = merge[merge_dates == cur_block].values\n",
    "            \n",
    "            copy_clf = copy.deepcopy(model)\n",
    "            copy_clf.fit(X_tr, y_tr)\n",
    "            pred_test = copy_clf.predict(X_test)\n",
    "            pred_test = np.clip(pred_test, 0., 20.)\n",
    "            preds.append(pred_test)\n",
    "            print(cur_block, end=' ')\n",
    "\n",
    "        preds = np.concatenate(preds, axis=0)\n",
    "        preds = preds.reshape((len(preds), 1))\n",
    "        all_preds.append(preds)\n",
    "    \n",
    "        print('')\n",
    "        \n",
    "    #knn:\n",
    "#     print('knn')\n",
    "#     X_tr = merge[merge_dates < level2_date_block[0]].values\n",
    "#     y_tr = merge_y[merge_dates < level2_date_block[0]]\n",
    "\n",
    "#     X_test = merge[merge_dates >= level2_date_block[0]].values\n",
    "#     knn.fit(X_tr, y_tr)\n",
    "#     knn_pred = knn.predict(X_test)\n",
    "#     knn_pred = np.clip(knn_pred, 0., 20.).reshape((len(knn_pred), 1))\n",
    "#     knn_dist = knn.kneighbors(X_test, return_distance=True)[0] # distances\n",
    "#     print(np.array(knn_dist).shape)\n",
    "#     all_preds.append(knn_pred)\n",
    "#     all_preds.append(knn_dist)\n",
    "    \n",
    "    # kmeans\n",
    "    X_test = merge[merge_dates >= level2_date_block[0]].values # >=27\n",
    "    mini_kmean.fit(merge.values)\n",
    "    kmean_pred = mini_kmean.predict(X_test)\n",
    "    kmean_dist = mini_kmean.transform(X_test)\n",
    "    \n",
    "    kmean_pred = np.array(kmean_pred).reshape((len(kmean_pred),1))\n",
    "    all_preds.append(kmean_pred)\n",
    "    all_preds.append(kmean_dist)\n",
    "    \n",
    "    return np.concatenate(all_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg: 31 32 33 34 \n",
      "lasso: 31 32 33 34 \n",
      "rf: 31 32 33 34 \n",
      "lgbm: 31 32 33 34 \n"
     ]
    }
   ],
   "source": [
    "stage2_data = stage2_feature_generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(885563, 13)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rg',\n",
       " 'lasso',\n",
       " 'rf',\n",
       " 'lgbm',\n",
       " 'kmean_dist_label',\n",
       " 'kmean_dist_0',\n",
       " 'kmean_dist_1',\n",
       " 'kmean_dist_2',\n",
       " 'kmean_dist_3',\n",
       " 'kmean_dist_4',\n",
       " 'kmean_dist_5',\n",
       " 'kmean_dist_6',\n",
       " 'kmean_dist_7']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['rg', 'lasso', 'rf', 'lgbm'] ##'knn']\n",
    "# columns.extend(['knn_dist_'+str(i) for i in range(15)])\n",
    "columns.extend(['kmean_dist_label'])\n",
    "columns.extend(['kmean_dist_'+str(i) for i in range(8)])\n",
    "print(len(columns))\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_df = pd.DataFrame(data=stage2_data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rg</th>\n",
       "      <th>lasso</th>\n",
       "      <th>rf</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>kmean_dist_label</th>\n",
       "      <th>kmean_dist_0</th>\n",
       "      <th>kmean_dist_1</th>\n",
       "      <th>kmean_dist_2</th>\n",
       "      <th>kmean_dist_3</th>\n",
       "      <th>kmean_dist_4</th>\n",
       "      <th>kmean_dist_5</th>\n",
       "      <th>kmean_dist_6</th>\n",
       "      <th>kmean_dist_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.457809</td>\n",
       "      <td>0.518210</td>\n",
       "      <td>1.104751</td>\n",
       "      <td>1.234071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.857702</td>\n",
       "      <td>8.712146</td>\n",
       "      <td>6.878428</td>\n",
       "      <td>7.236687</td>\n",
       "      <td>160.683082</td>\n",
       "      <td>8.372746</td>\n",
       "      <td>10.067307</td>\n",
       "      <td>32.780615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.990932</td>\n",
       "      <td>0.951176</td>\n",
       "      <td>1.786170</td>\n",
       "      <td>2.333394</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.806890</td>\n",
       "      <td>13.463366</td>\n",
       "      <td>11.329752</td>\n",
       "      <td>7.886795</td>\n",
       "      <td>162.224312</td>\n",
       "      <td>10.882863</td>\n",
       "      <td>14.441723</td>\n",
       "      <td>33.894320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.473575</td>\n",
       "      <td>0.448425</td>\n",
       "      <td>0.640284</td>\n",
       "      <td>0.663168</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.285941</td>\n",
       "      <td>10.126022</td>\n",
       "      <td>8.115691</td>\n",
       "      <td>6.480298</td>\n",
       "      <td>161.687453</td>\n",
       "      <td>7.767159</td>\n",
       "      <td>11.381747</td>\n",
       "      <td>32.819151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.421733</td>\n",
       "      <td>0.397657</td>\n",
       "      <td>0.457851</td>\n",
       "      <td>0.487791</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.528922</td>\n",
       "      <td>8.592862</td>\n",
       "      <td>6.444938</td>\n",
       "      <td>6.349900</td>\n",
       "      <td>161.312547</td>\n",
       "      <td>7.830429</td>\n",
       "      <td>9.995115</td>\n",
       "      <td>32.689497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406524</td>\n",
       "      <td>0.390211</td>\n",
       "      <td>0.397525</td>\n",
       "      <td>0.391166</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.568154</td>\n",
       "      <td>8.632067</td>\n",
       "      <td>6.464528</td>\n",
       "      <td>6.335744</td>\n",
       "      <td>161.346125</td>\n",
       "      <td>7.866945</td>\n",
       "      <td>10.024922</td>\n",
       "      <td>32.699838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rg     lasso        rf      lgbm  kmean_dist_label  kmean_dist_0  \\\n",
       "0  0.457809  0.518210  1.104751  1.234071               1.0      8.857702   \n",
       "1  0.990932  0.951176  1.786170  2.333394               5.0     12.806890   \n",
       "2  0.473575  0.448425  0.640284  0.663168               5.0      9.285941   \n",
       "3  0.421733  0.397657  0.457851  0.487791               6.0      8.528922   \n",
       "4  0.406524  0.390211  0.397525  0.391166               6.0      8.568154   \n",
       "\n",
       "   kmean_dist_1  kmean_dist_2  kmean_dist_3  kmean_dist_4  kmean_dist_5  \\\n",
       "0      8.712146      6.878428      7.236687    160.683082      8.372746   \n",
       "1     13.463366     11.329752      7.886795    162.224312     10.882863   \n",
       "2     10.126022      8.115691      6.480298    161.687453      7.767159   \n",
       "3      8.592862      6.444938      6.349900    161.312547      7.830429   \n",
       "4      8.632067      6.464528      6.335744    161.346125      7.866945   \n",
       "\n",
       "   kmean_dist_6  kmean_dist_7  \n",
       "0     10.067307     32.780615  \n",
       "1     14.441723     33.894320  \n",
       "2     11.381747     32.819151  \n",
       "3      9.995115     32.689497  \n",
       "4     10.024922     32.699838  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_io = pd.HDFStore('../data/feat/stage2_data.h5')\n",
    "stage2_io['stage2_df'] = stage2_df\n",
    "stage2_io.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load \n",
    "# with pd.HDFStore('../data/feat/stage2_data.h5') as stage2_io:\n",
    "#     print(stage2_io.keys())\n",
    "#     stage2_df = stage2_io['stage2_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extract Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/X_text_feats', '/X_text_feats_cv', '/X_text_feats_test', '/X_text_feats_train']\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('../data/feat/text_feats.h5') as text_io:\n",
    "    print(text_io.keys())\n",
    "    X_text_feats_test = text_io['X_text_feats_test']\n",
    "    X_text_feats_cv = text_io['X_text_feats_cv']\n",
    "    X_text_feats_train = text_io['X_text_feats_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10675632, 4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_feats_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     6186922\n",
       "False    4488710\n",
       "Name: date_block_num, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.value_counts() ## reduce memory use only num_date_block >= 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10675632, 4)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_feats_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_df = pd.concat([X_text_feats_train[mask],X_text_feats_cv])\n",
    "test_text_df = X_text_feats_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6639294"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df.shape[0] + test_text_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_text_df['item_name'].map(str) + ' ' + train_text_df['item_category_name'].map(str) + ' ' + train_text_df['shop_name'].map(str)\n",
    "test_texts = test_text_df['item_name'].map(str) + ' ' + test_text_df['item_category_name'].map(str) + ' ' + test_text_df['shop_name'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts = pd.Series(np.concatenate([train_texts, test_texts], axis=0))\n",
    "del train_text_df, test_text_df, train_texts, test_texts; gc.collect()\n",
    "all_texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_text_feats_train,X_text_feats_cv,X_text_feats_test; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. TFIDF - Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(lowercase=False, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294, 63999)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_features = tv.fit_transform(all_texts)\n",
    "tv_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=20, random_state=0)\n",
    "tv_svd_features = svd.fit_transform(tv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9893320053815842"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(tv_svd_features)/(1024*1024*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TF-IDF(binarize)- Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvb_features = tv_features.astype(bool).astype(float)\n",
    "del tv_features; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294, 20)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=20, random_state=0)\n",
    "tvb_svd_features = svd.fit_transform(tvb_features)\n",
    "tvb_svd_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9893320053815842"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(tvb_svd_features)/(1024*1024*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hasing + Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer(ngram_range=(1, 2), lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294, 1048576)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hv_features = hv.fit_transform(all_texts).tocsr()\n",
    "hv_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=20, random_state=0)\n",
    "hv_svd_features = svd.fit_transform(hv_features)\n",
    "hv_svd_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(hv_svd_features)/(1024*1024*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hasing(binarize) + Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvb_features = hv_features.astype(bool).astype(float)\n",
    "del hv_features; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=20, random_state=0)\n",
    "hvb_svd_features = svd.fit_transform(hvb_features)\n",
    "hvb_svd_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.getsizeof(hvb_svd_features)/(1024*1024*1024))\n",
    "del hvb_features; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Stack them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = np.concatenate([tv_svd_features, tvb_svd_features, hv_svd_features, hvb_svd_features], axis=1)\n",
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(text_features)/(1024*1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features_df = pd.DataFrame(data=text_features, columns=['text_f_'+str(i) for i in range(80)])\n",
    "\n",
    "text_io = pd.HDFStore('../data/feat/text_feat_df.h5') \n",
    "text_io['text_feats_df'] = text_features_df\n",
    "text_io.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_texts,hv,hv_svd_features,hvb_svd_features, km, text_features;gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate stage2 text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reload data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('../data/feat/text_feat_df.h5') as text_io:\n",
    "    text_features_df = text_io['text_feats_df'] ## 12-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.concat([X_train, X_cv,X_test], ignore_index=True)\n",
    "merge_dates = np.concatenate([train_dates,cv_dates, test_dates], axis=0) ## 12-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_y = np.concatenate([y_train,y_cv, np.zeros((len(test_dates),))], axis=0) ## 12-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11128004,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11128004, 54)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10675632,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dates.shape # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level2_date_block = [27,28,29,30,31,32]\n",
    "level2_date_block = [31,32]\n",
    "stage2_train_dates = merge_dates[merge_dates>=level2_date_block[0]] # 27-34\n",
    "stage2_train_mask = (stage2_train_dates <= level2_date_block[-1]) # 27-32\n",
    "stage2_valid_mask = (stage2_train_dates == 33) # 33\n",
    "stage2_final_train_mask = (stage2_train_dates <= 33) # 27-33\n",
    "stage2_test_mask = (stage2_train_dates==34) # 34\n",
    "stage2_train_y = merge_y[merge_dates>=level2_date_block[0]] # 27-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_f_0</th>\n",
       "      <th>text_f_1</th>\n",
       "      <th>text_f_2</th>\n",
       "      <th>text_f_3</th>\n",
       "      <th>text_f_4</th>\n",
       "      <th>text_f_5</th>\n",
       "      <th>text_f_6</th>\n",
       "      <th>text_f_7</th>\n",
       "      <th>text_f_8</th>\n",
       "      <th>text_f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>text_f_70</th>\n",
       "      <th>text_f_71</th>\n",
       "      <th>text_f_72</th>\n",
       "      <th>text_f_73</th>\n",
       "      <th>text_f_74</th>\n",
       "      <th>text_f_75</th>\n",
       "      <th>text_f_76</th>\n",
       "      <th>text_f_77</th>\n",
       "      <th>text_f_78</th>\n",
       "      <th>text_f_79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.277484</td>\n",
       "      <td>-0.173652</td>\n",
       "      <td>-0.063240</td>\n",
       "      <td>-0.090207</td>\n",
       "      <td>-0.023441</td>\n",
       "      <td>-0.013428</td>\n",
       "      <td>-0.019452</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>-0.021224</td>\n",
       "      <td>0.023921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033810</td>\n",
       "      <td>-0.234008</td>\n",
       "      <td>-0.110437</td>\n",
       "      <td>-0.110263</td>\n",
       "      <td>-0.022642</td>\n",
       "      <td>-0.003122</td>\n",
       "      <td>0.056965</td>\n",
       "      <td>0.105615</td>\n",
       "      <td>0.012552</td>\n",
       "      <td>0.030759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039884</td>\n",
       "      <td>0.027490</td>\n",
       "      <td>0.048064</td>\n",
       "      <td>-0.010053</td>\n",
       "      <td>-0.005663</td>\n",
       "      <td>-0.008881</td>\n",
       "      <td>-0.013801</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>-0.008782</td>\n",
       "      <td>0.018617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050828</td>\n",
       "      <td>-0.241337</td>\n",
       "      <td>-0.108003</td>\n",
       "      <td>-0.252701</td>\n",
       "      <td>-0.059449</td>\n",
       "      <td>0.121994</td>\n",
       "      <td>-0.172504</td>\n",
       "      <td>0.083715</td>\n",
       "      <td>-0.342954</td>\n",
       "      <td>0.627240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029936</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>0.032786</td>\n",
       "      <td>-0.004073</td>\n",
       "      <td>-0.004317</td>\n",
       "      <td>-0.006618</td>\n",
       "      <td>-0.011949</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>-0.008361</td>\n",
       "      <td>0.019091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053172</td>\n",
       "      <td>-0.237839</td>\n",
       "      <td>-0.102671</td>\n",
       "      <td>-0.253724</td>\n",
       "      <td>-0.060433</td>\n",
       "      <td>0.113566</td>\n",
       "      <td>-0.164430</td>\n",
       "      <td>0.098105</td>\n",
       "      <td>-0.327809</td>\n",
       "      <td>0.576223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.065214</td>\n",
       "      <td>0.058522</td>\n",
       "      <td>0.142886</td>\n",
       "      <td>-0.053096</td>\n",
       "      <td>-0.019396</td>\n",
       "      <td>-0.012969</td>\n",
       "      <td>-0.012155</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>-0.010409</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>-0.241615</td>\n",
       "      <td>-0.115704</td>\n",
       "      <td>-0.125150</td>\n",
       "      <td>-0.025767</td>\n",
       "      <td>0.021801</td>\n",
       "      <td>-0.000432</td>\n",
       "      <td>0.083451</td>\n",
       "      <td>-0.112115</td>\n",
       "      <td>0.189098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.043049</td>\n",
       "      <td>0.019077</td>\n",
       "      <td>0.038894</td>\n",
       "      <td>0.023213</td>\n",
       "      <td>-0.013758</td>\n",
       "      <td>-0.010637</td>\n",
       "      <td>-0.013122</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>-0.012691</td>\n",
       "      <td>0.017750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>-0.240677</td>\n",
       "      <td>-0.094627</td>\n",
       "      <td>-0.177729</td>\n",
       "      <td>-0.043124</td>\n",
       "      <td>0.047342</td>\n",
       "      <td>-0.066383</td>\n",
       "      <td>0.108523</td>\n",
       "      <td>-0.167366</td>\n",
       "      <td>0.356736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_f_0  text_f_1  text_f_2  text_f_3  text_f_4  text_f_5  text_f_6  \\\n",
       "0  0.277484 -0.173652 -0.063240 -0.090207 -0.023441 -0.013428 -0.019452   \n",
       "1  0.039884  0.027490  0.048064 -0.010053 -0.005663 -0.008881 -0.013801   \n",
       "2  0.029936  0.017483  0.032786 -0.004073 -0.004317 -0.006618 -0.011949   \n",
       "3  0.065214  0.058522  0.142886 -0.053096 -0.019396 -0.012969 -0.012155   \n",
       "4  0.043049  0.019077  0.038894  0.023213 -0.013758 -0.010637 -0.013122   \n",
       "\n",
       "   text_f_7  text_f_8  text_f_9    ...      text_f_70  text_f_71  text_f_72  \\\n",
       "0  0.007843 -0.021224  0.023921    ...      -0.033810  -0.234008  -0.110437   \n",
       "1  0.008955 -0.008782  0.018617    ...       0.050828  -0.241337  -0.108003   \n",
       "2  0.008032 -0.008361  0.019091    ...       0.053172  -0.237839  -0.102671   \n",
       "3  0.005954 -0.010409  0.008706    ...       0.017964  -0.241615  -0.115704   \n",
       "4  0.005971 -0.012691  0.017750    ...       0.027809  -0.240677  -0.094627   \n",
       "\n",
       "   text_f_73  text_f_74  text_f_75  text_f_76  text_f_77  text_f_78  text_f_79  \n",
       "0  -0.110263  -0.022642  -0.003122   0.056965   0.105615   0.012552   0.030759  \n",
       "1  -0.252701  -0.059449   0.121994  -0.172504   0.083715  -0.342954   0.627240  \n",
       "2  -0.253724  -0.060433   0.113566  -0.164430   0.098105  -0.327809   0.576223  \n",
       "3  -0.125150  -0.025767   0.021801  -0.000432   0.083451  -0.112115   0.189098  \n",
       "4  -0.177729  -0.043124   0.047342  -0.066383   0.108523  -0.167366   0.356736  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True,inplace=True)\n",
    "X_train = pd.concat([X_train,text_features_df.iloc[0:X_train.shape[0],:]], axis=1)\n",
    "train = X_train\n",
    "train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10675632, 134)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train.shape ## 12-32\n",
    "# y_train.shape ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_features_df = text_features_df.iloc[-test_dates.shape[0]:,:].reset_index(drop=True)\n",
    "# test = test_text_features_df\n",
    "test = pd.concat([X_test.reset_index(drop=True),test_text_features_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper params search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- simple hold out method to optimize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates.reset_index(drop=True,inplace=True) ##reset index\n",
    "y_train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \n",
    "    clf = params.get('clf')\n",
    "    new_params = params.get('params') ## update params\n",
    "\n",
    "    copy_clf = copy.deepcopy(clf)\n",
    "    original_params = copy_clf.get_params()\n",
    "    original_params.update(new_params)\n",
    "    copy_clf.set_params(**original_params) # update copy clf with trying new_params     \n",
    "    \n",
    "    ## simple hold out \n",
    "    ## train_dates --- 12 - 32\n",
    "    \n",
    "    \n",
    "    train_mask = train_dates < level2_date_block[0] #12-26\n",
    "    ## simple hold out \n",
    "    validation_mask = (train_dates >= level2_date_block[0]) & (train_dates <= level2_date_block[-1]) ## validate on the level2_date_block\n",
    "    \n",
    "    copy_clf.fit(X_train[train_mask].values, y_train[train_mask]) #  \n",
    "    \n",
    "    pred_y = copy_clf.predict(X_train[validation_mask].values) ## 27-32\n",
    "    pred_y = np.clip(pred_y, 0., 20.) # clip to (0,20)\n",
    "    rmse = mean_squared_error(y_train[validation_mask], pred_y)**.5\n",
    "    print('rmse: {:.5f} '.format(rmse), end='\\t')\n",
    "    print('params: {}'.format(new_params))\n",
    "    \n",
    "    return {'loss':rmse,'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 1.06085 \tparams: {'rg__alpha': 0.8913060076641278}\n",
      "rmse: 1.06153 \tparams: {'rg__alpha': 0.3635415790107782}\n",
      "rmse: 1.06142 \tparams: {'rg__alpha': 0.12722171982882946}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-68dc51dbab72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0malgo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mtrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mmax_evals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m            )\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         )\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    318\u001b[0m                     verbose=verbose)\n\u001b[0;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-bb8d53998e14>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mcopy_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalidation_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m## 27-32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20.\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# clip to (0,20)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalidation_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_final_estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \"\"\"\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m--> 241\u001b[1;33m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "rg_clf = Pipeline([\n",
    "    ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "    ('rg', Ridge(fit_intercept=True, normalize=True, max_iter=2000, random_state=0))\n",
    "])\n",
    "\n",
    "rg_params = {\n",
    "    'clf' : rg_clf,\n",
    "    'params':{\n",
    "        'rg__alpha':  hp.uniform('rg__alpha', 0., 1.0)\n",
    "    }\n",
    "    \n",
    "}\n",
    "best = fmin(fn = objective,\n",
    "            space = rg_params,\n",
    "            algo = tpe.suggest,\n",
    "            trials = trials,\n",
    "            max_evals = 10\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.961002177524, 'status': 'ok'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> rmse: 0.961002\n",
    "    - alpha: `0.234133853`\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate stage2 features with TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11128004, 54)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11128004, 80)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.concat([merge,text_features_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4261"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)), ('rg', Ridge(alpha=0.23413385351122218, copy_X=True, fit_intercept=True,\n",
       "   max_iter=2000, normalize=True, random_state=0, solver='auto', tol=0.001))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([\n",
    "                ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "                ('rg', Ridge(alpha=0.23413385351122218, fit_intercept=True, normalize=True, max_iter=2000, random_state=0))\n",
    "            ])\n",
    "model.fit(merge[merge_dates < 27].values, merge_y[merge_dates < 27])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_data_text = model.predict(merge[merge_dates >= 27].values)\n",
    "stage2_data_text = np.clip(stage2_data_text, 0., 20.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1828564,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_data_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save to npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"temp = np.load('../data/feat/stage2_data_text.npy')\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save('../data/feat/stage2_data_text.npy',stage2_data_text)\n",
    "\n",
    "'''temp = np.load('../data/feat/stage2_data_text.npy')'''"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
