{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Level Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load pre-processing data\n",
    "    - downcast to float32, int32 \n",
    "2. Train the first level models\n",
    "    - validate model with simple hold out method\n",
    "    - several models\n",
    "        - linear \n",
    "        - tree based\n",
    "        - knn\n",
    "    - features gen by stacking \n",
    "3. Text features extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/X_cv', '/X_test', '/X_train', '/y_cv', '/y_train']\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('../data/feat/data.h5') as store:\n",
    "    print(store.keys())\n",
    "    X_train = store['X_train']\n",
    "    X_cv = store['X_cv']\n",
    "    y_train = store['y_train']\n",
    "    y_cv = store['y_cv']\n",
    "    X_test = store['X_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.date_block_num.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - clip to (0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.clip(0,20)\n",
    "y_cv = y_cv.clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10675632, 54)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- downcast to `float32`, `int32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = downcast_dtypes(X_train)\n",
    "X_cv = downcast_dtypes(X_cv)\n",
    "X_test = downcast_dtypes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.float32)\n",
    "y_cv = y_cv.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `fillna` with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(0,inplace=True)\n",
    "X_cv.fillna(0,inplace=True)\n",
    "X_test.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Train /test reduce\n",
    "We take only `date_block_num` between `12~32`\n",
    "- memory issue\n",
    "- time cost issue\n",
    "\n",
    "But I can't improve rmse with smaller datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates = X_train.date_block_num\n",
    "\n",
    "mask = train_dates >= 0 # mask=0 : all consider\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "train_dates = train_dates[mask]\n",
    "test_dates = X_test.date_block_num\n",
    "cv_dates = X_cv.date_block_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10675632, 54)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. First Level Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates = X_train.date_block_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "level2_date_block = [27, 28, 29, 30, 31, 32]\n",
    "# level2_date_block = [32]\n",
    "level2_mask = train_dates.isin(level2_date_block)\n",
    "train_dates_level2 = train_dates[level2_mask]\n",
    "train_y_level2 = y_train[level2_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376192,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dates_level2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 custom grid search \n",
    "    - stolen from top20 kaggler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_grid_search_cv_evaluate(clf, X_train, y_train, param_grid):\n",
    "    \n",
    "    params_list = list(ParameterGrid(param_grid))\n",
    "    res_df = pd.DataFrame(data=np.zeros((len(params_list),3)), columns=['params', 'mean_test_score', 'std_test_score'])\n",
    "    res_df.loc[:,'params'] = params_list\n",
    "    \n",
    "    for i, params in enumerate(params_list):\n",
    "        scores = []\n",
    "        print('Fitting: ', params, '...', end='\\n\\tscores= ')\n",
    "        for cur_block in level2_date_block:\n",
    "            copy_clf = copy.deepcopy(clf)\n",
    "            original_param = copy_clf.get_params()\n",
    "            original_param.update(params)\n",
    "            copy_clf.set_params(**original_param) # update copy clf with trying params \n",
    "            \n",
    "            copy_clf.fit(X_train[train_dates < cur_block].values, y_train[train_dates < cur_block])\n",
    "            pred_y = copy_clf.predict(X_train[train_dates == cur_block].values)\n",
    "            pred_y = np.clip(pred_y, 0., 20.)\n",
    "            score = mean_squared_error(y_train[train_dates == cur_block], pred_y)**.5\n",
    "            print('{:.5f} '.format(score), end='')\n",
    "            scores.append(score)\n",
    "            del copy_clf; gc.collect()\n",
    "        \n",
    "        print('')\n",
    "        res_df.loc[i, 'mean_test_score'] = np.mean(scores)\n",
    "        res_df.loc[i, 'std_test_score'] = np.std(scores)\n",
    "        \n",
    "    print('Fitting finished')\n",
    "    res_df = res_df.sort_values(by=['mean_test_score', 'std_test_score'], ascending=True).reset_index(drop=True)\n",
    "    best_params = res_df.loc[0, 'params']\n",
    "    \n",
    "    print('Selected hyper-params:', best_params)\n",
    "    print('cv score: {:.4f}, std: {:.4f}'.format(res_df.loc[0, 'mean_test_score'], res_df.loc[0, 'std_test_score']))\n",
    "    del res_df, params_list; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_grid_search_simple_holdout_evaluate(clf, X_train, y_train, param_grid, level2_date_block=[32]):\n",
    "    \n",
    "    params_list = list(ParameterGrid(param_grid))\n",
    "    res_df = pd.DataFrame(data=np.zeros((len(params_list),2)), columns=['params', 'val_score'])\n",
    "    res_df.loc[:,'params'] = params_list\n",
    "    \n",
    "    train_mask = train_dates < level2_date_block[0]\n",
    "    validation_mask = (train_dates >= level2_date_block[0]) & (train_dates <= level2_date_block[-1])\n",
    "    for i, params in enumerate(params_list):\n",
    "        print('Fitting: ', params, '...', end='\\n\\tscore= ')\n",
    "        \n",
    "        copy_clf = copy.deepcopy(clf)\n",
    "        original_param = copy_clf.get_params()\n",
    "        original_param.update(params)\n",
    "        copy_clf.set_params(**original_param) # update copy clf with trying params \n",
    "\n",
    "        copy_clf.fit(X_train[train_mask].values, y_train[train_mask])\n",
    "        pred_y = copy_clf.predict(X_train[validation_mask].values)\n",
    "        pred_y = np.clip(pred_y, 0., 20.)\n",
    "        score = mean_squared_error(y_train[validation_mask], pred_y)**.5\n",
    "        print('{:.5f} '.format(score), end='\\n')\n",
    "        del copy_clf; gc.collect()\n",
    "\n",
    "        res_df.loc[i, 'val_score'] = score\n",
    "        \n",
    "    print('Fitting finished')\n",
    "    res_df = res_df.sort_values(by=['val_score'], ascending=True).reset_index(drop=True)\n",
    "    best_params = res_df.loc[0, 'params']\n",
    "    \n",
    "    print('Selected hyper-params:', best_params)\n",
    "    print('cv score: {:.4f}'.format(res_df.loc[0, 'val_score']))\n",
    "    del res_df, params_list; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Optimization\n",
    "- with `hyperopt` library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- simple hold out method to optimize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    '''\n",
    "        calculate rmse with simple holdout method \n",
    "        \n",
    "        -- train on `train_dates < level2_date_block[0]` \n",
    "        -- validate on `leve2_date_block`  (date_block_num : 27-32)\n",
    "    '''\n",
    "    ## extract clf and new_params from `params`\n",
    "    clf = params.get('clf')\n",
    "    new_params = params.get('params') ## update params\n",
    "    \n",
    "    ## update params\n",
    "    copy_clf = copy.deepcopy(clf)\n",
    "    original_params = copy_clf.get_params()\n",
    "    original_params.update(new_params)\n",
    "    copy_clf.set_params(**original_params) # update copy clf with trying new_params     \n",
    "    \n",
    "    train_mask = train_dates < level2_date_block[0]\n",
    "    \n",
    "    ## simple hold out method\n",
    "    ## validate on the level2_date_block\n",
    "    validation_mask = (train_dates >= level2_date_block[0]) & (train_dates <= level2_date_block[-1]) \n",
    "    \n",
    "    copy_clf.fit(X_train[train_mask].values, y_train[train_mask]) ## train on <27 , validate on 27-32\n",
    "        \n",
    "    pred_y = copy_clf.predict(X_train[validation_mask].values)\n",
    "    pred_y = np.clip(pred_y, 0., 20.) # clip to (0,20)\n",
    "    rmse = mean_squared_error(y_train[validation_mask], pred_y)**.5\n",
    "    print('rmse: {:.5f} '.format(rmse), end='\\t')\n",
    "    print('params: {}'.format(new_params))\n",
    "    \n",
    "    return {'loss':rmse,'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model \n",
    "- Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso #featuring L2/L1 regularized linear models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.96856 \tparams: {'rg__alpha': 0.7394366826551112}\n",
      "rmse: 0.96940 \tparams: {'rg__alpha': 0.8323212952211707}\n",
      "rmse: 0.96636 \tparams: {'rg__alpha': 0.45853883904970294}\n",
      "rmse: 0.96528 \tparams: {'rg__alpha': 0.2586129746939999}\n",
      "rmse: 0.96619 \tparams: {'rg__alpha': 0.43105622957293344}\n",
      "rmse: 0.96580 \tparams: {'rg__alpha': 0.36485344088561267}\n",
      "rmse: 0.96796 \tparams: {'rg__alpha': 0.6710648897251851}\n",
      "rmse: 0.96687 \tparams: {'rg__alpha': 0.5323310197084163}\n",
      "rmse: 0.96541 \tparams: {'rg__alpha': 0.08928462490891498}\n",
      "rmse: 0.96785 \tparams: {'rg__alpha': 0.6575017014736089}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "rg_clf = Pipeline([\n",
    "    ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "    ('rg', Ridge(fit_intercept=True, normalize=True, max_iter=2000, random_state=0))\n",
    "])\n",
    "rg_params = {\n",
    "    'clf':rg_clf,\n",
    "    'params': {'rg__alpha': hp.uniform('rg__alpha', 0., 1)},\n",
    "}\n",
    "\n",
    "best = fmin(fn = objective,\n",
    "            space = rg_params,\n",
    "            algo = tpe.suggest,\n",
    "            trials = trials,\n",
    "            max_evals = 10\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rg__alpha': 0.2586129746939999}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">rmse:0.96508 \n",
    " - alpha : 0.193929"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.96888 \tparams: {'lasso__alpha': 0.03497042093162755}\n",
      "rmse: 0.96732 \tparams: {'lasso__alpha': 0.029280833173449317}\n",
      "rmse: 0.97919 \tparams: {'lasso__alpha': 0.07070642751102232}\n",
      "rmse: 0.98575 \tparams: {'lasso__alpha': 0.09480172401964848}\n",
      "rmse: 0.97813 \tparams: {'lasso__alpha': 0.06642684123672093}\n",
      "rmse: 0.96817 \tparams: {'lasso__alpha': 0.03247322048195526}\n",
      "rmse: 0.96565 \tparams: {'lasso__alpha': 0.021311379705558964}\n",
      "rmse: 0.97563 \tparams: {'lasso__alpha': 0.05706225979785251}\n",
      "rmse: 0.98443 \tparams: {'lasso__alpha': 0.08997042098849649}\n",
      "rmse: 0.97709 \tparams: {'lasso__alpha': 0.0621304034294529}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "lasso_clf = Pipeline([\n",
    "    ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "    ('lasso', Lasso(random_state=0))\n",
    "])\n",
    "\n",
    "lasso_params = {\n",
    "    'clf':lasso_clf,\n",
    "    'params': {\n",
    "        'lasso__alpha': hp.uniform('lasso__alpha',0,0.1)\n",
    "    },    \n",
    "}\n",
    "\n",
    "best = fmin(fn = objective,\n",
    "            space = lasso_params,\n",
    "            algo = tpe.suggest,\n",
    "            trials = trials,\n",
    "            max_evals = 10\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso__alpha': 0.021311379705558964}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> rmse: 0.96565\n",
    "    - alpha: 0.021311"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree based model \n",
    "- lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "       min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "       n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "       subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.83811 \tparams: {'bagging_fraction': 0.7287250669902532, 'boosting_type': 'gbdt', 'feature_fraction': 0.9454531311886423, 'gamma': 0.35213985144391613, 'max_depth': 4, 'num_leaves': 80, 'reg_lambda': 0.9530539109026833}\n",
      "rmse: 0.82016 \tparams: {'bagging_fraction': 0.8936851006379823, 'boosting_type': 'gbdt', 'feature_fraction': 0.33191544462509315, 'gamma': 0.2853047365652319, 'max_depth': 12, 'num_leaves': 86, 'reg_lambda': 0.8372438851255922}\n",
      "rmse: 0.83413 \tparams: {'bagging_fraction': 0.9638977666454814, 'boosting_type': 'dart', 'feature_fraction': 0.9633378431302959, 'gamma': 0.11565837787421587, 'max_depth': 7, 'num_leaves': 82, 'reg_lambda': 0.8165793892277495}\n",
      "rmse: 0.81750 \tparams: {'bagging_fraction': 0.7784701027506175, 'boosting_type': 'gbdt', 'feature_fraction': 0.4683902745701608, 'gamma': 0.15908835269613442, 'max_depth': 13, 'num_leaves': 86, 'reg_lambda': 0.24404114889403705}\n",
      "rmse: 0.82944 \tparams: {'bagging_fraction': 0.9495228671083129, 'boosting_type': 'dart', 'feature_fraction': 0.9669296359526234, 'gamma': 0.4262811684365576, 'max_depth': 15, 'num_leaves': 98, 'reg_lambda': 0.6519378195584544}\n",
      "rmse: 0.83507 \tparams: {'bagging_fraction': 0.9430872235621006, 'boosting_type': 'dart', 'feature_fraction': 0.33582770383015825, 'gamma': 0.3454245261034683, 'max_depth': 14, 'num_leaves': 50, 'reg_lambda': 0.7500272242315192}\n",
      "rmse: 0.82777 \tparams: {'bagging_fraction': 0.849859426944532, 'boosting_type': 'dart', 'feature_fraction': 0.8788165504131693, 'gamma': 0.47885629186492384, 'max_depth': 12, 'num_leaves': 68, 'reg_lambda': 0.8507290050110188}\n",
      "rmse: 0.82909 \tparams: {'bagging_fraction': 0.7472519171930275, 'boosting_type': 'dart', 'feature_fraction': 0.4522069034767856, 'gamma': 0.20979809797290716, 'max_depth': 16, 'num_leaves': 84, 'reg_lambda': 0.13225054299346384}\n",
      "rmse: 0.82386 \tparams: {'bagging_fraction': 0.9796591166375556, 'boosting_type': 'gbdt', 'feature_fraction': 0.6688770534138946, 'gamma': 0.3937505545703267, 'max_depth': 9, 'num_leaves': 30, 'reg_lambda': 0.3468775110029938}\n",
      "rmse: 0.81984 \tparams: {'bagging_fraction': 0.7128711024752513, 'boosting_type': 'gbdt', 'feature_fraction': 0.8588590226898918, 'gamma': 0.20993489384685615, 'max_depth': 13, 'num_leaves': 70, 'reg_lambda': 0.4351334332379081}\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.LGBMRegressor(random_state=0, n_jobs=8)\n",
    "\n",
    "# 1. find an optimal n_esti for rather larger learning rate\n",
    "lgb_params = {\n",
    "    'clf' : lgb_clf,\n",
    "    'params': {\n",
    "        'boosting_type': hp.choice('boosting_type',['gbdt', 'dart']), ## gbdt \n",
    "#         'boosting_type': []'gbdt',\n",
    "        'num_leaves'   : hp.choice('num_leaves', np.arange(8,129,2,dtype=int)),\n",
    "        'max_depth' : hp.choice(\"max_depth\", np.arange(4, 17, dtype=int)),    \n",
    "        'feature_fraction': hp.uniform('feature_fraction', 0.3, 1.0),\n",
    "        'bagging_fraction': hp.uniform ('bagging_fraction', 0.7, 1),\n",
    "        'reg_lambda': hp.uniform('reg_lambda',0,1),\n",
    "        'gamma' : hp.uniform('gamma', 0.1,0.5)\n",
    "    }\n",
    "    \n",
    "}\n",
    "best =fmin(fn = objective,\n",
    "           space = lgb_params,\n",
    "           algo = tpe.suggest,\n",
    "           max_evals = 10\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.81909 \tparams: {'bagging_fraction': 0.9568845079308161, 'bossting_type': 'gbdt', 'feature_fraction': 0.6203248801718259, 'gamma': 0.39624896070423066, 'max_depth': 12, 'metric': 'rmse', 'num_leaves': 64, 'objective': 'regression', 'reg_lambda': 0.38856229720270463}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.81908550940125358, 'status': 'ok'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use pre-train params from lgb_model1\n",
    "lgb_clf = lgb.LGBMRegressor(random_state=0)\n",
    "lgb_params = {\n",
    "    'clf':lgb_clf,\n",
    "    'params':{\n",
    "        'bagging_fraction': 0.9568845079308161,\n",
    "        'bossting_type': 'gbdt',\n",
    "        'feature_fraction': 0.6203248801718259,\n",
    "        'gamma': 0.39624896070423066,\n",
    "        'max_depth': 12,\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': 64,\n",
    "        'objective': 'regression',\n",
    "        'reg_lambda': 0.38856229720270463\n",
    "    }\n",
    "}\n",
    "objective(lgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> rmse: 0.81909\n",
    "    - {'bagging_fraction': 0.9568845079308161, 'bossting_type': 'gbdt', 'feature_fraction': 0.6203248801718259, 'gamma': 0.39624896070423066, 'max_depth': 12, 'metric': 'rmse', 'num_leaves': 64, 'objective': 'regression', 'reg_lambda': 0.38856229720270463}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.9788870584216797,\n",
       " 'feature_fraction': 0.7591012763757823,\n",
       " 'gamma': 0.1517233454100392,\n",
       " 'max_depth': 8,\n",
       " 'num_leaves': 51,\n",
       " 'reg_lambda': 0.6813318433297506}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> rmse:0.81525\n",
    "\n",
    "    > bagging_fraction:`0.9789`, \n",
    "    > feature_fraction:`0.759`,\n",
    "    > gamma : `0.1517`,\n",
    "    > reg_labmda : `0.6813`\n",
    "    > max_depth : `12`,\n",
    "    > num_leaves : `110`,\n",
    "    > bossting_type : `gbdt`,\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.85067 \tparams: {'max_depth': 8, 'min_samples_leaf': 50, 'min_samples_split': 200, 'n_estimators': 100}\n",
      "rmse: 0.85119 \tparams: {'max_depth': 8, 'min_samples_leaf': 90, 'min_samples_split': 200, 'n_estimators': 250}\n",
      "rmse: 0.85122 \tparams: {'max_depth': 8, 'min_samples_leaf': 40, 'min_samples_split': 200, 'n_estimators': 300}\n",
      "rmse: 0.83015 \tparams: {'max_depth': 16, 'min_samples_leaf': 60, 'min_samples_split': 400, 'n_estimators': 200}\n",
      "rmse: 0.82904 \tparams: {'max_depth': 16, 'min_samples_leaf': 40, 'min_samples_split': 100, 'n_estimators': 50}\n",
      "rmse: 0.82801 \tparams: {'max_depth': 16, 'min_samples_leaf': 50, 'min_samples_split': 200, 'n_estimators': 300}\n",
      "rmse: 0.89163 \tparams: {'max_depth': 4, 'min_samples_leaf': 30, 'min_samples_split': 300, 'n_estimators': 100}\n",
      "rmse: 0.89163 \tparams: {'max_depth': 4, 'min_samples_leaf': 70, 'min_samples_split': 200, 'n_estimators': 100}\n",
      "rmse: 0.89398 \tparams: {'max_depth': 4, 'min_samples_leaf': 70, 'min_samples_split': 300, 'n_estimators': 300}\n",
      "rmse: 0.85056 \tparams: {'max_depth': 8, 'min_samples_leaf': 60, 'min_samples_split': 300, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestRegressor(min_samples_split=300, min_samples_leaf=30, max_features='sqrt',n_estimators=50,\n",
    "                               max_depth=4, n_jobs=4, criterion='mse',random_state=0)\n",
    "\n",
    "rf_clf.estimators_=1 # need to set a value otherwise rise AttributeError in hyperopt\n",
    "rf_params = {\n",
    "    'clf' : rf_clf,\n",
    "    'params' : {\n",
    "        'min_samples_split' : hp.choice('min_samples_split',np.arange(100,500,100)),\n",
    "        'min_samples_leaf': hp.choice('min_samples_leaf',np.arange(30,100,10)),\n",
    "        'n_estimators' : hp.choice('n_estimators', np.arange(50,301,50)),\n",
    "        'max_depth': hp.choice('max_depth',[4, 8, 12, 16])        \n",
    "    }    \n",
    "}\n",
    "\n",
    "best =fmin(fn = objective,\n",
    "           space = rf_params,\n",
    "           algo = tpe.suggest,\n",
    "           max_evals = 10\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> rmse: `0.82801`\n",
    " - max_depth = `16`\n",
    " - min_samples_leaf = `50`\n",
    " - min_samples_split = `200`\n",
    " - n_estimators = `300`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN  model\n",
    "\n",
    "- KNN: Prediction and Neighbor distances features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "          weights='uniform')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "knn_clf = KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                              metric_params=None, n_jobs=10, n_neighbors=5, p=1,\n",
    "                              weights='uniform')\n",
    "knn_params = {\n",
    "    'clf' : knn_clf,\n",
    "    'params' :{\n",
    "        'p': hp.choice('p',[0,1]),\n",
    "        'weights': hp.choice('weights',['uniform', 'distance']),\n",
    "        'n_neighbors': hp.choice('n_neighbors', np.arange(10, 101, 10,dtype=int))        \n",
    "    }\n",
    "}\n",
    "best = fmin(fn = objective,\n",
    "            space = knn_params,\n",
    "            algo = tpe.suggest,\n",
    "            trials = trials,\n",
    "            max_evals = 10\n",
    "           )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> knn: \n",
    "    - n_neighbors = `15`\n",
    "    - weights = `distance`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans\n",
    "- mini-batch kmeans cast to low dimensional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.metrics import calinski_harabaz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.concat([X_train, X_cv,X_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in np.arange(4,16,2):\n",
    "    print('n_clusters =', c, end=' score= ')\n",
    "    km = Pipeline([\n",
    "        ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "        ('kmean', MiniBatchKMeans(n_clusters=c, max_no_improvement=30, \n",
    "                                  verbose=0, batch_size=1000000, random_state=0))\n",
    "    ])\n",
    "#     mini_kmean = MiniBatchKMeans(n_clusters=8, batch_size=10000, verbose=2, random_state=0)\n",
    "    labels = km.fit_predict(merge)\n",
    "    print(calinski_harabaz_score(merge, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `n_cluster = 8` ... highest score means better clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dates = np.concatenate([train_dates,cv_dates, test_dates], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_dates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6639294,)\n"
     ]
    }
   ],
   "source": [
    "merge_y = np.concatenate([y_train,y_cv, np.zeros((len(test_dates),))], axis=0)\n",
    "print(merge_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_train_dates = merge_dates[merge_dates>=level2_date_block[0]] ## 27 - 34\n",
    "stage2_train_mask = (stage2_train_dates <= level2_date_block[-1]) # train on : 27-32\n",
    "stage2_valid_mask = (stage2_train_dates == 33) ## validate on : 33\n",
    "stage2_final_train_mask = (stage2_train_dates <= 33) ## \n",
    "stage2_test_mask = (stage2_train_dates==34)\n",
    "stage2_train_y = merge_y[merge_dates>=level2_date_block[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_models = {\n",
    "    'rg': Pipeline([\n",
    "                ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "                ('rg', Ridge(alpha=0.08, fit_intercept=True, normalize=True, max_iter=2000, random_state=0))\n",
    "            ]),\n",
    "    'lasso':Pipeline([\n",
    "                    ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "                    ('lasso', Lasso(alpha=0.0094, normalize=False, fit_intercept=True, max_iter=2000, random_state=0))\n",
    "                ]),\n",
    "    'rf': RandomForestRegressor(n_estimators=250,\n",
    "                               min_samples_split=300, min_samples_leaf=30, max_features='sqrt',\n",
    "                               max_depth=16, n_jobs=4, criterion='mse', random_state=0),\n",
    "    'lgbm': lgb.LGBMRegressor(boosting_type='gbdt', \n",
    "                              max_depth=12,\n",
    "                              num_leaves=110,\n",
    "                              bagging_fraction=0.979,\n",
    "                              feature_fraction=0.759,                              \n",
    "                              reg_lambda = 0.681,\n",
    "                              gamma = 0.1517,                              \n",
    "#                               subsample=.55, colsample_bytree=.75, ## \n",
    "                              n_jobs=8,\n",
    "                              random_state=0)\n",
    "}\n",
    "\n",
    "\n",
    "knn = KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                              metric_params=None, n_jobs=4, n_neighbors=15, p=1,\n",
    "                              weights='distance')\n",
    "\n",
    "mini_kmean = Pipeline([\n",
    "                ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "                ('kmean', MiniBatchKMeans(n_clusters=8, max_no_improvement=30, \n",
    "                                          verbose=0, batch_size=1000000, random_state=0))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage2_feature_generate():\n",
    "    \n",
    "    print('Training supervised models')\n",
    "    \n",
    "    all_preds = []\n",
    "    for model_name, model in supervised_models.items():\n",
    "        \n",
    "        print(model_name, end=': ')\n",
    "        preds = []\n",
    "        for cur_block in np.arange(27, 35, 1):\n",
    "            X_tr = merge[merge_dates < cur_block].values ## ndarray\n",
    "            y_tr = merge_y[merge_dates < cur_block]\n",
    "            X_test = merge[merge_dates == cur_block].values\n",
    "            \n",
    "            copy_clf = copy.deepcopy(model)\n",
    "            copy_clf.fit(X_tr, y_tr)\n",
    "            pred_test = copy_clf.predict(X_test)\n",
    "            pred_test = np.clip(pred_test, 0., 20.)\n",
    "            preds.append(pred_test)\n",
    "            print(cur_block, end=' ')\n",
    "\n",
    "        preds = np.concatenate(preds, axis=0)\n",
    "        preds = preds.reshape((len(preds), 1))\n",
    "        all_preds.append(preds)\n",
    "    \n",
    "        print('')\n",
    "        \n",
    "    #knn:\n",
    "    print('knn')\n",
    "    X_tr = merge[merge_dates < 27].values\n",
    "    y_tr = merge_y[merge_dates < 27]\n",
    "\n",
    "    X_test = merge[merge_dates >= 27].values\n",
    "    knn.fit(X_tr, y_tr)\n",
    "    knn_pred = knn.predict(X_test)\n",
    "    knn_pred = np.clip(knn_pred, 0., 20.).reshape((len(knn_pred), 1))\n",
    "    knn_dist = knn.kneighbors(X_test, return_distance=True)[0] # distances\n",
    "    print(np.array(knn_dist).shape)\n",
    "    all_preds.append(knn_pred)\n",
    "    all_preds.append(knn_dist)\n",
    "    \n",
    "    # kmeans\n",
    "    mini_kmean.fit(merge.values)\n",
    "    kmean_pred = mini_kmean.predict(X_test)\n",
    "    kmean_dist = mini_kmean.transform(X_test)\n",
    "    \n",
    "    kmean_pred = np.array(kmean_pred).reshape((len(kmean_pred),1))\n",
    "    all_preds.append(kmean_pred)\n",
    "    all_preds.append(kmean_dist)\n",
    "    \n",
    "    return np.concatenate(all_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training supervised models\n",
      "rg: 27 28 29 30 31 32 33 34 \n",
      "lasso: 27 28 29 30 31 32 33 34 \n",
      "rf: 27 28 29 30 31 32 33 34 \n",
      "lgbm: 27 28 29 30 31 32 33 34 \n",
      "knn\n",
      "(1828564, 15)\n"
     ]
    }
   ],
   "source": [
    "stage2_data = stage2_feature_generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rg',\n",
       " 'lasso',\n",
       " 'rf',\n",
       " 'lgbm',\n",
       " 'knn',\n",
       " 'knn_dist_0',\n",
       " 'knn_dist_1',\n",
       " 'knn_dist_2',\n",
       " 'knn_dist_3',\n",
       " 'knn_dist_4',\n",
       " 'knn_dist_5',\n",
       " 'knn_dist_6',\n",
       " 'knn_dist_7',\n",
       " 'knn_dist_8',\n",
       " 'knn_dist_9',\n",
       " 'knn_dist_10',\n",
       " 'knn_dist_11',\n",
       " 'knn_dist_12',\n",
       " 'knn_dist_13',\n",
       " 'knn_dist_14',\n",
       " 'kmean_dist_label',\n",
       " 'kmean_dist_0',\n",
       " 'kmean_dist_1',\n",
       " 'kmean_dist_2',\n",
       " 'kmean_dist_3',\n",
       " 'kmean_dist_4',\n",
       " 'kmean_dist_5',\n",
       " 'kmean_dist_6',\n",
       " 'kmean_dist_7']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['rg', 'lasso', 'rf', 'lgbm', 'knn']\n",
    "columns.extend(['knn_dist_'+str(i) for i in range(15)])\n",
    "columns.extend(['kmean_dist_label'])\n",
    "columns.extend(['kmean_dist_'+str(i) for i in range(8)])\n",
    "print(len(columns))\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_df = pd.DataFrame(data=stage2_data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rg</th>\n",
       "      <td>0.345505</td>\n",
       "      <td>1.083458</td>\n",
       "      <td>0.432379</td>\n",
       "      <td>0.495248</td>\n",
       "      <td>0.458267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>0.299434</td>\n",
       "      <td>1.036473</td>\n",
       "      <td>0.398738</td>\n",
       "      <td>0.437356</td>\n",
       "      <td>0.401383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.559380</td>\n",
       "      <td>2.350962</td>\n",
       "      <td>0.645353</td>\n",
       "      <td>3.162069</td>\n",
       "      <td>2.405929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>0.687585</td>\n",
       "      <td>2.604097</td>\n",
       "      <td>0.502553</td>\n",
       "      <td>5.001240</td>\n",
       "      <td>3.038452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.461946</td>\n",
       "      <td>1.886891</td>\n",
       "      <td>0.400254</td>\n",
       "      <td>0.075603</td>\n",
       "      <td>0.663293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_0</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>7097.084351</td>\n",
       "      <td>8810.403742</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_1</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>7367.291954</td>\n",
       "      <td>8901.891784</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_2</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>7391.268279</td>\n",
       "      <td>8916.891784</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_3</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>7754.255436</td>\n",
       "      <td>8944.502339</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_4</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>7779.592759</td>\n",
       "      <td>8967.156340</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_5</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>7819.591077</td>\n",
       "      <td>8977.680930</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_6</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>7830.676775</td>\n",
       "      <td>9023.499205</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_7</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>7867.915540</td>\n",
       "      <td>9029.414672</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_8</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>7931.644382</td>\n",
       "      <td>9030.499205</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_9</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>7991.663709</td>\n",
       "      <td>9055.954235</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_10</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>8051.430374</td>\n",
       "      <td>9056.891784</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_11</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>8173.423018</td>\n",
       "      <td>9084.961986</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_12</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>8284.936405</td>\n",
       "      <td>9086.499205</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_13</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>8288.974285</td>\n",
       "      <td>9117.782312</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_dist_14</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>8422.030430</td>\n",
       "      <td>9150.136168</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmean_dist_label</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmean_dist_0</th>\n",
       "      <td>16.171893</td>\n",
       "      <td>9.423429</td>\n",
       "      <td>8.785192</td>\n",
       "      <td>16.186510</td>\n",
       "      <td>16.180627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmean_dist_1</th>\n",
       "      <td>16.788638</td>\n",
       "      <td>10.257709</td>\n",
       "      <td>8.794748</td>\n",
       "      <td>16.802709</td>\n",
       "      <td>16.797045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmean_dist_2</th>\n",
       "      <td>13.484739</td>\n",
       "      <td>8.150730</td>\n",
       "      <td>6.493592</td>\n",
       "      <td>13.502333</td>\n",
       "      <td>13.495253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmean_dist_3</th>\n",
       "      <td>10.455496</td>\n",
       "      <td>6.497106</td>\n",
       "      <td>6.395639</td>\n",
       "      <td>10.478966</td>\n",
       "      <td>10.469525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmean_dist_4</th>\n",
       "      <td>163.121368</td>\n",
       "      <td>161.405323</td>\n",
       "      <td>161.372517</td>\n",
       "      <td>163.123577</td>\n",
       "      <td>163.122691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmean_dist_5</th>\n",
       "      <td>14.736764</td>\n",
       "      <td>7.958082</td>\n",
       "      <td>8.162270</td>\n",
       "      <td>14.752742</td>\n",
       "      <td>14.746311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmean_dist_6</th>\n",
       "      <td>17.483576</td>\n",
       "      <td>11.485983</td>\n",
       "      <td>10.156587</td>\n",
       "      <td>17.496040</td>\n",
       "      <td>17.491022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmean_dist_7</th>\n",
       "      <td>35.278573</td>\n",
       "      <td>32.846975</td>\n",
       "      <td>32.766569</td>\n",
       "      <td>35.280873</td>\n",
       "      <td>35.279936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0            1            2           3           4\n",
       "rg                  0.345505     1.083458     0.432379    0.495248    0.458267\n",
       "lasso               0.299434     1.036473     0.398738    0.437356    0.401383\n",
       "rf                  0.559380     2.350962     0.645353    3.162069    2.405929\n",
       "lgbm                0.687585     2.604097     0.502553    5.001240    3.038452\n",
       "knn                 0.461946     1.886891     0.400254    0.075603    0.663293\n",
       "knn_dist_0         15.000000  7097.084351  8810.403742   11.000000    9.000000\n",
       "knn_dist_1         15.000000  7367.291954  8901.891784   12.000000   10.000000\n",
       "knn_dist_2         15.000000  7391.268279  8916.891784   12.000000   10.000000\n",
       "knn_dist_3         16.000000  7754.255436  8944.502339   13.000000   11.000000\n",
       "knn_dist_4         16.000000  7779.592759  8967.156340   13.000000   11.000000\n",
       "knn_dist_5         16.000000  7819.591077  8977.680930   14.000000   11.000000\n",
       "knn_dist_6         16.000000  7830.676775  9023.499205   14.000000   12.000000\n",
       "knn_dist_7         16.000000  7867.915540  9029.414672   15.000000   12.000000\n",
       "knn_dist_8         17.000000  7931.644382  9030.499205   16.000000   12.000000\n",
       "knn_dist_9         17.000000  7991.663709  9055.954235   17.000000   12.000000\n",
       "knn_dist_10        17.000000  8051.430374  9056.891784   17.000000   13.000000\n",
       "knn_dist_11        17.000000  8173.423018  9084.961986   18.000000   13.000000\n",
       "knn_dist_12        17.000000  8284.936405  9086.499205   18.000000   13.000000\n",
       "knn_dist_13        17.000000  8288.974285  9117.782312   19.000000   14.000000\n",
       "knn_dist_14        17.000000  8422.030430  9150.136168   19.000000   14.000000\n",
       "kmean_dist_label    3.000000     5.000000     6.000000    3.000000    3.000000\n",
       "kmean_dist_0       16.171893     9.423429     8.785192   16.186510   16.180627\n",
       "kmean_dist_1       16.788638    10.257709     8.794748   16.802709   16.797045\n",
       "kmean_dist_2       13.484739     8.150730     6.493592   13.502333   13.495253\n",
       "kmean_dist_3       10.455496     6.497106     6.395639   10.478966   10.469525\n",
       "kmean_dist_4      163.121368   161.405323   161.372517  163.123577  163.122691\n",
       "kmean_dist_5       14.736764     7.958082     8.162270   14.752742   14.746311\n",
       "kmean_dist_6       17.483576    11.485983    10.156587   17.496040   17.491022\n",
       "kmean_dist_7       35.278573    32.846975    32.766569   35.280873   35.279936"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_io = pd.HDFStore('../data/feat/stage2_data.h5')\n",
    "stage2_io['stage2_df'] = stage2_df\n",
    "stage2_io.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/stage2_df']\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('../data/feat/stage2_data.h5') as stage2_io:\n",
    "    print(stage2_io.keys())\n",
    "    stage2_df = stage2_io['stage2_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/X_text_feats', '/X_text_feats_cv', '/X_text_feats_test', '/X_text_feats_train']\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('../data/feat/text_feats.h5') as text_io:\n",
    "    print(text_io.keys())\n",
    "    X_text_feats_test = text_io['X_text_feats_test']\n",
    "    X_text_feats_cv = text_io['X_text_feats_cv']\n",
    "    X_text_feats_train = text_io['X_text_feats_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10675632, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_feats_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     6186922\n",
       "False    4488710\n",
       "Name: date_block_num, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.value_counts() ## reduce memory use only num_date_block >= 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10913804"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_feats_train.shape[0] + X_text_feats_cv.shape[0]  #+ X_text_feats_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10675632, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_feats_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_df = pd.concat([X_text_feats_train[mask],X_text_feats_cv])\n",
    "test_text_df = X_text_feats_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6639294"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df.shape[0] + test_text_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_text_df['item_name'].map(str) + ' ' + train_text_df['item_category_name'].map(str) + ' ' + train_text_df['shop_name'].map(str)\n",
    "test_texts = test_text_df['item_name'].map(str) + ' ' + test_text_df['item_category_name'].map(str) + ' ' + test_text_df['shop_name'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts = pd.Series(np.concatenate([train_texts, test_texts], axis=0))\n",
    "del train_text_df, test_text_df, train_texts, test_texts; gc.collect()\n",
    "all_texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1896"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_text_feats_train,X_text_feats_cv,X_text_feats_test; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. TFIDF - Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(lowercase=False, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294, 63999)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_features = tv.fit_transform(all_texts)\n",
    "tv_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=20, random_state=0)\n",
    "tv_svd_features = svd.fit_transform(tv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9893320053815842"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(tv_svd_features)/(1024*1024*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TF-IDF(binarize)- Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvb_features = tv_features.astype(bool).astype(float)\n",
    "del tv_features; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294, 20)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=20, random_state=0)\n",
    "tvb_svd_features = svd.fit_transform(tvb_features)\n",
    "tvb_svd_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9893320053815842"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(tvb_svd_features)/(1024*1024*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hasing + Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer(ngram_range=(1, 2), lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294, 1048576)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hv_features = hv.fit_transform(all_texts).tocsr()\n",
    "hv_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294, 20)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=20, random_state=0)\n",
    "hv_svd_features = svd.fit_transform(hv_features)\n",
    "hv_svd_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9893320053815842"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(hv_svd_features)/(1024*1024*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hasing(binarize) + Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvb_features = hv_features.astype(bool).astype(float)\n",
    "del hv_features; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294, 20)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=20, random_state=0)\n",
    "hvb_svd_features = svd.fit_transform(hvb_features)\n",
    "hvb_svd_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9893320053815842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sys.getsizeof(hvb_svd_features)/(1024*1024*1024))\n",
    "del hvb_features; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Stack them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294, 80)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = np.concatenate([tv_svd_features, tvb_svd_features, hv_svd_features, hvb_svd_features], axis=1)\n",
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9573277086019516"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(text_features)/(1024*1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features_df = pd.DataFrame(data=text_features, columns=['text_f_'+str(i) for i in range(80)])\n",
    "\n",
    "text_io = pd.HDFStore('../data/feat/text_feat_df.h5') \n",
    "text_io['text_feats_df'] = text_features_df\n",
    "text_io.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate stage2 text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('../data/feat/text_feat_df.h5') as text_io:\n",
    "    text_features_df = text_io['text_feats_df'] ## 12-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.concat([X_train, X_cv,X_test], ignore_index=True)\n",
    "merge_dates = np.concatenate([train_dates,cv_dates, test_dates], axis=0) ## 12-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_y = np.concatenate([y_train,y_cv, np.zeros((len(test_dates),))], axis=0) ## 12-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294, 54)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6186922,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dates.shape # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "level2_date_block = [27,28,29,30,31,32]\n",
    "stage2_train_dates = merge_dates[merge_dates>=level2_date_block[0]] # 27-34\n",
    "stage2_train_mask = (stage2_train_dates <= level2_date_block[-1]) # 27-32\n",
    "stage2_valid_mask = (stage2_train_dates == 33) # 33\n",
    "stage2_final_train_mask = (stage2_train_dates <= 33) # 27-33\n",
    "stage2_test_mask = (stage2_train_dates==34) # 34\n",
    "stage2_train_y = merge_y[merge_dates>=level2_date_block[0]] # 27-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True,inplace=True)\n",
    "X_train = pd.concat([X_train,text_features_df.iloc[0:X_train.shape[0],:]], axis=1)\n",
    "# train = X_train\n",
    "# train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6186922, 134)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape ## 12-32\n",
    "# y_train.shape ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214200"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dates.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_features_df = text_features_df.iloc[-test_dates.shape[0]:,:].reset_index(drop=True)\n",
    "test = pd.concat([X_test.reset_index(drop=True),test_text_features_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 134)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper params search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level2_date_block[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- simple hold out method to optimize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates.reset_index(drop=True,inplace=True) ##reset index\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "\n",
    "def objective(params):\n",
    "    \n",
    "    clf = params.get('clf')\n",
    "    new_params = params.get('params') ## update params\n",
    "\n",
    "    copy_clf = copy.deepcopy(clf)\n",
    "    original_params = copy_clf.get_params()\n",
    "    original_params.update(new_params)\n",
    "    copy_clf.set_params(**original_params) # update copy clf with trying new_params     \n",
    "    \n",
    "    ## simple hold out \n",
    "    ## train_dates --- 12 - 32\n",
    "    \n",
    "    \n",
    "    train_mask = train_dates < level2_date_block[0] #12-26\n",
    "    ## simple hold out \n",
    "    validation_mask = (train_dates >= level2_date_block[0]) & (train_dates <= level2_date_block[-1]) ## validate on the level2_date_block\n",
    "    \n",
    "    copy_clf.fit(X_train[train_mask].values, y_train[train_mask]) #  \n",
    "    \n",
    "    pred_y = copy_clf.predict(X_train[validation_mask].values) ## 27-32\n",
    "    pred_y = np.clip(pred_y, 0., 20.) # clip to (0,20)\n",
    "    rmse = mean_squared_error(y_train[validation_mask], pred_y)**.5\n",
    "    print('rmse: {:.5f} '.format(rmse), end='\\t')\n",
    "    print('params: {}'.format(new_params))\n",
    "    \n",
    "    return {'loss':rmse,'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.96357 \tparams: {'rg__alpha': 0.3147292713629707}\n",
      "rmse: 0.96250 \tparams: {'rg__alpha': 0.08519099879049385}\n",
      "rmse: 0.96421 \tparams: {'rg__alpha': 0.4044099788839268}\n",
      "rmse: 0.96447 \tparams: {'rg__alpha': 0.43645905573545196}\n",
      "rmse: 0.96418 \tparams: {'rg__alpha': 0.4009849415326201}\n",
      "rmse: 0.96378 \tparams: {'rg__alpha': 0.3460070240018216}\n",
      "rmse: 0.96259 \tparams: {'rg__alpha': 0.03432567333200587}\n",
      "rmse: 0.96317 \tparams: {'rg__alpha': 0.2468350021491552}\n",
      "rmse: 0.96394 \tparams: {'rg__alpha': 0.36806573677837384}\n",
      "rmse: 0.96284 \tparams: {'rg__alpha': 0.17809668480975327}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "rg_clf = Pipeline([\n",
    "    ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "    ('rg', Ridge(fit_intercept=True, normalize=True, max_iter=2000, random_state=0))\n",
    "])\n",
    "\n",
    "rg_params = {\n",
    "    'clf' : rg_clf,\n",
    "    'params':{\n",
    "        'rg__alpha':  hp.uniform('rg__alpha', 0., 1.0)\n",
    "    }\n",
    "    \n",
    "}\n",
    "best = fmin(fn = objective,\n",
    "            space = rg_params,\n",
    "            algo = tpe.suggest,\n",
    "            trials = trials,\n",
    "            max_evals = 10\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> alpha\n",
    "    - 0.0851909"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate stage2 features with TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294, 54)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294, 80)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.concat([merge,text_features_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4571"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)), ('rg', Ridge(alpha=0.0851909, copy_X=True, fit_intercept=True, max_iter=2000,\n",
       "   normalize=True, random_state=0, solver='auto', tol=0.001))])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([\n",
    "                ('standardscaler', StandardScaler(copy=False, with_mean=True, with_std=True)),\n",
    "                ('rg', Ridge(alpha=.0851909, fit_intercept=True, normalize=True, max_iter=2000, random_state=0))\n",
    "            ])\n",
    "model.fit(merge[merge_dates < 27].values, merge_y[merge_dates < 27])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shop_id</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <td>10297.000000</td>\n",
       "      <td>10296.000000</td>\n",
       "      <td>10298.000000</td>\n",
       "      <td>10300.000000</td>\n",
       "      <td>10284.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_block_num</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_category_id</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id_avg_item_price_lag_1</th>\n",
       "      <td>741.560730</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>392.347504</td>\n",
       "      <td>682.033325</td>\n",
       "      <td>266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id_sum_item_cnt_day_lag_1</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id_avg_item_cnt_day_lag_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.308511</td>\n",
       "      <td>1.058824</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop_id_avg_item_price_lag_1</th>\n",
       "      <td>865.302917</td>\n",
       "      <td>865.302917</td>\n",
       "      <td>865.302917</td>\n",
       "      <td>865.302917</td>\n",
       "      <td>865.302917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop_id_sum_item_cnt_day_lag_1</th>\n",
       "      <td>10055.000000</td>\n",
       "      <td>10055.000000</td>\n",
       "      <td>10055.000000</td>\n",
       "      <td>10055.000000</td>\n",
       "      <td>10055.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop_id_avg_item_cnt_day_lag_1</th>\n",
       "      <td>1.363205</td>\n",
       "      <td>1.363205</td>\n",
       "      <td>1.363205</td>\n",
       "      <td>1.363205</td>\n",
       "      <td>1.363205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_category_id_avg_item_price_lag_1</th>\n",
       "      <td>415.529144</td>\n",
       "      <td>981.385864</td>\n",
       "      <td>257.766296</td>\n",
       "      <td>415.529144</td>\n",
       "      <td>280.213409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_category_id_sum_item_cnt_day_lag_1</th>\n",
       "      <td>9959.000000</td>\n",
       "      <td>2052.000000</td>\n",
       "      <td>28598.000000</td>\n",
       "      <td>9959.000000</td>\n",
       "      <td>1425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_category_id_avg_item_cnt_day_lag_1</th>\n",
       "      <td>1.049310</td>\n",
       "      <td>1.018868</td>\n",
       "      <td>1.163135</td>\n",
       "      <td>1.049310</td>\n",
       "      <td>1.016405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_cnt_month_lag_1</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id_avg_item_price_lag_2</th>\n",
       "      <td>749.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>389.673309</td>\n",
       "      <td>686.460693</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id_sum_item_cnt_day_lag_2</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id_avg_item_cnt_day_lag_2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.226191</td>\n",
       "      <td>1.367424</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop_id_avg_item_price_lag_2</th>\n",
       "      <td>730.927124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>730.927124</td>\n",
       "      <td>730.927124</td>\n",
       "      <td>730.927124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop_id_sum_item_cnt_day_lag_2</th>\n",
       "      <td>7978.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7978.000000</td>\n",
       "      <td>7978.000000</td>\n",
       "      <td>7978.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop_id_avg_item_cnt_day_lag_2</th>\n",
       "      <td>1.413036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.413036</td>\n",
       "      <td>1.413036</td>\n",
       "      <td>1.413036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_category_id_avg_item_price_lag_2</th>\n",
       "      <td>451.941986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>253.212753</td>\n",
       "      <td>451.941986</td>\n",
       "      <td>275.436768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_category_id_sum_item_cnt_day_lag_2</th>\n",
       "      <td>7420.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25433.000000</td>\n",
       "      <td>7420.000000</td>\n",
       "      <td>1054.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_category_id_avg_item_cnt_day_lag_2</th>\n",
       "      <td>1.065480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187626</td>\n",
       "      <td>1.065480</td>\n",
       "      <td>1.009579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_cnt_month_lag_2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id_avg_item_price_lag_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>387.736420</td>\n",
       "      <td>659.328308</td>\n",
       "      <td>272.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id_sum_item_cnt_day_lag_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id_avg_item_cnt_day_lag_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.606061</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop_id_avg_item_price_lag_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>691.489380</td>\n",
       "      <td>691.489380</td>\n",
       "      <td>691.489380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop_id_sum_item_cnt_day_lag_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6676.000000</td>\n",
       "      <td>6676.000000</td>\n",
       "      <td>6676.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop_id_avg_item_cnt_day_lag_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.337876</td>\n",
       "      <td>1.337876</td>\n",
       "      <td>1.337876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_50</th>\n",
       "      <td>-0.180033</td>\n",
       "      <td>-0.146619</td>\n",
       "      <td>-0.207971</td>\n",
       "      <td>-0.180033</td>\n",
       "      <td>-0.030481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_51</th>\n",
       "      <td>-0.153903</td>\n",
       "      <td>-0.118807</td>\n",
       "      <td>-0.175445</td>\n",
       "      <td>-0.153903</td>\n",
       "      <td>-0.133433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_52</th>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.081837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_53</th>\n",
       "      <td>-0.001976</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>-0.003440</td>\n",
       "      <td>-0.001976</td>\n",
       "      <td>-0.035135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_54</th>\n",
       "      <td>0.010778</td>\n",
       "      <td>-0.006542</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>0.010778</td>\n",
       "      <td>-0.167786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_55</th>\n",
       "      <td>-0.021560</td>\n",
       "      <td>-0.024223</td>\n",
       "      <td>-0.033774</td>\n",
       "      <td>-0.021560</td>\n",
       "      <td>0.030063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_56</th>\n",
       "      <td>-0.009103</td>\n",
       "      <td>-0.003821</td>\n",
       "      <td>-0.016994</td>\n",
       "      <td>-0.009103</td>\n",
       "      <td>-0.032991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_57</th>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.084474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_58</th>\n",
       "      <td>0.003729</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>-0.002713</td>\n",
       "      <td>0.003729</td>\n",
       "      <td>-0.028601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_59</th>\n",
       "      <td>0.039419</td>\n",
       "      <td>-0.003631</td>\n",
       "      <td>0.032073</td>\n",
       "      <td>0.039419</td>\n",
       "      <td>0.014635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_60</th>\n",
       "      <td>2.008444</td>\n",
       "      <td>2.111174</td>\n",
       "      <td>1.337944</td>\n",
       "      <td>2.008444</td>\n",
       "      <td>1.175036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_61</th>\n",
       "      <td>-1.567986</td>\n",
       "      <td>-1.696096</td>\n",
       "      <td>-0.519320</td>\n",
       "      <td>-1.567986</td>\n",
       "      <td>0.762245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_62</th>\n",
       "      <td>-0.760401</td>\n",
       "      <td>-0.833965</td>\n",
       "      <td>-0.077362</td>\n",
       "      <td>-0.760401</td>\n",
       "      <td>-0.137371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_63</th>\n",
       "      <td>-0.940262</td>\n",
       "      <td>-1.086306</td>\n",
       "      <td>1.361660</td>\n",
       "      <td>-0.940262</td>\n",
       "      <td>0.180278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_64</th>\n",
       "      <td>0.420398</td>\n",
       "      <td>0.422050</td>\n",
       "      <td>0.016933</td>\n",
       "      <td>0.420398</td>\n",
       "      <td>0.697786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_65</th>\n",
       "      <td>-0.895177</td>\n",
       "      <td>-0.893015</td>\n",
       "      <td>-0.907938</td>\n",
       "      <td>-0.895177</td>\n",
       "      <td>-0.964233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_66</th>\n",
       "      <td>0.156057</td>\n",
       "      <td>0.152022</td>\n",
       "      <td>0.160064</td>\n",
       "      <td>0.156057</td>\n",
       "      <td>0.121103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_67</th>\n",
       "      <td>-0.258953</td>\n",
       "      <td>-0.241944</td>\n",
       "      <td>-0.290110</td>\n",
       "      <td>-0.258953</td>\n",
       "      <td>0.224749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_68</th>\n",
       "      <td>0.123255</td>\n",
       "      <td>0.134705</td>\n",
       "      <td>0.129494</td>\n",
       "      <td>0.123255</td>\n",
       "      <td>-0.069207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_69</th>\n",
       "      <td>0.024794</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>0.024794</td>\n",
       "      <td>1.788185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_70</th>\n",
       "      <td>0.029253</td>\n",
       "      <td>0.022853</td>\n",
       "      <td>0.023262</td>\n",
       "      <td>0.029253</td>\n",
       "      <td>0.434330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_71</th>\n",
       "      <td>0.060605</td>\n",
       "      <td>0.059408</td>\n",
       "      <td>0.053279</td>\n",
       "      <td>0.060605</td>\n",
       "      <td>0.394472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_72</th>\n",
       "      <td>0.968887</td>\n",
       "      <td>0.960539</td>\n",
       "      <td>0.973456</td>\n",
       "      <td>0.968887</td>\n",
       "      <td>0.824389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_73</th>\n",
       "      <td>-0.167136</td>\n",
       "      <td>-0.167536</td>\n",
       "      <td>-0.181098</td>\n",
       "      <td>-0.167136</td>\n",
       "      <td>-0.210678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_74</th>\n",
       "      <td>-0.085876</td>\n",
       "      <td>-0.082899</td>\n",
       "      <td>-0.072753</td>\n",
       "      <td>-0.085876</td>\n",
       "      <td>-0.447102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_75</th>\n",
       "      <td>0.056333</td>\n",
       "      <td>0.071592</td>\n",
       "      <td>0.049451</td>\n",
       "      <td>0.056333</td>\n",
       "      <td>-0.487347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_76</th>\n",
       "      <td>-0.021442</td>\n",
       "      <td>-0.041229</td>\n",
       "      <td>-0.025229</td>\n",
       "      <td>-0.021442</td>\n",
       "      <td>-0.153259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_77</th>\n",
       "      <td>-0.020925</td>\n",
       "      <td>-0.013534</td>\n",
       "      <td>-0.014346</td>\n",
       "      <td>-0.020925</td>\n",
       "      <td>-0.203642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_78</th>\n",
       "      <td>-0.042606</td>\n",
       "      <td>-0.026975</td>\n",
       "      <td>-0.031661</td>\n",
       "      <td>-0.042606</td>\n",
       "      <td>-0.281350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_f_79</th>\n",
       "      <td>-0.013391</td>\n",
       "      <td>0.029369</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>-0.013391</td>\n",
       "      <td>-0.100445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0             1  \\\n",
       "shop_id                                     54.000000     54.000000   \n",
       "item_id                                  10297.000000  10296.000000   \n",
       "date_block_num                              12.000000     12.000000   \n",
       "item_category_id                            37.000000     38.000000   \n",
       "item_id_avg_item_price_lag_1               741.560730   1599.000000   \n",
       "item_id_sum_item_cnt_day_lag_1              42.000000     24.000000   \n",
       "item_id_avg_item_cnt_day_lag_1               1.000000      1.000000   \n",
       "shop_id_avg_item_price_lag_1               865.302917    865.302917   \n",
       "shop_id_sum_item_cnt_day_lag_1           10055.000000  10055.000000   \n",
       "shop_id_avg_item_cnt_day_lag_1               1.363205      1.363205   \n",
       "item_category_id_avg_item_price_lag_1      415.529144    981.385864   \n",
       "item_category_id_sum_item_cnt_day_lag_1   9959.000000   2052.000000   \n",
       "item_category_id_avg_item_cnt_day_lag_1      1.049310      1.018868   \n",
       "item_cnt_month_lag_1                         3.000000      0.000000   \n",
       "item_id_avg_item_price_lag_2               749.000000      0.000000   \n",
       "item_id_sum_item_cnt_day_lag_2               2.000000      0.000000   \n",
       "item_id_avg_item_cnt_day_lag_2               1.000000      0.000000   \n",
       "shop_id_avg_item_price_lag_2               730.927124      0.000000   \n",
       "shop_id_sum_item_cnt_day_lag_2            7978.000000      0.000000   \n",
       "shop_id_avg_item_cnt_day_lag_2               1.413036      0.000000   \n",
       "item_category_id_avg_item_price_lag_2      451.941986      0.000000   \n",
       "item_category_id_sum_item_cnt_day_lag_2   7420.000000      0.000000   \n",
       "item_category_id_avg_item_cnt_day_lag_2      1.065480      0.000000   \n",
       "item_cnt_month_lag_2                         0.000000      0.000000   \n",
       "item_id_avg_item_price_lag_3                 0.000000      0.000000   \n",
       "item_id_sum_item_cnt_day_lag_3               0.000000      0.000000   \n",
       "item_id_avg_item_cnt_day_lag_3               0.000000      0.000000   \n",
       "shop_id_avg_item_price_lag_3                 0.000000      0.000000   \n",
       "shop_id_sum_item_cnt_day_lag_3               0.000000      0.000000   \n",
       "shop_id_avg_item_cnt_day_lag_3               0.000000      0.000000   \n",
       "...                                               ...           ...   \n",
       "text_f_50                                   -0.180033     -0.146619   \n",
       "text_f_51                                   -0.153903     -0.118807   \n",
       "text_f_52                                    0.002517      0.008954   \n",
       "text_f_53                                   -0.001976      0.006432   \n",
       "text_f_54                                    0.010778     -0.006542   \n",
       "text_f_55                                   -0.021560     -0.024223   \n",
       "text_f_56                                   -0.009103     -0.003821   \n",
       "text_f_57                                    0.008756      0.021700   \n",
       "text_f_58                                    0.003729      0.018333   \n",
       "text_f_59                                    0.039419     -0.003631   \n",
       "text_f_60                                    2.008444      2.111174   \n",
       "text_f_61                                   -1.567986     -1.696096   \n",
       "text_f_62                                   -0.760401     -0.833965   \n",
       "text_f_63                                   -0.940262     -1.086306   \n",
       "text_f_64                                    0.420398      0.422050   \n",
       "text_f_65                                   -0.895177     -0.893015   \n",
       "text_f_66                                    0.156057      0.152022   \n",
       "text_f_67                                   -0.258953     -0.241944   \n",
       "text_f_68                                    0.123255      0.134705   \n",
       "text_f_69                                    0.024794      0.013649   \n",
       "text_f_70                                    0.029253      0.022853   \n",
       "text_f_71                                    0.060605      0.059408   \n",
       "text_f_72                                    0.968887      0.960539   \n",
       "text_f_73                                   -0.167136     -0.167536   \n",
       "text_f_74                                   -0.085876     -0.082899   \n",
       "text_f_75                                    0.056333      0.071592   \n",
       "text_f_76                                   -0.021442     -0.041229   \n",
       "text_f_77                                   -0.020925     -0.013534   \n",
       "text_f_78                                   -0.042606     -0.026975   \n",
       "text_f_79                                   -0.013391      0.029369   \n",
       "\n",
       "                                                    2             3  \\\n",
       "shop_id                                     54.000000     54.000000   \n",
       "item_id                                  10298.000000  10300.000000   \n",
       "date_block_num                              12.000000     12.000000   \n",
       "item_category_id                            40.000000     37.000000   \n",
       "item_id_avg_item_price_lag_1               392.347504    682.033325   \n",
       "item_id_sum_item_cnt_day_lag_1             369.000000     54.000000   \n",
       "item_id_avg_item_cnt_day_lag_1               1.308511      1.058824   \n",
       "shop_id_avg_item_price_lag_1               865.302917    865.302917   \n",
       "shop_id_sum_item_cnt_day_lag_1           10055.000000  10055.000000   \n",
       "shop_id_avg_item_cnt_day_lag_1               1.363205      1.363205   \n",
       "item_category_id_avg_item_price_lag_1      257.766296    415.529144   \n",
       "item_category_id_sum_item_cnt_day_lag_1  28598.000000   9959.000000   \n",
       "item_category_id_avg_item_cnt_day_lag_1      1.163135      1.049310   \n",
       "item_cnt_month_lag_1                        21.000000      1.000000   \n",
       "item_id_avg_item_price_lag_2               389.673309    686.460693   \n",
       "item_id_sum_item_cnt_day_lag_2            1309.000000    361.000000   \n",
       "item_id_avg_item_cnt_day_lag_2               2.226191      1.367424   \n",
       "shop_id_avg_item_price_lag_2               730.927124    730.927124   \n",
       "shop_id_sum_item_cnt_day_lag_2            7978.000000   7978.000000   \n",
       "shop_id_avg_item_cnt_day_lag_2               1.413036      1.413036   \n",
       "item_category_id_avg_item_price_lag_2      253.212753    451.941986   \n",
       "item_category_id_sum_item_cnt_day_lag_2  25433.000000   7420.000000   \n",
       "item_category_id_avg_item_cnt_day_lag_2      1.187626      1.065480   \n",
       "item_cnt_month_lag_2                       119.000000     31.000000   \n",
       "item_id_avg_item_price_lag_3               387.736420    659.328308   \n",
       "item_id_sum_item_cnt_day_lag_3             144.000000     53.000000   \n",
       "item_id_avg_item_cnt_day_lag_3               2.526316      1.606061   \n",
       "shop_id_avg_item_price_lag_3               691.489380    691.489380   \n",
       "shop_id_sum_item_cnt_day_lag_3            6676.000000   6676.000000   \n",
       "shop_id_avg_item_cnt_day_lag_3               1.337876      1.337876   \n",
       "...                                               ...           ...   \n",
       "text_f_50                                   -0.207971     -0.180033   \n",
       "text_f_51                                   -0.175445     -0.153903   \n",
       "text_f_52                                    0.002964      0.002517   \n",
       "text_f_53                                   -0.003440     -0.001976   \n",
       "text_f_54                                    0.013831      0.010778   \n",
       "text_f_55                                   -0.033774     -0.021560   \n",
       "text_f_56                                   -0.016994     -0.009103   \n",
       "text_f_57                                    0.015511      0.008756   \n",
       "text_f_58                                   -0.002713      0.003729   \n",
       "text_f_59                                    0.032073      0.039419   \n",
       "text_f_60                                    1.337944      2.008444   \n",
       "text_f_61                                   -0.519320     -1.567986   \n",
       "text_f_62                                   -0.077362     -0.760401   \n",
       "text_f_63                                    1.361660     -0.940262   \n",
       "text_f_64                                    0.016933      0.420398   \n",
       "text_f_65                                   -0.907938     -0.895177   \n",
       "text_f_66                                    0.160064      0.156057   \n",
       "text_f_67                                   -0.290110     -0.258953   \n",
       "text_f_68                                    0.129494      0.123255   \n",
       "text_f_69                                    0.006340      0.024794   \n",
       "text_f_70                                    0.023262      0.029253   \n",
       "text_f_71                                    0.053279      0.060605   \n",
       "text_f_72                                    0.973456      0.968887   \n",
       "text_f_73                                   -0.181098     -0.167136   \n",
       "text_f_74                                   -0.072753     -0.085876   \n",
       "text_f_75                                    0.049451      0.056333   \n",
       "text_f_76                                   -0.025229     -0.021442   \n",
       "text_f_77                                   -0.014346     -0.020925   \n",
       "text_f_78                                   -0.031661     -0.042606   \n",
       "text_f_79                                    0.004714     -0.013391   \n",
       "\n",
       "                                                    4  \n",
       "shop_id                                     54.000000  \n",
       "item_id                                  10284.000000  \n",
       "date_block_num                              12.000000  \n",
       "item_category_id                            57.000000  \n",
       "item_id_avg_item_price_lag_1               266.000000  \n",
       "item_id_sum_item_cnt_day_lag_1               4.000000  \n",
       "item_id_avg_item_cnt_day_lag_1               1.000000  \n",
       "shop_id_avg_item_price_lag_1               865.302917  \n",
       "shop_id_sum_item_cnt_day_lag_1           10055.000000  \n",
       "shop_id_avg_item_cnt_day_lag_1               1.363205  \n",
       "item_category_id_avg_item_price_lag_1      280.213409  \n",
       "item_category_id_sum_item_cnt_day_lag_1   1425.000000  \n",
       "item_category_id_avg_item_cnt_day_lag_1      1.016405  \n",
       "item_cnt_month_lag_1                         0.000000  \n",
       "item_id_avg_item_price_lag_2               299.000000  \n",
       "item_id_sum_item_cnt_day_lag_2               3.000000  \n",
       "item_id_avg_item_cnt_day_lag_2               1.000000  \n",
       "shop_id_avg_item_price_lag_2               730.927124  \n",
       "shop_id_sum_item_cnt_day_lag_2            7978.000000  \n",
       "shop_id_avg_item_cnt_day_lag_2               1.413036  \n",
       "item_category_id_avg_item_price_lag_2      275.436768  \n",
       "item_category_id_sum_item_cnt_day_lag_2   1054.000000  \n",
       "item_category_id_avg_item_cnt_day_lag_2      1.009579  \n",
       "item_cnt_month_lag_2                         0.000000  \n",
       "item_id_avg_item_price_lag_3               272.600006  \n",
       "item_id_sum_item_cnt_day_lag_3               5.000000  \n",
       "item_id_avg_item_cnt_day_lag_3               1.000000  \n",
       "shop_id_avg_item_price_lag_3               691.489380  \n",
       "shop_id_sum_item_cnt_day_lag_3            6676.000000  \n",
       "shop_id_avg_item_cnt_day_lag_3               1.337876  \n",
       "...                                               ...  \n",
       "text_f_50                                   -0.030481  \n",
       "text_f_51                                   -0.133433  \n",
       "text_f_52                                    0.081837  \n",
       "text_f_53                                   -0.035135  \n",
       "text_f_54                                   -0.167786  \n",
       "text_f_55                                    0.030063  \n",
       "text_f_56                                   -0.032991  \n",
       "text_f_57                                    0.084474  \n",
       "text_f_58                                   -0.028601  \n",
       "text_f_59                                    0.014635  \n",
       "text_f_60                                    1.175036  \n",
       "text_f_61                                    0.762245  \n",
       "text_f_62                                   -0.137371  \n",
       "text_f_63                                    0.180278  \n",
       "text_f_64                                    0.697786  \n",
       "text_f_65                                   -0.964233  \n",
       "text_f_66                                    0.121103  \n",
       "text_f_67                                    0.224749  \n",
       "text_f_68                                   -0.069207  \n",
       "text_f_69                                    1.788185  \n",
       "text_f_70                                    0.434330  \n",
       "text_f_71                                    0.394472  \n",
       "text_f_72                                    0.824389  \n",
       "text_f_73                                   -0.210678  \n",
       "text_f_74                                   -0.447102  \n",
       "text_f_75                                   -0.487347  \n",
       "text_f_76                                   -0.153259  \n",
       "text_f_77                                   -0.203642  \n",
       "text_f_78                                   -0.281350  \n",
       "text_f_79                                   -0.100445  \n",
       "\n",
       "[134 rows x 5 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_data_text = model.predict(merge[merge_dates >= 27].values)\n",
    "stage2_data_text = np.clip(stage2_data_text, 0., 20.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1828564,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_data_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save to npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/feat/stage2_data_text.npy',stage2_data_text)\n",
    "\n",
    "'''temp = np.load('../data/feat/stage2_data_text.npy')'''"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
