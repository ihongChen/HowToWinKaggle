{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparams tuning \n",
    "\n",
    "## Features \n",
    "    - lag / mean encoding (numerical)\n",
    "    - hashing/tfidf svd text features\n",
    "## cross validation \n",
    "Use only simple hold out scheme\n",
    "- train on `[0-32]`\n",
    "- validate at `date_block_num = 33`\n",
    "- via `hyperopt ` packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/X_cv', '/X_test', '/X_train', '/y_cv', '/y_train']\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('../data/feat/data.h5') as store:\n",
    "    print(store.keys())\n",
    "    X_train = store['X_train']\n",
    "    X_cv = store['X_cv']\n",
    "    y_train = store['y_train']\n",
    "    y_cv = store['y_cv']\n",
    "    X_test = store['X_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.clip(0,20)\n",
    "y_cv = y_cv.clip(0,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/all_feats_df_all']\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('../data/feat/all_feat_df_all.h5') as feat:\n",
    "    print(feat.keys())\n",
    "    all_feats_df_all = feat['all_feats_df_all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11128004, 134)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 1.11852\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's rmse: 1.10167\n",
      "[3]\tvalid_0's rmse: 1.08613\n",
      "[4]\tvalid_0's rmse: 1.0737\n",
      "[5]\tvalid_0's rmse: 1.06229\n",
      "[6]\tvalid_0's rmse: 1.05183\n",
      "[7]\tvalid_0's rmse: 1.04235\n",
      "[8]\tvalid_0's rmse: 1.034\n",
      "[9]\tvalid_0's rmse: 1.02549\n",
      "[10]\tvalid_0's rmse: 1.01715\n",
      "[11]\tvalid_0's rmse: 1.01078\n",
      "[12]\tvalid_0's rmse: 1.00436\n",
      "[13]\tvalid_0's rmse: 0.998014\n",
      "[14]\tvalid_0's rmse: 0.993048\n",
      "[15]\tvalid_0's rmse: 0.986648\n",
      "[16]\tvalid_0's rmse: 0.98167\n",
      "[17]\tvalid_0's rmse: 0.977493\n",
      "[18]\tvalid_0's rmse: 0.973237\n",
      "[19]\tvalid_0's rmse: 0.969171\n",
      "[20]\tvalid_0's rmse: 0.966458\n",
      "[21]\tvalid_0's rmse: 0.964129\n",
      "[22]\tvalid_0's rmse: 0.960643\n",
      "[23]\tvalid_0's rmse: 0.958231\n",
      "[24]\tvalid_0's rmse: 0.956003\n",
      "[25]\tvalid_0's rmse: 0.953993\n",
      "[26]\tvalid_0's rmse: 0.952234\n",
      "[27]\tvalid_0's rmse: 0.950771\n",
      "[28]\tvalid_0's rmse: 0.948667\n",
      "[29]\tvalid_0's rmse: 0.946728\n",
      "[30]\tvalid_0's rmse: 0.945399\n",
      "[31]\tvalid_0's rmse: 0.944374\n",
      "[32]\tvalid_0's rmse: 0.942995\n",
      "[33]\tvalid_0's rmse: 0.941946\n",
      "[34]\tvalid_0's rmse: 0.94107\n",
      "[35]\tvalid_0's rmse: 0.940024\n",
      "[36]\tvalid_0's rmse: 0.93949\n",
      "[37]\tvalid_0's rmse: 0.938961\n",
      "[38]\tvalid_0's rmse: 0.938306\n",
      "[39]\tvalid_0's rmse: 0.937703\n",
      "[40]\tvalid_0's rmse: 0.93696\n",
      "[41]\tvalid_0's rmse: 0.936528\n",
      "[42]\tvalid_0's rmse: 0.935722\n",
      "[43]\tvalid_0's rmse: 0.93552\n",
      "[44]\tvalid_0's rmse: 0.935101\n",
      "[45]\tvalid_0's rmse: 0.934031\n",
      "[46]\tvalid_0's rmse: 0.93363\n",
      "[47]\tvalid_0's rmse: 0.933348\n",
      "[48]\tvalid_0's rmse: 0.933107\n",
      "[49]\tvalid_0's rmse: 0.93264\n",
      "[50]\tvalid_0's rmse: 0.932358\n",
      "[51]\tvalid_0's rmse: 0.932081\n",
      "[52]\tvalid_0's rmse: 0.931791\n",
      "[53]\tvalid_0's rmse: 0.931377\n",
      "[54]\tvalid_0's rmse: 0.931149\n",
      "[55]\tvalid_0's rmse: 0.930796\n",
      "[56]\tvalid_0's rmse: 0.930605\n",
      "[57]\tvalid_0's rmse: 0.930349\n",
      "[58]\tvalid_0's rmse: 0.930015\n",
      "[59]\tvalid_0's rmse: 0.929474\n",
      "[60]\tvalid_0's rmse: 0.92935\n",
      "[61]\tvalid_0's rmse: 0.929277\n",
      "[62]\tvalid_0's rmse: 0.928728\n",
      "[63]\tvalid_0's rmse: 0.928092\n",
      "[64]\tvalid_0's rmse: 0.927978\n",
      "[65]\tvalid_0's rmse: 0.927248\n",
      "[66]\tvalid_0's rmse: 0.926928\n",
      "[67]\tvalid_0's rmse: 0.926648\n",
      "[68]\tvalid_0's rmse: 0.926406\n",
      "[69]\tvalid_0's rmse: 0.926257\n",
      "[70]\tvalid_0's rmse: 0.926155\n",
      "[71]\tvalid_0's rmse: 0.925969\n",
      "[72]\tvalid_0's rmse: 0.925286\n",
      "[73]\tvalid_0's rmse: 0.925124\n",
      "[74]\tvalid_0's rmse: 0.924882\n",
      "[75]\tvalid_0's rmse: 0.923928\n",
      "[76]\tvalid_0's rmse: 0.923629\n",
      "[77]\tvalid_0's rmse: 0.923196\n",
      "[78]\tvalid_0's rmse: 0.923116\n",
      "[79]\tvalid_0's rmse: 0.922911\n",
      "[80]\tvalid_0's rmse: 0.922755\n",
      "[81]\tvalid_0's rmse: 0.922521\n",
      "[82]\tvalid_0's rmse: 0.922348\n",
      "[83]\tvalid_0's rmse: 0.921861\n",
      "[84]\tvalid_0's rmse: 0.921795\n",
      "[85]\tvalid_0's rmse: 0.921464\n",
      "[86]\tvalid_0's rmse: 0.921354\n",
      "[87]\tvalid_0's rmse: 0.920979\n",
      "[88]\tvalid_0's rmse: 0.921058\n",
      "[89]\tvalid_0's rmse: 0.920909\n",
      "[90]\tvalid_0's rmse: 0.920765\n",
      "[91]\tvalid_0's rmse: 0.920909\n",
      "[92]\tvalid_0's rmse: 0.920832\n",
      "[93]\tvalid_0's rmse: 0.920524\n",
      "[94]\tvalid_0's rmse: 0.920483\n",
      "[95]\tvalid_0's rmse: 0.920244\n",
      "[96]\tvalid_0's rmse: 0.920081\n",
      "[97]\tvalid_0's rmse: 0.919954\n",
      "[98]\tvalid_0's rmse: 0.919542\n",
      "[99]\tvalid_0's rmse: 0.919221\n",
      "[100]\tvalid_0's rmse: 0.919166\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's rmse: 0.919166\n"
     ]
    }
   ],
   "source": [
    "''' simple test on params tuning for validation data (33)'''\n",
    "train_mask = all_feats_df_all.date_block_num <= 32\n",
    "cv_mask = all_feats_df_all.date_block_num == 33\n",
    "\n",
    "params = {    \n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'max_depth': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5    \n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(all_feats_df_all[train_mask], y_train)\n",
    "lgb_cv = lgb.Dataset(all_feats_df_all[cv_mask], y_cv, reference=lgb_train)\n",
    "\n",
    "reg = lgb.train(params,\n",
    "                early_stopping_rounds = 5,\n",
    "                train_set = lgb_train,\n",
    "                valid_sets=lgb_cv,\n",
    "                verbose_eval = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_objective(params):\n",
    "    ## stolen from :https://github.com/hyperopt/hyperopt/issues/357\n",
    "    lgb_train = lgb.Dataset(X_train,y_train)\n",
    "    lgb_cv = lgb.Dataset(X_cv,y_cv,reference=lgb_train)\n",
    "    params\n",
    "    reg = lgb.train(params_set,\n",
    "                    early_stopping_rounds = 5,\n",
    "                    train_set = lgb_train,\n",
    "                    valid_sets=lgb_cv,\n",
    "                    verbose_eval = False)\n",
    "#     score = cross_val_score(reg, X_train,y_train, cv=StratifiedKFold()).mean()\n",
    "    print('params:{}'.format(params))\n",
    "    pred = reg.predict(X_cv, num_iteration=reg.best_iteration)\n",
    "    mse = mean_squared_error(y_cv, pred)\n",
    "    rmse = mse**0.5\n",
    "    print(\"SCORE:{:.5f}\".format(rmse))\n",
    "    return {'loss':rmse, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_space = {\n",
    "    'boosting_type'   : hp.choice('boosting_type',['gbdt', 'dart']), ## gbdt \n",
    "    'max_depth'       : hp.choice(\"max_depth\", np.arange(4, 17, dtype=int)),\n",
    "    'num_leaves'      : hp.choice('num_leaves', np.arange(8,129,2,dtype=int)),\n",
    "    ''\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.3, 1.0),\n",
    "    'bagging_fraction': hp.uniform ('bagging_fraction', 0.7, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda',0,1),\n",
    "    'gamma' : hp.uniform('gamma', 0.1,0.5),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
